対角成分が大きくなってしまった。
→Crossentropyを使っており、outputの確率が1を超えるとlossが正になり有利になるから積極的に1を超えてた。

対角成分を-3に固定して学習するといい感じの形になった！

叩き台としての近似は、2stepくらいなら上手くいくが、距離が長くなるとほとんど最初のワンステップのみしか学習してくれなくなった。

    # 正解数が多いほど損失が大きくなっている事に注意（修正すべきか？）
    loss = criterion(outputs, train_Y)


やりたいこと
2ルート作ってみる。違う分野だと想定する。

L2変えた時、-3も変更する必要あるのでは