{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 時間情報のない集団データ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 方針"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "・内部に問題ごとの依存関係を定義し、その関係をもとに遷移させる。\n",
    "\n",
    "・条件付き確率（遷移確率）と周辺分布の積の和から次の周辺分布を求める。\n",
    "\n",
    "・まずは遷移過程が部分的にしか分からない人工データを用意し、モデルを学習する。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 人工データ生成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0. ]\n",
      " [3.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0. ]\n",
      " [3.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0. ]\n",
      " [3.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0. ]\n",
      " [0.  1.5 1.5 0.  0.  0.  0.  0.  0.  0.  0. ]\n",
      " [0.  0.  1.5 1.5 0.  0.  0.  0.  0.  0.  0. ]\n",
      " [0.  0.  0.  0.  3.  0.  0.  0.  0.  0.  0. ]\n",
      " [0.  0.  0.  0.  0.  3.  0.  0.  0.  0.  0. ]\n",
      " [0.  0.  0.  0.  0.  0.  1.5 1.5 0.  0.  0. ]\n",
      " [0.  0.  0.  0.  0.  0.  0.  0.  3.  0.  0. ]\n",
      " [0.  0.  0.  0.  0.  0.  0.  0.  0.  3.  0. ]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# 問題の依存関係の行列 A \n",
    "A = np.array([\n",
    "    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],  # 初期状態\n",
    "    [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],  # 問題1は初期状態のみに依存\n",
    "    [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],  # 問題2は初期状態のみに依存\n",
    "    [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],  # 問題3は初期状態のみに依存\n",
    "    [0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0],  # 問題4は問題1、問題2に依存\n",
    "    [0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0],  # 問題5は問題2、問題3に依存\n",
    "    [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0],  # 問題6は問題5に依存\n",
    "    [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0],  # 問題7は問題6に依存\n",
    "    [0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0],  # 問題8は問題6、問題7に依存\n",
    "    [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0],  # 問題9は問題8に依存\n",
    "    [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0]  # 問題10は問題9に依存\n",
    "], dtype=float) * 3\n",
    "\n",
    "# 0でない要素の数で割る処理\n",
    "nonzero_counts = np.count_nonzero(A[1:], axis=1, keepdims=True)\n",
    "A[1:] = np.where(nonzero_counts != 0, A[1:] / nonzero_counts, 0)\n",
    "\n",
    "print(A)\n",
    "\n",
    "num_questions = len(A)-1  # 問題数\n",
    "\n",
    "# 遷移確率を計算する関数\n",
    "def calculate_transition_probabilities(A, X):\n",
    "    n = len(X)\n",
    "    raw_probabilities = np.zeros(n)  # 遷移確率の元となる値\n",
    "    \n",
    "    # 不正解の問題に対して遷移確率を計算\n",
    "    for i in range(n):\n",
    "        if X[i] == 0:  # まだ正解していない問題のみ対象\n",
    "            required_problems = A[i, :]  # i番目の問題に必要な依存関係\n",
    "            \n",
    "            solved_problems = X * required_problems  # 現状解けている\n",
    "            \n",
    "            num_solved = np.sum(solved_problems)      # 実際に解けた問題の数\n",
    "            \n",
    "            raw_probabilities[i] = np.exp(num_solved)\n",
    "    \n",
    "    # 総和で割って正規化\n",
    "    total_sum = np.sum(raw_probabilities)  # expの総和\n",
    "    if total_sum > 0:  # 総和が0でなければ正規化\n",
    "        probabilities = raw_probabilities / total_sum\n",
    "    else:\n",
    "        probabilities = raw_probabilities  # 総和が0ならそのまま\n",
    "    \n",
    "    return probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 教師データセットを生成する関数\n",
    "def generate_training_data(A, initial_X, num_correct_problems, num_data_per_step):\n",
    "    n = len(initial_X)  # 問題数\n",
    "    dataset = []\n",
    "    \n",
    "    # 各ステップでデータを生成\n",
    "    for i in range(1, num_correct_problems + 1):  # 正解させる問題数。別にnum_correct_problems問目は生成する必要ない。\n",
    "        for j in range(num_data_per_step):  # 各ステップごとにデータ数\n",
    "            X = initial_X.copy()  # 初期状態からスタート\n",
    "            input_X = X.copy()\n",
    "            # i問正解させる\n",
    "            for k in range(i):\n",
    "\n",
    "                probabilities = calculate_transition_probabilities(A, X)\n",
    "                \n",
    "                if np.sum(probabilities) > 0:  # 正規化された確率がある場合\n",
    "                    # 確率に基づいて次に正解させる問題を選択\n",
    "                    next_correct_problem = np.random.choice(n, p=probabilities)\n",
    "                    X[next_correct_problem] = 1  # 選ばれた問題を正解に遷移させる\n",
    "                \n",
    "            # 初期状態と1ステップ後の状態の差分を教師データとして使用\n",
    "            target_Y = (X - input_X).clip(min=0)  # 0から1に変わった部分のみを1、他は0\n",
    "\n",
    "            # print(f\"input_X: {input_X}, target_Y: {target_Y}\")\n",
    "\n",
    "            # 初期状態（入力）と差分（教師データ）のペアを保存\n",
    "            dataset.append((input_X.copy(), target_Y.copy()))  # (入力データ, 教師データ)\n",
    "    return dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## モデル"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "\n",
    "import itertools\n",
    "from collections import defaultdict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def _bcsoftmax1d(x, budget):\n",
    "    \"\"\"Budget Constrained Softmax function for vector.\n",
    "\n",
    "    Args:\n",
    "        x (Tensor): input vector. shape: (n_outputs, )\n",
    "        budget (Tensor): budget (constraint) vector. shape: (n_outputs, )\n",
    "\n",
    "    Returns:\n",
    "        y (Tensor): output probability vector. shape: (n_outputs, ). Satisfying the constraints y_i <= budget_i.\n",
    "    \n",
    "    \"\"\"\n",
    "    x = x - torch.max(x, dim=0)[0] # normalization to avoid numerical errors\n",
    "    exp_x = torch.exp(x)\n",
    "    # sorting\n",
    "    _, indices = torch.sort(budget / exp_x, descending=False)\n",
    "    exp_x = exp_x[indices]\n",
    "    budget = budget[indices]\n",
    "    # find K_B\n",
    "    r = torch.flip(torch.cumsum(torch.flip(exp_x, dims=(0, )), dim=0), dims=(0, ))\n",
    "    s = 1.0 - (torch.cumsum(budget, dim=0) - budget)\n",
    "    z = r / s\n",
    "    is_in_KB = torch.logical_and(\n",
    "        (s - budget) > 0, exp_x / z > budget\n",
    "    )\n",
    "    # compute outputs\n",
    "    s = 1 - torch.sum(budget * is_in_KB)\n",
    "    r = torch.sum(exp_x * (~is_in_KB))\n",
    "    y = torch.where(~is_in_KB, s * exp_x / r, budget)\n",
    "    # undo sorting\n",
    "    _, inv_indices = torch.sort(indices, descending=False)\n",
    "    return y[inv_indices]\n",
    "\n",
    "\n",
    "def _bcsoftmax1d_stable(x, budget):\n",
    "    \"\"\"Budget Constrained Softmax function for vector.\n",
    "    This function is more numerically stable than `_bcsoftmax1d` by computing some values in log-scale.\n",
    "    \n",
    "    Args:\n",
    "        x (Tensor): input vector. shape: (n_outputs, )\n",
    "        budget (Tensor): budget (constraint) vector. shape: (n_outputs, )\n",
    "\n",
    "    Returns:\n",
    "        y (Tensor): output probability vector. shape: (n_outputs, ). Satisfying the constraints y_i <= budget_i.\n",
    "    \n",
    "    \"\"\"\n",
    "    # sorting\n",
    "    _, indices = torch.sort(torch.log(budget) - x, descending=False)\n",
    "    x = x[indices]\n",
    "    budget = budget[indices]\n",
    "    # find K_B\n",
    "    log_r = torch.flip(torch.logcumsumexp(torch.flip(x, dims=(0, )), dim=0), dims=(0, ))\n",
    "    s = 1.0 - (torch.cumsum(budget, dim=0) - budget)\n",
    "    is_in_KB = torch.logical_or(\n",
    "        budget == 0,\n",
    "        torch.logical_and(\n",
    "            s - budget > 0,\n",
    "            x - log_r + torch.log(s) > torch.log(budget)\n",
    "        )\n",
    "    )\n",
    "    # compute outputs\n",
    "    exp_x = torch.exp(x - torch.max(torch.where(~is_in_KB, x, -torch.inf), dim=0)[0])\n",
    "    s = 1 - torch.sum(budget * is_in_KB)\n",
    "    r = torch.sum(exp_x * (~is_in_KB))\n",
    "    y = torch.where(~is_in_KB, s * exp_x / r, budget)\n",
    "    # undo sorting\n",
    "    _, inv_indices = torch.sort(indices, descending=False)\n",
    "    return y[inv_indices]\n",
    "\n",
    "\n",
    "class BCSoftmax1d(torch.autograd.Function):\n",
    "    \"\"\"Autograd implementation of Budget Constrained Softmax function for vector.\n",
    "    \"\"\"\n",
    "    generate_vmap_rule = True\n",
    "    \n",
    "    @staticmethod\n",
    "    def forward(x, c):\n",
    "        y = _bcsoftmax1d_stable(x, c)\n",
    "        return y\n",
    "\n",
    "    @staticmethod\n",
    "    def setup_context(ctx, inputs, output):\n",
    "        x, c = inputs\n",
    "        is_in_KB = c == output\n",
    "        ctx.save_for_backward(x, c, is_in_KB)\n",
    "    \n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_y):\n",
    "        x, c, is_in_KB = ctx.saved_tensors\n",
    "        exp_x = torch.exp(\n",
    "            x - torch.max(torch.where(~is_in_KB, x, -torch.inf), dim=0)[0]\n",
    "        )\n",
    "        s = 1 - torch.sum(c * is_in_KB)\n",
    "        r = torch.sum(exp_x * (~is_in_KB))\n",
    "        \n",
    "        # compute Jacobian\n",
    "        Jx = torch.where(\n",
    "            torch.outer(~is_in_KB, ~is_in_KB),\n",
    "            torch.diag(~is_in_KB * exp_x) * r - torch.outer(exp_x, exp_x),\n",
    "            0,\n",
    "        )\n",
    "        Jx *= torch.where(\n",
    "            s > 0,\n",
    "            s / (r * r),\n",
    "            0\n",
    "        )\n",
    "        Jc = torch.where(\n",
    "            torch.outer(~is_in_KB, is_in_KB),\n",
    "            - exp_x[:, None] / r,\n",
    "            1.0 * torch.diag(is_in_KB)\n",
    "        )\n",
    "\n",
    "        # print(\"s\", s, \"r\", r)\n",
    "        # print(\"勾配\", torch.matmul(grad_y, Jx), torch.matmul(grad_y, Jc))\n",
    "        assert not torch.isnan(torch.matmul(grad_y, Jx)).any(), \"Jx contains NaN\"\n",
    "        assert not torch.isinf(torch.matmul(grad_y, Jx)).any(), \"Jx contains Inf\"\n",
    "        assert not torch.isnan(torch.matmul(grad_y, Jc)).any(), \"Jc contains NaN\"\n",
    "        assert not torch.isinf(torch.matmul(grad_y, Jc)).any(), \"Jc contains Inf\"\n",
    "\n",
    "        # return vector-Jacobian product\n",
    "        return torch.matmul(grad_y, Jx), torch.matmul(grad_y, Jc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "######### Use these functions! #########\n",
    "bcsoftmax1d = BCSoftmax1d.apply\n",
    "\n",
    "# データによってmodelを通す回数が違\n",
    "# bcsoftmax2d = torch.vmap(BCSoftmax1d.apply) # input shape = (batch_size, n_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, num_questions):\n",
    "        super(Model, self).__init__()\n",
    "        self.fc = nn.Linear(num_questions, num_questions, bias=False)  # 全結合層\n",
    "\n",
    "    def forward(self, x, c):\n",
    "        x = self.fc(x)  # 全結合層の適用\n",
    "        x = bcsoftmax1d(x, c)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# モデル、損失関数、最適化関数の設定\n",
    "model = Model(num_questions+1)  # 5問+初期状態の問題を扱うモデル\n",
    "criterion = nn.CrossEntropyLoss()  # クロスエントロピー損失\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KLダイバージェンスの計算式\n",
    "\n",
    "$$ D_{\\text{KL}}(p \\| q) = \\sum_{i} p(i) \\log \\frac{p(i)}{q(i)} $$\n",
    "\n",
    "---\n",
    "\n",
    "Hellinger距離の計算式\n",
    "\n",
    "$$ H(p, q) = \\frac{1}{\\sqrt{2}} \\left\\| \\sqrt{p} - \\sqrt{q} \\right\\|_2 $$\n",
    "\n",
    "ここで、ユークリッドノルム（L2ノルム）は以下のように定義されます：\n",
    "\n",
    "$$ \\left\\| \\sqrt{p} - \\sqrt{q} \\right\\|_2 = \\sqrt{\\sum_{i} \\left( \\sqrt{p(i)} - \\sqrt{q(i)} \\right)^2} $$\n",
    "\n",
    "---\n",
    "\n",
    "Jensen-Shannonダイバージェンスの式\n",
    "\n",
    "JSD は、pとqの加重平均 $$ m = \\frac{1}{2}(p + q) $$ を使い、以下の式で表されます：\n",
    "\n",
    "$$ D_{\\text{JS}}(p \\| q) = \\frac{1}{2} D_{\\text{KL}}(p \\| m) + \\frac{1}{2} D_{\\text{KL}}(q \\| m) $$\n",
    "\n",
    "ここで、 D_{\\text{KL}}(p \\| q)  は KL ダイバージェンスを表し、以下のように計算されます：\n",
    "\n",
    "$$ D_{\\text{KL}}(p \\| q) = \\sum_{i} p(i) \\log \\frac{p(i)}{q(i)} $$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def kl_divergence(p, q, epsilon=1e-10):\n",
    "    \"\"\"\n",
    "    KLダイバージェンスを計算する関数（qが0の場合の無限大問題を回避）\n",
    "    \n",
    "    Parameters:\n",
    "        p (numpy.ndarray): 真の確率分布\n",
    "        q (numpy.ndarray): 予測確率分布\n",
    "        epsilon (float): スムージングパラメータ（非常に小さい値）\n",
    "    \n",
    "    Returns:\n",
    "        float: KLダイバージェンス\n",
    "    \"\"\"\n",
    "    p = np.array(p, dtype=np.float64)\n",
    "    q = np.array(q, dtype=np.float64)\n",
    "    \n",
    "    # pとqにスムージングを適用\n",
    "    p = np.where(p == 0, epsilon, p)\n",
    "    q = np.where(q == 0, epsilon, q)\n",
    "    \n",
    "    # KLダイバージェンスの計算\n",
    "    return np.sum(p * np.log(p / q))\n",
    "\n",
    "def hellinger_distance(p, q):\n",
    "    \"\"\"\n",
    "    Hellinger距離を計算する関数\n",
    "\n",
    "    Parameters:\n",
    "        p (numpy.ndarray): 真の分布 [batch_size, num_classes]\n",
    "        q (numpy.ndarray): 予測分布 [batch_size, num_classes]\n",
    "    \n",
    "    Returns:\n",
    "        float: Hellinger距離の平均値\n",
    "    \"\"\"\n",
    "    p = np.array(p, dtype=np.float64)\n",
    "    q = np.array(q, dtype=np.float64)\n",
    "    # Hellinger距離の計算式: H(p, q) = (1/√2) * ||√p - √q||_2\n",
    "    sqrt_p = np.sqrt(p)\n",
    "    sqrt_q = np.sqrt(q)\n",
    "    distance = np.sqrt(np.sum((sqrt_p - sqrt_q) ** 2)) / np.sqrt(2)\n",
    "    return np.mean(distance)\n",
    "\n",
    "def jensen_shannon_divergence(p, q):\n",
    "    \"\"\"\n",
    "    Jensen-Shannon divergence を計算する関数\n",
    "\n",
    "    Parameters:\n",
    "        p (numpy.ndarray): 真の分布 [batch_size, num_classes]\n",
    "        q (numpy.ndarray): 予測分布 [batch_size, num_classes]\n",
    "    \n",
    "    Returns:\n",
    "        float: Jensen-Shannon divergence の平均値\n",
    "    \"\"\"\n",
    "    p = np.array(p, dtype=np.float64)\n",
    "    q = np.array(q, dtype=np.float64)\n",
    "\n",
    "    # 0 の値があると log(0) が発生するため、微小値を加える\n",
    "    epsilon = 1e-12\n",
    "    p = np.clip(p, epsilon, 1)\n",
    "    q = np.clip(q, epsilon, 1)\n",
    "    \n",
    "    # 分布の平均 M\n",
    "    m = 0.5 * (p + q)\n",
    "    \n",
    "    # Kullback-Leibler divergence の補助関数\n",
    "    def kl(a, b):\n",
    "        return np.sum(a * np.log(a / b))\n",
    "    \n",
    "    # JSD の計算: JSD(p || q) = 0.5 * (KL(p || M) + KL(q || M))\n",
    "    jsd = 0.5 * (kl(p, m) + kl(q, m))\n",
    "    \n",
    "    # 各サンプルの平均を返す\n",
    "    return np.mean(jsd)\n",
    "\n",
    "\n",
    "def evaluate_model(r, p, q):\n",
    "    \"\"\"\n",
    "    遷移確率の真値と予測値の類似性を評価する関数\n",
    "    :param r: 各ノードの重み (np.array)\n",
    "    :param p: 各ノードの真の遷移確率 (2D np.array: ノード数 x 遷移確率)\n",
    "    :param q: 各ノードの予測遷移確率 (2D np.array: ノード数 x 遷移確率)\n",
    "    :return: 評価指標 L\n",
    "    \"\"\"\n",
    "    L = 0\n",
    "    for k in range(len(r)):\n",
    "        L += r[k] * kl_divergence(p[k], q[k])\n",
    "    return L"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 学習"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# データセットの生成\n",
    "num_data_per_step = 20     # 各ステップごとに生成するデータ数\n",
    "\n",
    "num_epochs = 1500  # エポック数\n",
    "alpha = 0.001 # 正則化パラメータ\n",
    "early_stopping_patience = 10  # Early Stopping の patience\n",
    "\n",
    "split_ratio = 0.5  # 学習データと検証データの分割比率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/zg/773ptkr55z99zw26dvy19_v00000gn/T/ipykernel_58815/359068116.py:33: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/tensor_new.cpp:281.)\n",
      "  train_X = torch.tensor(train_X_data, dtype=torch.float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [100/1500], Loss: 12.4994, Validation Loss: 12.5455\n",
      "Epoch [200/1500], Loss: 12.4374, Validation Loss: 12.5049\n",
      "Epoch [300/1500], Loss: 12.4126, Validation Loss: 12.4938\n",
      "Epoch [400/1500], Loss: 12.4008, Validation Loss: 12.4874\n",
      "Epoch [500/1500], Loss: 12.3939, Validation Loss: 12.4841\n",
      "Epoch [600/1500], Loss: 12.3891, Validation Loss: 12.4815\n",
      "Epoch [700/1500], Loss: 12.3853, Validation Loss: 12.4794\n",
      "Epoch [800/1500], Loss: 12.3818, Validation Loss: 12.4778\n",
      "Early stopping at epoch 810\n",
      "Training complete!\n"
     ]
    }
   ],
   "source": [
    "# 生徒の回答状況 X (1が正解、0が不正解)\n",
    "# 初期状態は全て不正解\n",
    "X_init = np.array([1] + [0] * num_questions)\n",
    "\n",
    "training_data = generate_training_data(A, X_init, num_questions, num_data_per_step)\n",
    "train_X = [input_data for input_data, _ in training_data]\n",
    "train_Y = [target_data for _, target_data in training_data]\n",
    "\n",
    "\n",
    "# データをトレーニングと検証に分割（正解数のバランスが良くなるように分割）\n",
    "# 8:2に分割\n",
    "def split_balanced_data(train_X, train_Y, ratio=0.8):\n",
    "    data_per_correct_count = defaultdict(list)\n",
    "    for x, y in zip(train_X, train_Y):\n",
    "        correct_count = sum(y)\n",
    "        data_per_correct_count[correct_count].append((x, y))\n",
    "\n",
    "    train_X_data, train_Y_data, val_X_data, val_Y_data = [], [], [], []\n",
    "    for correct_count, data in data_per_correct_count.items():\n",
    "        split_index = int(len(data) * ratio)\n",
    "        train_data = data[:split_index]\n",
    "        val_data = data[split_index:]\n",
    "        train_X_data.extend([x for x, y in train_data])\n",
    "        train_Y_data.extend([y for x, y in train_data])\n",
    "        val_X_data.extend([x for x, y in val_data])\n",
    "        val_Y_data.extend([y for x, y in val_data])\n",
    "\n",
    "    return train_X_data, train_Y_data, val_X_data, val_Y_data\n",
    "\n",
    "train_X_data, train_Y_data, val_X_data, val_Y_data = split_balanced_data(train_X, train_Y, split_ratio)\n",
    "\n",
    "# PyTorch テンソルに変換\n",
    "train_X = torch.tensor(train_X_data, dtype=torch.float32)\n",
    "train_Y = torch.tensor(train_Y_data, dtype=torch.float32)\n",
    "val_X = torch.tensor(val_X_data, dtype=torch.float32)\n",
    "val_Y = torch.tensor(val_Y_data, dtype=torch.float32)\n",
    "\n",
    "\"状態定義\"\n",
    "\n",
    "# Generate states where the first digit is always 1\n",
    "states = [(1,) + state for state in itertools.product([0, 1], repeat=num_questions)]\n",
    "\n",
    "states = sorted(states, key=lambda state: sum(state))\n",
    "\n",
    "# Initialize the state counts\n",
    "state_counts = defaultdict(int)\n",
    "\n",
    "# Assuming 'dataset' is your list of student results\n",
    "for result, result2 in training_data:\n",
    "    # print(result2)\n",
    "    state_tuple = tuple(map(int, result + result2))  # Convert np.int64 to int\n",
    "    state_counts[state_tuple] += 1  # Count only if the first digit is 1\n",
    "\n",
    "# Display the counts for each state\n",
    "for state in states:\n",
    "    count = state_counts[state]\n",
    "    formatted_state = list(state)  # Convert tuple to list for the desired format\n",
    "\n",
    "\"モデル定義\"\n",
    "# モデル、損失関数、最適化関数の設定\n",
    "model = Model(num_questions+1)  # 5問+初期状態の問題を扱うモデル\n",
    "criterion = nn.CrossEntropyLoss()  # クロスエントロピー損失\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "\"学習\"\n",
    "best_val_loss = float('inf')\n",
    "early_stopping_counter = 0\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()  # モデルを訓練モードに\n",
    "    optimizer.zero_grad()  # 勾配の初期化\n",
    "\n",
    "    outputs = []  # 出力を保持するリスト\n",
    "\n",
    "    # 各データに対して train_Y の値に基づいてループを実行\n",
    "    for i, target in enumerate(train_Y):\n",
    "        c = torch.cat([torch.tensor([0.0]), torch.ones(num_questions, dtype=torch.float32)])\n",
    "        output = train_X[i]  # 各 i 番目の入力データを使用\n",
    "        output = output.view(-1)\n",
    "        # target (train_Y[i]) が int 型または float 型であると仮定\n",
    "        for _ in range(int(sum(target))):\n",
    "            # もしcの和が1なら、rが0となるので対応\n",
    "            if c.sum() <= 1:\n",
    "                # print(\"aaaaaaaa\")\n",
    "                output_0 = c\n",
    "            else:\n",
    "                output_0 = model(output, c)  # 前回の出力を次のステップの入力として使用\n",
    "            output = output_0 + output  # 出力を加算\n",
    "            c = c - output_0  # 予算を更新\n",
    "\n",
    "        outputs.append(output - train_X[i])  # 最終的な出力を保存\n",
    "\n",
    "    # outputs を適切な形に変換して損失計算（例えば torch.stack を使用）\n",
    "    outputs = torch.stack(outputs)\n",
    "    outputs = outputs.squeeze(1)\n",
    "\n",
    "    # モデルの出力の確認\n",
    "    assert not torch.isnan(outputs).any(), \"Model output contains NaN\"\n",
    "    assert not torch.isinf(outputs).any(), \"Model output contains Inf\"\n",
    "\n",
    "    # L1正則化項の計算\n",
    "    l1_reg = torch.tensor(0.0, requires_grad=True)\n",
    "    for param in model.parameters():\n",
    "        l1_reg = l1_reg + torch.sum(torch.abs(param))\n",
    "\n",
    "    # 損失の計算\n",
    "    loss0 = criterion(outputs, train_Y)\n",
    "\n",
    "    loss = loss0 + alpha * l1_reg  # L1正則化項を追加した損失\n",
    "\n",
    "    # 損失の確認\n",
    "    assert not torch.isnan(loss).any(), \"Loss contains NaN\"\n",
    "    assert not torch.isinf(loss).any(), \"Loss contains Inf\"\n",
    "\n",
    "    # バックプロパゲーションとパラメータの更新\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # 検証フェーズ\n",
    "    model.eval()  # モデルを評価モードに\n",
    "    with torch.no_grad():\n",
    "        val_outputs = []\n",
    "        for i, target in enumerate(val_Y):\n",
    "            c = torch.cat([torch.tensor([0.0]), torch.ones(num_questions, dtype=torch.float32)])\n",
    "            output = val_X[i]  # 各 i 番目の入力データを使用\n",
    "            output = output.view(-1)\n",
    "            for _ in range(int(sum(target))):\n",
    "                if c.sum() <= 1:\n",
    "                    output_0 = c\n",
    "                else:\n",
    "                    output_0 = model(output, c)\n",
    "                output = output_0 + output\n",
    "                c = c - output_0\n",
    "            val_outputs.append(output - val_X[i])\n",
    "\n",
    "        val_outputs = torch.stack(val_outputs)\n",
    "        val_outputs = val_outputs.squeeze(1)\n",
    "        val_loss0 = criterion(val_outputs, val_Y)\n",
    "        val_loss = val_loss0 + alpha * l1_reg\n",
    "\n",
    "    # Early Stopping の処理\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        early_stopping_counter = 0\n",
    "    else:\n",
    "        early_stopping_counter += 1\n",
    "\n",
    "    if early_stopping_counter >= early_stopping_patience:\n",
    "        print(f\"Early stopping at epoch {epoch+1}\")\n",
    "        break\n",
    "\n",
    "    # 100エポックごとに損失を表示\n",
    "    if (epoch+1) % 100 == 0:\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}, Validation Loss: {val_loss.item():.4f}')\n",
    "\n",
    "# 学習結果の確認\n",
    "print(\"Training complete!\")\n",
    "\n",
    "\"モデル評価\"\n",
    "node_probabilities = defaultdict(float)\n",
    "start = (1,) + tuple(0 for _ in range(num_questions))\n",
    "node_probabilities[start] = 1\n",
    "\n",
    "# 機械学習モデルと簡易モデル\n",
    "KL = 0\n",
    "HD = 0\n",
    "JSD = 0\n",
    "KL2 = 0\n",
    "HD2 = 0\n",
    "JSD2 = 0\n",
    "\n",
    "for state in states:\n",
    "    probabilities = calculate_transition_probabilities(A, np.array(state))\n",
    "\n",
    "    # 最下層から頂点までのノードの分布を順に計算\n",
    "    for i in range(num_questions + 1):\n",
    "        if state[i] == 0:  # まだ解けていない問題\n",
    "            # 遷移後の状態\n",
    "            next_state = list(state)\n",
    "            next_state[i] = 1\n",
    "            next_state = tuple(next_state)\n",
    "            node_probabilities[next_state] += probabilities[i] * node_probabilities[state]\n",
    "    \n",
    "    # budgetの計算\n",
    "    c_g = torch.ones(num_questions+1, dtype=torch.float32)\n",
    "    c_g = c_g - torch.tensor(state, dtype=torch.float32)\n",
    "\n",
    "    # 状態とその予測分布\n",
    "    state_tensor = torch.tensor(state, dtype=torch.float32)\n",
    "    predicted_values = model(state_tensor, c_g)  # 予測値を計算\n",
    "\n",
    "    # 評価指標の計算\n",
    "    kl = node_probabilities[state] * kl_divergence(probabilities, predicted_values.detach())\n",
    "    hd = node_probabilities[state] * hellinger_distance(probabilities, predicted_values.detach())\n",
    "    jsd = node_probabilities[state] * jensen_shannon_divergence(probabilities, predicted_values.detach())\n",
    "    # print(f\"状態: {state}, ノード分布: {node_probabilities[state]:.3g}, KL: {kl:.3g}, HD: {hd:.3g}, JSD: {jsd:.3g}\")\n",
    "    # print(f\"真の遷移確率: {probabilities}, 予測遷移確率: {predicted_values}\")\n",
    "    KL += kl\n",
    "    HD += hd\n",
    "    JSD += jsd\n",
    "\n",
    "    predicted_values2 = []\n",
    "    total = 0\n",
    "    # 次に解ける可能性のある未解決の問題を見つける\n",
    "    for i in range(num_questions+1):\n",
    "        if state[i] == 0:  # まだ解けていない問題\n",
    "            # その問題が解けた状態を生成（遷移後の状態）\n",
    "            next_state = list(state)\n",
    "            next_state[i] = 1\n",
    "            next_state = tuple(next_state)\n",
    "            predicted_values2.append(state_counts[next_state])\n",
    "            total += state_counts[next_state]\n",
    "        else:\n",
    "            predicted_values2.append(0)\n",
    "    if total > 0:\n",
    "        predicted_values2 = np.array(predicted_values2) / total\n",
    "    # 評価指標の計算\n",
    "    kl2 = node_probabilities[state] * kl_divergence(probabilities, predicted_values2)\n",
    "    hd2 = node_probabilities[state] * hellinger_distance(probabilities, predicted_values2)\n",
    "    jsd2 = node_probabilities[state] * jensen_shannon_divergence(probabilities, predicted_values2)\n",
    "    # print(f\"状態: {state}, ノード分布: {node_probabilities[state]:.3g}, KL: {kl2:.3g}, HD: {hd2:.3g}, JSD: {jsd2:.3g}\")\n",
    "    # print(f\"真の遷移確率: {probabilities}, 予測遷移確率: {predicted_values2}\")\n",
    "    KL2 += kl2\n",
    "    HD2 += hd2\n",
    "    JSD2 += jsd2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## テスト"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test = np.array([1, 1, 0, 0, 0, 0], dtype=np.float32)\n",
    "\n",
    "# # numpy配列をtorch.Tensorに変換\n",
    "# test_tensor = torch.tensor(test, dtype=torch.float32)\n",
    "\n",
    "# model.eval()  # モデルを評価モードに\n",
    "\n",
    "# c_test = torch.ones(num_questions+1, dtype=torch.float32)\n",
    "# c_test = c_test - test_tensor  # 予算を更新\n",
    "\n",
    "# # モデルに入力を渡して出力を得る\n",
    "# output = model(test_tensor, c_test)\n",
    "# print(\"Output:\", output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### パラメータ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a Parameter containing:\n",
      "tensor([[     0.0008,     -0.0016,      0.0042,     -0.0016,     -0.0017,\n",
      "              0.0019,      0.0013,     -0.0006,     -0.0011,      0.0006,\n",
      "             -0.0010],\n",
      "        [     1.5535,      0.0011,      1.1788,      0.1698,      0.0014,\n",
      "             -0.0005,      0.0007,      0.0002,      0.0008,     -0.0003,\n",
      "              0.0008],\n",
      "        [     2.5109,      0.5276,      1.1669,      0.8719,      0.0001,\n",
      "              0.0011,     -0.0002,     -0.0006,      0.0005,     -0.0006,\n",
      "             -0.0004],\n",
      "        [     2.6496,      0.4911,      0.4446,      0.0008,      0.0001,\n",
      "              0.0003,     -0.0011,     -0.0003,     -0.0002,     -0.0002,\n",
      "             -0.0002],\n",
      "        [    -1.0069,      0.0006,      0.0004,      0.0006,      0.0004,\n",
      "             -0.0025,      0.0013,     -0.0004,     -0.0009,     -0.0006,\n",
      "             -0.0021],\n",
      "        [    -1.0802,      0.5952,      0.0931,      1.2321,     -0.0006,\n",
      "             -0.0005,      0.0011,      0.0006,      0.0006,     -0.0002,\n",
      "              0.0013],\n",
      "        [    -1.6652,      0.0009,     -0.0000,      0.0015,     -0.0030,\n",
      "              0.4856,     -0.0014,     -2.2562,     -0.0022,     -0.0012,\n",
      "              0.0002],\n",
      "        [    -2.0756,     -0.0013,     -0.0008,     -0.0028,      0.7310,\n",
      "              0.0048,      0.0064,      0.0008,     -0.0011,     -0.0011,\n",
      "             -0.0015],\n",
      "        [    -2.0709,     -0.2501,     -1.1371,     -0.5180,      0.0045,\n",
      "             -0.0005,      0.1276,      2.2176,      0.0015,      0.0010,\n",
      "             -0.0007],\n",
      "        [    -1.4906,     -1.0704,     -0.9841,     -1.5113,     -0.0000,\n",
      "             -0.3924,     -0.0002,     -0.0001,      0.0009,     -0.0003,\n",
      "             -0.0001],\n",
      "        [    -1.8963,     -0.9055,     -1.1094,     -1.6289,     -0.6468,\n",
      "             -0.7612,     -0.0835,     -0.4469,     -0.0006,     -0.0000,\n",
      "             -0.0004]], requires_grad=True)\n",
      "本来の依存関係\n",
      " [[0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0. ]\n",
      " [3.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0. ]\n",
      " [3.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0. ]\n",
      " [3.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0. ]\n",
      " [0.  1.5 1.5 0.  0.  0.  0.  0.  0.  0.  0. ]\n",
      " [0.  0.  1.5 1.5 0.  0.  0.  0.  0.  0.  0. ]\n",
      " [0.  0.  0.  0.  3.  0.  0.  0.  0.  0.  0. ]\n",
      " [0.  0.  0.  0.  0.  3.  0.  0.  0.  0.  0. ]\n",
      " [0.  0.  0.  0.  0.  0.  1.5 1.5 0.  0.  0. ]\n",
      " [0.  0.  0.  0.  0.  0.  0.  0.  3.  0.  0. ]\n",
      " [0.  0.  0.  0.  0.  0.  0.  0.  0.  3.  0. ]]\n"
     ]
    }
   ],
   "source": [
    "torch.set_printoptions(precision=4, sci_mode=False)# モデルの各パラメータを表示\n",
    "for param in model.parameters():\n",
    "    print(\"a\", param)\n",
    "\n",
    "print(\"本来の依存関係\\n\", A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 評価指標"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 図示"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])\n",
      "tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0), Probabilities: [0.         0.29864034 0.29864034 0.29864034 0.01486843 0.01486843\n",
      " 0.01486843 0.01486843 0.01486843 0.01486843 0.01486843], Predicted Values: tensor([0.0000, 0.1445, 0.3765, 0.4325, 0.0112, 0.0104, 0.0058, 0.0038, 0.0039,\n",
      "        0.0069, 0.0046], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0.])\n",
      "tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1), Probabilities: [0.         0.30314767 0.30314767 0.30314767 0.01509283 0.01509283\n",
      " 0.01509283 0.01509283 0.01509283 0.01509283 0.        ], Predicted Values: tensor([0.0000, 0.1453, 0.3781, 0.4345, 0.0112, 0.0104, 0.0058, 0.0038, 0.0039,\n",
      "        0.0069, 0.0000], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1.])\n",
      "tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0), Probabilities: [0.         0.23535308 0.23535308 0.23535308 0.01171754 0.01171754\n",
      " 0.01171754 0.01171754 0.01171754 0.         0.23535308], Predicted Values: tensor([0.0000, 0.1455, 0.3790, 0.4356, 0.0112, 0.0105, 0.0058, 0.0039, 0.0039,\n",
      "        0.0000, 0.0046], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1.])\n",
      "tensor([[1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0), Probabilities: [0.         0.23535308 0.23535308 0.23535308 0.01171754 0.01171754\n",
      " 0.01171754 0.01171754 0.         0.23535308 0.01171754], Predicted Values: tensor([0.0000, 0.1452, 0.3781, 0.4340, 0.0112, 0.0104, 0.0058, 0.0038, 0.0000,\n",
      "        0.0069, 0.0046], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1.])\n",
      "tensor([[1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0), Probabilities: [0.         0.288013   0.288013   0.288013   0.01433932 0.01433932\n",
      " 0.01433932 0.         0.06426439 0.01433932 0.01433932], Predicted Values: tensor([0.0000, 0.1416, 0.3687, 0.4237, 0.0109, 0.0102, 0.0006, 0.0000, 0.0347,\n",
      "        0.0067, 0.0029], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1.])\n",
      "tensor([[1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0), Probabilities: [0.         0.288013   0.288013   0.288013   0.01433932 0.01433932\n",
      " 0.         0.01433932 0.06426439 0.01433932 0.01433932], Predicted Values: tensor([0.0000, 0.1455, 0.3787, 0.4346, 0.0112, 0.0105, 0.0000, 0.0039, 0.0044,\n",
      "        0.0069, 0.0042], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1.])\n",
      "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0), Probabilities: [0.         0.23535308 0.23535308 0.23535308 0.01171754 0.\n",
      " 0.01171754 0.23535308 0.01171754 0.01171754 0.01171754], Predicted Values: tensor([0.0000, 0.1461, 0.3811, 0.4374, 0.0113, 0.0000, 0.0095, 0.0039, 0.0039,\n",
      "        0.0047, 0.0022], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1.])\n",
      "tensor([[1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0), Probabilities: [0.         0.23535308 0.23535308 0.23535308 0.         0.01171754\n",
      " 0.23535308 0.01171754 0.01171754 0.01171754 0.01171754], Predicted Values: tensor([0.0000, 0.1460, 0.3799, 0.4364, 0.0000, 0.0105, 0.0058, 0.0080, 0.0039,\n",
      "        0.0069, 0.0024], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1.])\n",
      "tensor([[1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0), Probabilities: [0.         0.39653389 0.39653389 0.         0.01974226 0.08847867\n",
      " 0.01974226 0.01974226 0.01974226 0.01974226 0.01974226], Predicted Values: tensor([    0.0000,     0.1512,     0.7949,     0.0000,     0.0099,     0.0314,\n",
      "            0.0051,     0.0034,     0.0020,     0.0013,     0.0008],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1.])\n",
      "tensor([[1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0), Probabilities: [0.         0.37103058 0.         0.37103058 0.08278811 0.08278811\n",
      " 0.01847252 0.01847252 0.01847252 0.01847252 0.01847252], Predicted Values: tensor([0.0000, 0.3975, 0.0000, 0.5708, 0.0095, 0.0096, 0.0049, 0.0032, 0.0010,\n",
      "        0.0022, 0.0013], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1.])\n",
      "tensor([[1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0), Probabilities: [0.         0.         0.39653389 0.39653389 0.08847867 0.01974226\n",
      " 0.01974226 0.01974226 0.01974226 0.01974226 0.01974226], Predicted Values: tensor([0.0000, 0.0000, 0.4585, 0.5078, 0.0080, 0.0135, 0.0042, 0.0028, 0.0022,\n",
      "        0.0017, 0.0013], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0.])\n",
      "tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1), Probabilities: [0.         0.30779314 0.30779314 0.30779314 0.01532412 0.01532412\n",
      " 0.01532412 0.01532412 0.01532412 0.         0.        ], Predicted Values: tensor([0.0000, 0.1463, 0.3807, 0.4376, 0.0113, 0.0105, 0.0058, 0.0039, 0.0039,\n",
      "        0.0000, 0.0000], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0.])\n",
      "tensor([[1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1), Probabilities: [0.         0.23814353 0.23814353 0.23814353 0.01185647 0.01185647\n",
      " 0.01185647 0.01185647 0.         0.23814353 0.        ], Predicted Values: tensor([0.0000, 0.1460, 0.3797, 0.4360, 0.0112, 0.0105, 0.0058, 0.0039, 0.0000,\n",
      "        0.0069, 0.0000], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1.])\n",
      "tensor([[1., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0), Probabilities: [0.         0.23814353 0.23814353 0.23814353 0.01185647 0.01185647\n",
      " 0.01185647 0.01185647 0.         0.         0.23814353], Predicted Values: tensor([0.0000, 0.1462, 0.3806, 0.4371, 0.0113, 0.0105, 0.0058, 0.0039, 0.0000,\n",
      "        0.0000, 0.0046], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0.])\n",
      "tensor([[1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1), Probabilities: [0.         0.29220299 0.29220299 0.29220299 0.01454793 0.01454793\n",
      " 0.01454793 0.         0.0651993  0.01454793 0.        ], Predicted Values: tensor([0.0000, 0.1422, 0.3697, 0.4249, 0.0109, 0.0102, 0.0006, 0.0000, 0.0348,\n",
      "        0.0068, 0.0000], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1.])\n",
      "tensor([[1., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0), Probabilities: [0.         0.22870257 0.22870257 0.22870257 0.01138643 0.01138643\n",
      " 0.01138643 0.         0.05103044 0.         0.22870257], Predicted Values: tensor([0.0000, 0.1426, 0.3711, 0.4266, 0.0110, 0.0102, 0.0006, 0.0000, 0.0350,\n",
      "        0.0000, 0.0029], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1.])\n",
      "tensor([[1., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0), Probabilities: [0.         0.23814353 0.23814353 0.23814353 0.01185647 0.01185647\n",
      " 0.01185647 0.         0.         0.23814353 0.01185647], Predicted Values: tensor([0.0000, 0.1468, 0.3820, 0.4387, 0.0113, 0.0105, 0.0006, 0.0000, 0.0000,\n",
      "        0.0070, 0.0030], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0.])\n",
      "tensor([[1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1), Probabilities: [0.         0.29220299 0.29220299 0.29220299 0.01454793 0.01454793\n",
      " 0.         0.01454793 0.0651993  0.01454793 0.        ], Predicted Values: tensor([0.0000, 0.1463, 0.3802, 0.4365, 0.0113, 0.0105, 0.0000, 0.0039, 0.0044,\n",
      "        0.0070, 0.0000], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1.])\n",
      "tensor([[1., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0), Probabilities: [0.         0.22870257 0.22870257 0.22870257 0.01138643 0.01138643\n",
      " 0.         0.01138643 0.05103044 0.         0.22870257], Predicted Values: tensor([0.0000, 0.1465, 0.3812, 0.4377, 0.0113, 0.0105, 0.0000, 0.0039, 0.0044,\n",
      "        0.0000, 0.0043], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1.])\n",
      "tensor([[1., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0), Probabilities: [0.         0.23814353 0.23814353 0.23814353 0.01185647 0.01185647\n",
      " 0.         0.01185647 0.         0.23814353 0.01185647], Predicted Values: tensor([0.0000, 0.1462, 0.3805, 0.4364, 0.0113, 0.0105, 0.0000, 0.0039, 0.0000,\n",
      "        0.0070, 0.0043], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1.])\n",
      "tensor([[1., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0), Probabilities: [0.         0.23814353 0.23814353 0.23814353 0.01185647 0.01185647\n",
      " 0.         0.         0.23814353 0.01185647 0.01185647], Predicted Values: tensor([0.0000, 0.1412, 0.3673, 0.4217, 0.0109, 0.0102, 0.0000, 0.0000, 0.0393,\n",
      "        0.0067, 0.0026], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0.])\n",
      "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1), Probabilities: [0.         0.23814353 0.23814353 0.23814353 0.01185647 0.\n",
      " 0.01185647 0.23814353 0.01185647 0.01185647 0.        ], Predicted Values: tensor([0.0000, 0.1465, 0.3818, 0.4384, 0.0113, 0.0000, 0.0095, 0.0039, 0.0039,\n",
      "        0.0047, 0.0000], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1.])\n",
      "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0), Probabilities: [0.         0.19419885 0.19419885 0.19419885 0.00966859 0.\n",
      " 0.00966859 0.19419885 0.00966859 0.         0.19419885], Predicted Values: tensor([0.0000, 0.1468, 0.3828, 0.4396, 0.0113, 0.0000, 0.0095, 0.0039, 0.0039,\n",
      "        0.0000, 0.0022], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1.])\n",
      "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0), Probabilities: [0.         0.19419885 0.19419885 0.19419885 0.00966859 0.\n",
      " 0.00966859 0.19419885 0.         0.19419885 0.00966859], Predicted Values: tensor([0.0000, 0.1467, 0.3827, 0.4390, 0.0113, 0.0000, 0.0095, 0.0039, 0.0000,\n",
      "        0.0047, 0.0022], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1.])\n",
      "tensor([[1., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0), Probabilities: [0.         0.29220299 0.29220299 0.29220299 0.01454793 0.\n",
      " 0.01454793 0.         0.0651993  0.01454793 0.01454793], Predicted Values: tensor([0.0000, 0.1434, 0.3740, 0.4294, 0.0111, 0.0000, 0.0010, 0.0000, 0.0351,\n",
      "        0.0046, 0.0014], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1.])\n",
      "tensor([[1., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0), Probabilities: [0.         0.22870257 0.22870257 0.22870257 0.01138643 0.\n",
      " 0.         0.22870257 0.05103044 0.01138643 0.01138643], Predicted Values: tensor([0.0000, 0.1476, 0.3847, 0.4412, 0.0114, 0.0000, 0.0000, 0.0040, 0.0045,\n",
      "        0.0047, 0.0020], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0.])\n",
      "tensor([[1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1), Probabilities: [0.         0.23814353 0.23814353 0.23814353 0.         0.01185647\n",
      " 0.23814353 0.01185647 0.01185647 0.01185647 0.        ], Predicted Values: tensor([0.0000, 0.1465, 0.3808, 0.4375, 0.0000, 0.0105, 0.0058, 0.0080, 0.0039,\n",
      "        0.0070, 0.0000], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1.])\n",
      "tensor([[1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0), Probabilities: [0.         0.19419885 0.19419885 0.19419885 0.         0.00966859\n",
      " 0.19419885 0.00966859 0.00966859 0.         0.19419885], Predicted Values: tensor([0.0000, 0.1471, 0.3825, 0.4396, 0.0000, 0.0105, 0.0059, 0.0081, 0.0039,\n",
      "        0.0000, 0.0024], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.])\n",
      "tensor([[1., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0), Probabilities: [0.         0.19419885 0.19419885 0.19419885 0.         0.00966859\n",
      " 0.19419885 0.00966859 0.         0.19419885 0.00966859], Predicted Values: tensor([0.0000, 0.1467, 0.3815, 0.4380, 0.0000, 0.0105, 0.0058, 0.0081, 0.0000,\n",
      "        0.0070, 0.0024], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1.])\n",
      "tensor([[1., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0), Probabilities: [0.         0.22870257 0.22870257 0.22870257 0.         0.01138643\n",
      " 0.22870257 0.         0.05103044 0.01138643 0.01138643], Predicted Values: tensor([0.0000, 0.1435, 0.3732, 0.4288, 0.0000, 0.0103, 0.0006, 0.0000, 0.0353,\n",
      "        0.0068, 0.0015], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "tensor([[1., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0), Probabilities: [0.         0.29220299 0.29220299 0.29220299 0.         0.01454793\n",
      " 0.         0.01454793 0.0651993  0.01454793 0.01454793], Predicted Values: tensor([0.0000, 0.1470, 0.3821, 0.4385, 0.0000, 0.0105, 0.0000, 0.0081, 0.0045,\n",
      "        0.0070, 0.0022], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1.])\n",
      "tensor([[1., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0), Probabilities: [0.         0.19419885 0.19419885 0.19419885 0.         0.\n",
      " 0.19419885 0.19419885 0.00966859 0.00966859 0.00966859], Predicted Values: tensor([0.0000, 0.1474, 0.3841, 0.4409, 0.0000, 0.0000, 0.0095, 0.0082, 0.0039,\n",
      "        0.0047, 0.0011], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0.])\n",
      "tensor([[1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1), Probabilities: [0.         0.40452003 0.40452003 0.         0.02013987 0.09026062\n",
      " 0.02013987 0.02013987 0.02013987 0.02013987 0.        ], Predicted Values: tensor([0.0000, 0.1515, 0.7953, 0.0000, 0.0099, 0.0315, 0.0051, 0.0034, 0.0020,\n",
      "        0.0013, 0.0000], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1.])\n",
      "tensor([[1., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0), Probabilities: [0.         0.29220299 0.29220299 0.         0.01454793 0.0651993\n",
      " 0.01454793 0.01454793 0.01454793 0.         0.29220299], Predicted Values: tensor([0.0000, 0.1514, 0.7959, 0.0000, 0.0099, 0.0315, 0.0051, 0.0034, 0.0020,\n",
      "        0.0000, 0.0008], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1.])\n",
      "tensor([[1., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0), Probabilities: [0.         0.29220299 0.29220299 0.         0.01454793 0.0651993\n",
      " 0.01454793 0.01454793 0.         0.29220299 0.01454793], Predicted Values: tensor([    0.0000,     0.1515,     0.7965,     0.0000,     0.0099,     0.0315,\n",
      "            0.0051,     0.0034,     0.0000,     0.0013,     0.0008],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1.])\n",
      "tensor([[1., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0), Probabilities: [0.         0.37801344 0.37801344 0.         0.01882018 0.0843462\n",
      " 0.01882018 0.         0.0843462  0.01882018 0.01882018], Predicted Values: tensor([    0.0000,     0.1500,     0.7882,     0.0000,     0.0098,     0.0312,\n",
      "            0.0005,     0.0000,     0.0185,     0.0013,     0.0005],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1.])\n",
      "tensor([[1., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0), Probabilities: [0.         0.37801344 0.37801344 0.         0.01882018 0.0843462\n",
      " 0.         0.01882018 0.0843462  0.01882018 0.01882018], Predicted Values: tensor([    0.0000,     0.1521,     0.7986,     0.0000,     0.0099,     0.0316,\n",
      "            0.0000,     0.0034,     0.0023,     0.0013,     0.0007],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1.])\n",
      "tensor([[1., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0), Probabilities: [0.         0.30779314 0.30779314 0.         0.01532412 0.\n",
      " 0.01532412 0.30779314 0.01532412 0.01532412 0.01532412], Predicted Values: tensor([    0.0000,     0.1555,     0.8189,     0.0000,     0.0101,     0.0000,\n",
      "            0.0085,     0.0035,     0.0021,     0.0009,     0.0004],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1.])\n",
      "tensor([[1., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0), Probabilities: [0.         0.29220299 0.29220299 0.         0.         0.0651993\n",
      " 0.29220299 0.01454793 0.01454793 0.01454793 0.01454793], Predicted Values: tensor([    0.0000,     0.1524,     0.8000,     0.0000,     0.0000,     0.0316,\n",
      "            0.0051,     0.0071,     0.0020,     0.0013,     0.0004],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0.])\n",
      "tensor([[1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1), Probabilities: [0.         0.37801344 0.         0.37801344 0.0843462  0.0843462\n",
      " 0.01882018 0.01882018 0.01882018 0.01882018 0.        ], Predicted Values: tensor([0.0000, 0.3982, 0.0000, 0.5713, 0.0094, 0.0097, 0.0049, 0.0032, 0.0010,\n",
      "        0.0022, 0.0000], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1.])\n",
      "tensor([[1., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0), Probabilities: [0.         0.27811603 0.         0.27811603 0.06205608 0.06205608\n",
      " 0.01384658 0.01384658 0.01384658 0.         0.27811603], Predicted Values: tensor([0.0000, 0.3983, 0.0000, 0.5721, 0.0095, 0.0097, 0.0049, 0.0032, 0.0010,\n",
      "        0.0000, 0.0013], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1.])\n",
      "tensor([[1., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0), Probabilities: [0.         0.27811603 0.         0.27811603 0.06205608 0.06205608\n",
      " 0.01384658 0.01384658 0.         0.27811603 0.01384658], Predicted Values: tensor([0.0000, 0.3981, 0.0000, 0.5712, 0.0095, 0.0097, 0.0049, 0.0032, 0.0000,\n",
      "        0.0022, 0.0013], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1.])\n",
      "tensor([[1., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0), Probabilities: [0.         0.35476697 0.         0.35476697 0.07915921 0.07915921\n",
      " 0.01766281 0.         0.07915921 0.01766281 0.01766281], Predicted Values: tensor([    0.0000,     0.3974,     0.0000,     0.5704,     0.0094,     0.0096,\n",
      "            0.0005,     0.0000,     0.0096,     0.0022,     0.0008],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1.])\n",
      "tensor([[1., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0), Probabilities: [0.         0.35476697 0.         0.35476697 0.07915921 0.07915921\n",
      " 0.         0.01766281 0.07915921 0.01766281 0.01766281], Predicted Values: tensor([0.0000, 0.3998, 0.0000, 0.5731, 0.0095, 0.0097, 0.0000, 0.0033, 0.0012,\n",
      "        0.0022, 0.0012], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1.])\n",
      "tensor([[1., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0), Probabilities: [0.         0.29220299 0.         0.29220299 0.0651993  0.\n",
      " 0.01454793 0.29220299 0.01454793 0.01454793 0.01454793], Predicted Values: tensor([0.0000, 0.4005, 0.0000, 0.5756, 0.0095, 0.0000, 0.0080, 0.0033, 0.0011,\n",
      "        0.0015, 0.0006], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1.])\n",
      "tensor([[1., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0), Probabilities: [0.         0.29220299 0.         0.29220299 0.         0.0651993\n",
      " 0.29220299 0.01454793 0.01454793 0.01454793 0.01454793], Predicted Values: tensor([0.0000, 0.4004, 0.0000, 0.5743, 0.0000, 0.0097, 0.0049, 0.0068, 0.0011,\n",
      "        0.0022, 0.0007], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1.])\n",
      "tensor([[1., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0), Probabilities: [0.         0.40452003 0.         0.         0.09026062 0.40452003\n",
      " 0.02013987 0.02013987 0.02013987 0.02013987 0.02013987], Predicted Values: tensor([    0.0000,     0.9006,     0.0000,     0.0000,     0.0181,     0.0632,\n",
      "            0.0094,     0.0062,     0.0012,     0.0009,     0.0005],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0.])\n",
      "tensor([[1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1), Probabilities: [0.         0.         0.40452003 0.40452003 0.09026062 0.02013987\n",
      " 0.02013987 0.02013987 0.02013987 0.02013987 0.        ], Predicted Values: tensor([0.0000, 0.0000, 0.4591, 0.5085, 0.0080, 0.0136, 0.0042, 0.0028, 0.0022,\n",
      "        0.0017, 0.0000], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1.])\n",
      "tensor([[1., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0), Probabilities: [0.         0.         0.29220299 0.29220299 0.0651993  0.01454793\n",
      " 0.01454793 0.01454793 0.01454793 0.         0.29220299], Predicted Values: tensor([0.0000, 0.0000, 0.4592, 0.5088, 0.0080, 0.0135, 0.0042, 0.0028, 0.0022,\n",
      "        0.0000, 0.0013], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1.])\n",
      "tensor([[1., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0), Probabilities: [0.         0.         0.29220299 0.29220299 0.0651993  0.01454793\n",
      " 0.01454793 0.01454793 0.         0.29220299 0.01454793], Predicted Values: tensor([0.0000, 0.0000, 0.4597, 0.5088, 0.0080, 0.0136, 0.0042, 0.0028, 0.0000,\n",
      "        0.0017, 0.0013], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1.])\n",
      "tensor([[1., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0), Probabilities: [0.         0.         0.37801344 0.37801344 0.0843462  0.01882018\n",
      " 0.01882018 0.         0.0843462  0.01882018 0.01882018], Predicted Values: tensor([    0.0000,     0.0000,     0.4536,     0.5025,     0.0079,     0.0134,\n",
      "            0.0004,     0.0000,     0.0196,     0.0017,     0.0008],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1.])\n",
      "tensor([[1., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0), Probabilities: [0.         0.         0.37801344 0.37801344 0.0843462  0.01882018\n",
      " 0.         0.01882018 0.0843462  0.01882018 0.01882018], Predicted Values: tensor([0.0000, 0.0000, 0.4605, 0.5096, 0.0081, 0.0136, 0.0000, 0.0028, 0.0025,\n",
      "        0.0017, 0.0012], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1.])\n",
      "tensor([[1., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0), Probabilities: [0.         0.         0.29220299 0.29220299 0.0651993  0.\n",
      " 0.01454793 0.29220299 0.01454793 0.01454793 0.01454793], Predicted Values: tensor([0.0000, 0.0000, 0.4644, 0.5139, 0.0081, 0.0000, 0.0068, 0.0028, 0.0022,\n",
      "        0.0012, 0.0006], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1.])\n",
      "tensor([[1., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0), Probabilities: [0.         0.         0.30779314 0.30779314 0.         0.01532412\n",
      " 0.30779314 0.01532412 0.01532412 0.01532412 0.01532412], Predicted Values: tensor([0.0000, 0.0000, 0.4612, 0.5108, 0.0000, 0.0136, 0.0042, 0.0058, 0.0022,\n",
      "        0.0017, 0.0007], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1.])\n",
      "tensor([[1., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0), Probabilities: [0.         0.         0.58990241 0.         0.13162502 0.13162502\n",
      " 0.02936951 0.02936951 0.02936951 0.02936951 0.02936951], Predicted Values: tensor([    0.0000,     0.0000,     0.9455,     0.0000,     0.0069,     0.0400,\n",
      "            0.0036,     0.0024,     0.0011,     0.0003,     0.0002],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1.])\n",
      "tensor([[1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0), Probabilities: [0.         0.         0.         0.40452003 0.40452003 0.09026062\n",
      " 0.02013987 0.02013987 0.02013987 0.02013987 0.02013987], Predicted Values: tensor([    0.0000,     0.0000,     0.0000,     0.9617,     0.0098,     0.0180,\n",
      "            0.0050,     0.0033,     0.0008,     0.0008,     0.0005],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0.])\n",
      "tensor([[1., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1), Probabilities: [0.        0.3125832 0.3125832 0.3125832 0.0155626 0.0155626 0.0155626\n",
      " 0.0155626 0.        0.        0.       ], Predicted Values: tensor([0.0000, 0.1470, 0.3823, 0.4391, 0.0113, 0.0106, 0.0059, 0.0039, 0.0000,\n",
      "        0.0000, 0.0000], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0.])\n",
      "tensor([[1., 0., 0., 0., 0., 0., 0., 1., 0., 1., 1.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1), Probabilities: [0.         0.2965167  0.2965167  0.2965167  0.0147627  0.0147627\n",
      " 0.0147627  0.         0.06616182 0.         0.        ], Predicted Values: tensor([0.0000, 0.1431, 0.3721, 0.4278, 0.0110, 0.0103, 0.0006, 0.0000, 0.0350,\n",
      "        0.0000, 0.0000], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 1., 1., 1., 1., 1., 0., 0., 1., 0.])\n",
      "tensor([[1., 0., 0., 0., 0., 0., 0., 1., 1., 0., 1.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1), Probabilities: [0.         0.24100095 0.24100095 0.24100095 0.01199873 0.01199873\n",
      " 0.01199873 0.         0.         0.24100095 0.        ], Predicted Values: tensor([0.0000, 0.1474, 0.3831, 0.4400, 0.0113, 0.0106, 0.0006, 0.0000, 0.0000,\n",
      "        0.0070, 0.0000], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1.])\n",
      "tensor([[1., 0., 0., 0., 0., 0., 0., 1., 1., 1., 0.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0), Probabilities: [0.         0.24100095 0.24100095 0.24100095 0.01199873 0.01199873\n",
      " 0.01199873 0.         0.         0.         0.24100095], Predicted Values: tensor([0.0000, 0.1479, 0.3846, 0.4419, 0.0114, 0.0106, 0.0006, 0.0000, 0.0000,\n",
      "        0.0000, 0.0030], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0.])\n",
      "tensor([[1., 0., 0., 0., 0., 0., 1., 0., 0., 1., 1.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1), Probabilities: [0.         0.2965167  0.2965167  0.2965167  0.0147627  0.0147627\n",
      " 0.         0.0147627  0.06616182 0.         0.        ], Predicted Values: tensor([0.0000, 0.1473, 0.3828, 0.4396, 0.0114, 0.0106, 0.0000, 0.0039, 0.0045,\n",
      "        0.0000, 0.0000], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 1., 1., 1., 1., 0., 1., 0., 1., 0.])\n",
      "tensor([[1., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1), Probabilities: [0.         0.24100095 0.24100095 0.24100095 0.01199873 0.01199873\n",
      " 0.         0.01199873 0.         0.24100095 0.        ], Predicted Values: tensor([0.0000, 0.1470, 0.3820, 0.4382, 0.0113, 0.0106, 0.0000, 0.0039, 0.0000,\n",
      "        0.0070, 0.0000], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 1., 1., 1., 1., 0., 1., 0., 0., 1.])\n",
      "tensor([[1., 0., 0., 0., 0., 0., 1., 0., 1., 1., 0.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0), Probabilities: [0.         0.24100095 0.24100095 0.24100095 0.01199873 0.01199873\n",
      " 0.         0.01199873 0.         0.         0.24100095], Predicted Values: tensor([0.0000, 0.1473, 0.3831, 0.4395, 0.0114, 0.0106, 0.0000, 0.0039, 0.0000,\n",
      "        0.0000, 0.0043], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 1., 1., 1., 1., 0., 0., 1., 1., 0.])\n",
      "tensor([[1., 0., 0., 0., 0., 0., 1., 1., 0., 0., 1.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1), Probabilities: [0.         0.24100095 0.24100095 0.24100095 0.01199873 0.01199873\n",
      " 0.         0.         0.24100095 0.01199873 0.        ], Predicted Values: tensor([0.0000, 0.1417, 0.3682, 0.4228, 0.0109, 0.0102, 0.0000, 0.0000, 0.0394,\n",
      "        0.0067, 0.0000], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 1., 1., 1., 1., 0., 0., 1., 0., 1.])\n",
      "tensor([[1., 0., 0., 0., 0., 0., 1., 1., 0., 1., 0.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0), Probabilities: [0.         0.19609481 0.19609481 0.19609481 0.00976299 0.00976299\n",
      " 0.         0.         0.19609481 0.         0.19609481], Predicted Values: tensor([0.0000, 0.1422, 0.3697, 0.4246, 0.0110, 0.0102, 0.0000, 0.0000, 0.0396,\n",
      "        0.0000, 0.0027], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1.])\n",
      "tensor([[1., 0., 0., 0., 0., 0., 1., 1., 1., 0., 0.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0), Probabilities: [0.         0.24100095 0.24100095 0.24100095 0.01199873 0.01199873\n",
      " 0.         0.         0.         0.24100095 0.01199873], Predicted Values: tensor([0.0000, 0.1471, 0.3825, 0.4388, 0.0113, 0.0106, 0.0000, 0.0000, 0.0000,\n",
      "        0.0070, 0.0027], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0.])\n",
      "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1), Probabilities: [0.         0.24100095 0.24100095 0.24100095 0.01199873 0.\n",
      " 0.01199873 0.24100095 0.01199873 0.         0.        ], Predicted Values: tensor([0.0000, 0.1472, 0.3836, 0.4405, 0.0113, 0.0000, 0.0096, 0.0039, 0.0039,\n",
      "        0.0000, 0.0000], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 0.])\n",
      "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 1., 0., 1.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1), Probabilities: [0.         0.19609481 0.19609481 0.19609481 0.00976299 0.\n",
      " 0.00976299 0.19609481 0.         0.19609481 0.        ], Predicted Values: tensor([0.0000, 0.1472, 0.3835, 0.4399, 0.0113, 0.0000, 0.0095, 0.0039, 0.0000,\n",
      "        0.0047, 0.0000], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1.])\n",
      "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 1., 1., 0.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0), Probabilities: [0.         0.19609481 0.19609481 0.19609481 0.00976299 0.\n",
      " 0.00976299 0.19609481 0.         0.         0.19609481], Predicted Values: tensor([0.0000, 0.1474, 0.3844, 0.4411, 0.0113, 0.0000, 0.0096, 0.0039, 0.0000,\n",
      "        0.0000, 0.0022], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 1., 1., 1., 0., 1., 0., 1., 1., 0.])\n",
      "tensor([[1., 0., 0., 0., 0., 1., 0., 1., 0., 0., 1.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1), Probabilities: [0.         0.2965167  0.2965167  0.2965167  0.0147627  0.\n",
      " 0.0147627  0.         0.06616182 0.0147627  0.        ], Predicted Values: tensor([0.0000, 0.1438, 0.3744, 0.4300, 0.0110, 0.0000, 0.0010, 0.0000, 0.0352,\n",
      "        0.0046, 0.0000], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 1., 1., 1., 0., 1., 0., 1., 0., 1.])\n",
      "tensor([[1., 0., 0., 0., 0., 1., 0., 1., 0., 1., 0.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0), Probabilities: [0.         0.23133667 0.23133667 0.23133667 0.01151757 0.\n",
      " 0.01151757 0.         0.05161819 0.         0.23133667], Predicted Values: tensor([0.0000, 0.1441, 0.3756, 0.4315, 0.0111, 0.0000, 0.0010, 0.0000, 0.0353,\n",
      "        0.0000, 0.0014], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 1., 1., 1., 0., 1., 0., 0., 1., 1.])\n",
      "tensor([[1., 0., 0., 0., 0., 1., 0., 1., 1., 0., 0.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0), Probabilities: [0.         0.24100095 0.24100095 0.24100095 0.01199873 0.\n",
      " 0.01199873 0.         0.         0.24100095 0.01199873], Predicted Values: tensor([0.0000, 0.1488, 0.3877, 0.4449, 0.0114, 0.0000, 0.0010, 0.0000, 0.0000,\n",
      "        0.0048, 0.0014], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 1., 1., 1., 0., 0., 1., 1., 1., 0.])\n",
      "tensor([[1., 0., 0., 0., 0., 1., 1., 0., 0., 0., 1.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1), Probabilities: [0.         0.23133667 0.23133667 0.23133667 0.01151757 0.\n",
      " 0.         0.23133667 0.05161819 0.01151757 0.        ], Predicted Values: tensor([0.0000, 0.1480, 0.3854, 0.4420, 0.0114, 0.0000, 0.0000, 0.0040, 0.0045,\n",
      "        0.0048, 0.0000], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 1., 1., 1., 0., 0., 1., 1., 0., 1.])\n",
      "tensor([[1., 0., 0., 0., 0., 1., 1., 0., 0., 1., 0.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0), Probabilities: [0.         0.18964834 0.18964834 0.18964834 0.00944203 0.\n",
      " 0.         0.18964834 0.04231626 0.         0.18964834], Predicted Values: tensor([0.0000, 0.1483, 0.3864, 0.4433, 0.0114, 0.0000, 0.0000, 0.0040, 0.0045,\n",
      "        0.0000, 0.0020], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 1., 1., 1., 0., 0., 1., 0., 1., 1.])\n",
      "tensor([[1., 0., 0., 0., 0., 1., 1., 0., 1., 0., 0.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0), Probabilities: [0.         0.19609481 0.19609481 0.19609481 0.00976299 0.\n",
      " 0.         0.19609481 0.         0.19609481 0.00976299], Predicted Values: tensor([0.0000, 0.1483, 0.3865, 0.4430, 0.0114, 0.0000, 0.0000, 0.0040, 0.0000,\n",
      "        0.0048, 0.0020], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1.])\n",
      "tensor([[1., 0., 0., 0., 0., 1., 1., 1., 0., 0., 0.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0), Probabilities: [0.         0.24100095 0.24100095 0.24100095 0.01199873 0.\n",
      " 0.         0.         0.24100095 0.01199873 0.01199873], Predicted Values: tensor([0.0000, 0.1431, 0.3727, 0.4276, 0.0110, 0.0000, 0.0000, 0.0000, 0.0398,\n",
      "        0.0046, 0.0012], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 1., 1., 0., 1., 1., 1., 1., 0., 0.])\n",
      "tensor([[1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1), Probabilities: [0.         0.24100095 0.24100095 0.24100095 0.         0.01199873\n",
      " 0.24100095 0.01199873 0.01199873 0.         0.        ], Predicted Values: tensor([0.0000, 0.1476, 0.3833, 0.4406, 0.0000, 0.0106, 0.0059, 0.0081, 0.0039,\n",
      "        0.0000, 0.0000], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 0.])\n",
      "tensor([[1., 0., 0., 0., 1., 0., 0., 0., 1., 0., 1.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1), Probabilities: [0.         0.19609481 0.19609481 0.19609481 0.         0.00976299\n",
      " 0.19609481 0.00976299 0.         0.19609481 0.        ], Predicted Values: tensor([0.0000, 0.1472, 0.3824, 0.4390, 0.0000, 0.0106, 0.0058, 0.0081, 0.0000,\n",
      "        0.0070, 0.0000], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1.])\n",
      "tensor([[1., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0), Probabilities: [0.         0.19609481 0.19609481 0.19609481 0.         0.00976299\n",
      " 0.19609481 0.00976299 0.         0.         0.19609481], Predicted Values: tensor([0.0000, 0.1477, 0.3841, 0.4411, 0.0000, 0.0106, 0.0059, 0.0081, 0.0000,\n",
      "        0.0000, 0.0025], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 1., 1., 0., 1., 1., 0., 1., 1., 0.])\n",
      "tensor([[1., 0., 0., 0., 1., 0., 0., 1., 0., 0., 1.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1), Probabilities: [0.         0.23133667 0.23133667 0.23133667 0.         0.01151757\n",
      " 0.23133667 0.         0.05161819 0.01151757 0.        ], Predicted Values: tensor([0.0000, 0.1439, 0.3736, 0.4294, 0.0000, 0.0103, 0.0006, 0.0000, 0.0353,\n",
      "        0.0068, 0.0000], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 1., 1., 0., 1., 1., 0., 1., 0., 1.])\n",
      "tensor([[1., 0., 0., 0., 1., 0., 0., 1., 0., 1., 0.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0), Probabilities: [0.         0.18964834 0.18964834 0.18964834 0.         0.00944203\n",
      " 0.18964834 0.         0.04231626 0.         0.18964834], Predicted Values: tensor([0.0000, 0.1445, 0.3756, 0.4318, 0.0000, 0.0104, 0.0006, 0.0000, 0.0355,\n",
      "        0.0000, 0.0015], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1.])\n",
      "tensor([[1., 0., 0., 0., 1., 0., 0., 1., 1., 0., 0.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0), Probabilities: [0.         0.19609481 0.19609481 0.19609481 0.         0.00976299\n",
      " 0.19609481 0.         0.         0.19609481 0.00976299], Predicted Values: tensor([0.0000, 0.1489, 0.3869, 0.4443, 0.0000, 0.0107, 0.0006, 0.0000, 0.0000,\n",
      "        0.0071, 0.0016], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 1., 1., 0., 1., 0., 1., 1., 1., 0.])\n",
      "tensor([[1., 0., 0., 0., 1., 0., 1., 0., 0., 0., 1.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1), Probabilities: [0.         0.2965167  0.2965167  0.2965167  0.         0.0147627\n",
      " 0.         0.0147627  0.06616182 0.0147627  0.        ], Predicted Values: tensor([0.0000, 0.1475, 0.3829, 0.4395, 0.0000, 0.0106, 0.0000, 0.0081, 0.0045,\n",
      "        0.0070, 0.0000], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 1., 1., 0., 1., 0., 1., 1., 0., 1.])\n",
      "tensor([[1., 0., 0., 0., 1., 0., 1., 0., 0., 1., 0.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0), Probabilities: [0.         0.23133667 0.23133667 0.23133667 0.         0.01151757\n",
      " 0.         0.01151757 0.05161819 0.         0.23133667], Predicted Values: tensor([0.0000, 0.1480, 0.3847, 0.4417, 0.0000, 0.0106, 0.0000, 0.0082, 0.0045,\n",
      "        0.0000, 0.0023], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 1., 1., 0., 1., 0., 1., 0., 1., 1.])\n",
      "tensor([[1., 0., 0., 0., 1., 0., 1., 0., 1., 0., 0.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0), Probabilities: [0.         0.24100095 0.24100095 0.24100095 0.         0.01199873\n",
      " 0.         0.01199873 0.         0.24100095 0.01199873], Predicted Values: tensor([0.0000, 0.1477, 0.3839, 0.4403, 0.0000, 0.0106, 0.0000, 0.0082, 0.0000,\n",
      "        0.0070, 0.0023], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 1., 1., 0., 1., 0., 0., 1., 1., 1.])\n",
      "tensor([[1., 0., 0., 0., 1., 0., 1., 1., 0., 0., 0.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0), Probabilities: [0.         0.24100095 0.24100095 0.24100095 0.         0.01199873\n",
      " 0.         0.         0.24100095 0.01199873 0.01199873], Predicted Values: tensor([0.0000, 0.1431, 0.3717, 0.4268, 0.0000, 0.0103, 0.0000, 0.0000, 0.0399,\n",
      "        0.0068, 0.0014], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0.])\n",
      "tensor([[1., 0., 0., 0., 1., 1., 0., 0., 0., 0., 1.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1), Probabilities: [0.         0.19609481 0.19609481 0.19609481 0.         0.\n",
      " 0.19609481 0.19609481 0.00976299 0.00976299 0.        ], Predicted Values: tensor([0.0000, 0.1477, 0.3845, 0.4414, 0.0000, 0.0000, 0.0096, 0.0082, 0.0039,\n",
      "        0.0047, 0.0000], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 1., 1., 0., 0., 1., 1., 1., 0., 1.])\n",
      "tensor([[1., 0., 0., 0., 1., 1., 0., 0., 0., 1., 0.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0), Probabilities: [0.         0.16529507 0.16529507 0.16529507 0.         0.\n",
      " 0.16529507 0.16529507 0.00822956 0.         0.16529507], Predicted Values: tensor([0.0000, 0.1481, 0.3859, 0.4431, 0.0000, 0.0000, 0.0096, 0.0082, 0.0040,\n",
      "        0.0000, 0.0011], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 1., 1., 0., 0., 1., 1., 0., 1., 1.])\n",
      "tensor([[1., 0., 0., 0., 1., 1., 0., 0., 1., 0., 0.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0), Probabilities: [0.         0.16529507 0.16529507 0.16529507 0.         0.\n",
      " 0.16529507 0.16529507 0.         0.16529507 0.00822956], Predicted Values: tensor([0.0000, 0.1481, 0.3858, 0.4425, 0.0000, 0.0000, 0.0096, 0.0082, 0.0000,\n",
      "        0.0048, 0.0011], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 1., 1., 0., 0., 1., 0., 1., 1., 1.])\n",
      "tensor([[1., 0., 0., 0., 1., 1., 0., 1., 0., 0., 0.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0), Probabilities: [0.         0.23133667 0.23133667 0.23133667 0.         0.\n",
      " 0.23133667 0.         0.05161819 0.01151757 0.01151757], Predicted Values: tensor([0.0000, 0.1453, 0.3783, 0.4344, 0.0000, 0.0000, 0.0010, 0.0000, 0.0357,\n",
      "        0.0047, 0.0007], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1.])\n",
      "tensor([[1., 0., 0., 0., 1., 1., 1., 0., 0., 0., 0.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0), Probabilities: [0.         0.23133667 0.23133667 0.23133667 0.         0.\n",
      " 0.         0.23133667 0.05161819 0.01151757 0.01151757], Predicted Values: tensor([0.0000, 0.1489, 0.3877, 0.4447, 0.0000, 0.0000, 0.0000, 0.0083, 0.0045,\n",
      "        0.0048, 0.0011], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 1., 0., 1., 1., 1., 1., 1., 0., 0.])\n",
      "tensor([[1., 0., 0., 1., 0., 0., 0., 0., 0., 1., 1.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1), Probabilities: [0.         0.41283446 0.41283446 0.         0.02055382 0.09211582\n",
      " 0.02055382 0.02055382 0.02055382 0.         0.        ], Predicted Values: tensor([0.0000, 0.1517, 0.7964, 0.0000, 0.0099, 0.0315, 0.0051, 0.0034, 0.0020,\n",
      "        0.0000, 0.0000], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 1., 0., 1., 1., 1., 1., 0., 1., 0.])\n",
      "tensor([[1., 0., 0., 1., 0., 0., 0., 0., 1., 0., 1.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1), Probabilities: [0.         0.2965167  0.2965167  0.         0.0147627  0.06616182\n",
      " 0.0147627  0.0147627  0.         0.2965167  0.        ], Predicted Values: tensor([0.0000, 0.1518, 0.7969, 0.0000, 0.0099, 0.0316, 0.0051, 0.0034, 0.0000,\n",
      "        0.0013, 0.0000], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1.])\n",
      "tensor([[1., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0), Probabilities: [0.         0.2965167  0.2965167  0.         0.0147627  0.06616182\n",
      " 0.0147627  0.0147627  0.         0.         0.2965167 ], Predicted Values: tensor([    0.0000,     0.1518,     0.7975,     0.0000,     0.0099,     0.0315,\n",
      "            0.0051,     0.0034,     0.0000,     0.0000,     0.0008],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 0.])\n",
      "tensor([[1., 0., 0., 1., 0., 0., 0., 1., 0., 0., 1.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1), Probabilities: [0.         0.38526418 0.38526418 0.         0.01918117 0.08596406\n",
      " 0.01918117 0.         0.08596406 0.01918117 0.        ], Predicted Values: tensor([    0.0000,     0.1502,     0.7884,     0.0000,     0.0098,     0.0312,\n",
      "            0.0005,     0.0000,     0.0185,     0.0013,     0.0000],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1.])\n",
      "tensor([[1., 0., 0., 1., 0., 0., 0., 1., 0., 1., 0.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0), Probabilities: [0.         0.28202106 0.28202106 0.         0.014041   0.0629274\n",
      " 0.014041   0.         0.0629274  0.         0.28202106], Predicted Values: tensor([    0.0000,     0.1503,     0.7891,     0.0000,     0.0098,     0.0312,\n",
      "            0.0005,     0.0000,     0.0185,     0.0000,     0.0005],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 1., 0., 1., 1., 1., 0., 0., 1., 1.])\n",
      "tensor([[1., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0), Probabilities: [0.         0.2965167  0.2965167  0.         0.0147627  0.06616182\n",
      " 0.0147627  0.         0.         0.2965167  0.0147627 ], Predicted Values: tensor([    0.0000,     0.1529,     0.8030,     0.0000,     0.0100,     0.0318,\n",
      "            0.0005,     0.0000,     0.0000,     0.0014,     0.0005],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0.])\n",
      "tensor([[1., 0., 0., 1., 0., 0., 1., 0., 0., 0., 1.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1), Probabilities: [0.         0.38526418 0.38526418 0.         0.01918117 0.08596406\n",
      " 0.         0.01918117 0.08596406 0.01918117 0.        ], Predicted Values: tensor([0.0000, 0.1523, 0.7990, 0.0000, 0.0099, 0.0317, 0.0000, 0.0034, 0.0023,\n",
      "        0.0013, 0.0000], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 1., 0., 1., 1., 0., 1., 1., 0., 1.])\n",
      "tensor([[1., 0., 0., 1., 0., 0., 1., 0., 0., 1., 0.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0), Probabilities: [0.         0.28202106 0.28202106 0.         0.014041   0.0629274\n",
      " 0.         0.014041   0.0629274  0.         0.28202106], Predicted Values: tensor([    0.0000,     0.1523,     0.7996,     0.0000,     0.0099,     0.0317,\n",
      "            0.0000,     0.0034,     0.0023,     0.0000,     0.0007],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 1., 0., 1., 1., 0., 1., 0., 1., 1.])\n",
      "tensor([[1., 0., 0., 1., 0., 0., 1., 0., 1., 0., 0.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0), Probabilities: [0.         0.2965167  0.2965167  0.         0.0147627  0.06616182\n",
      " 0.         0.0147627  0.         0.2965167  0.0147627 ], Predicted Values: tensor([    0.0000,     0.1524,     0.8004,     0.0000,     0.0099,     0.0317,\n",
      "            0.0000,     0.0034,     0.0000,     0.0014,     0.0007],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1.])\n",
      "tensor([[1., 0., 0., 1., 0., 0., 1., 1., 0., 0., 0.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0), Probabilities: [0.         0.2965167  0.2965167  0.         0.0147627  0.06616182\n",
      " 0.         0.         0.2965167  0.0147627  0.0147627 ], Predicted Values: tensor([    0.0000,     0.1499,     0.7865,     0.0000,     0.0098,     0.0312,\n",
      "            0.0000,     0.0000,     0.0209,     0.0013,     0.0005],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 1., 0., 1., 0., 1., 1., 1., 1., 0.])\n",
      "tensor([[1., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1), Probabilities: [0.        0.3125832 0.3125832 0.        0.0155626 0.        0.0155626\n",
      " 0.3125832 0.0155626 0.0155626 0.       ], Predicted Values: tensor([0.0000, 0.1557, 0.8191, 0.0000, 0.0101, 0.0000, 0.0086, 0.0035, 0.0021,\n",
      "        0.0009, 0.0000], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 1., 0., 1., 0., 1., 1., 1., 0., 1.])\n",
      "tensor([[1., 0., 0., 1., 0., 1., 0., 0., 0., 1., 0.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0), Probabilities: [0.         0.24100095 0.24100095 0.         0.01199873 0.\n",
      " 0.01199873 0.24100095 0.01199873 0.         0.24100095], Predicted Values: tensor([    0.0000,     0.1557,     0.8196,     0.0000,     0.0101,     0.0000,\n",
      "            0.0086,     0.0035,     0.0021,     0.0000,     0.0004],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 1., 0., 1., 0., 1., 1., 0., 1., 1.])\n",
      "tensor([[1., 0., 0., 1., 0., 1., 0., 0., 1., 0., 0.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0), Probabilities: [0.         0.24100095 0.24100095 0.         0.01199873 0.\n",
      " 0.01199873 0.24100095 0.         0.24100095 0.01199873], Predicted Values: tensor([    0.0000,     0.1559,     0.8206,     0.0000,     0.0101,     0.0000,\n",
      "            0.0085,     0.0035,     0.0000,     0.0009,     0.0004],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 1., 0., 1., 0., 1., 0., 1., 1., 1.])\n",
      "tensor([[1., 0., 0., 1., 0., 1., 0., 1., 0., 0., 0.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0), Probabilities: [0.         0.41283446 0.41283446 0.         0.02055382 0.\n",
      " 0.02055382 0.         0.09211582 0.02055382 0.02055382], Predicted Values: tensor([    0.0000,     0.1547,     0.8141,     0.0000,     0.0101,     0.0000,\n",
      "            0.0009,     0.0000,     0.0190,     0.0009,     0.0002],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 1., 0., 1., 0., 0., 1., 1., 1., 1.])\n",
      "tensor([[1., 0., 0., 1., 0., 1., 1., 0., 0., 0., 0.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0), Probabilities: [0.         0.2965167  0.2965167  0.         0.0147627  0.\n",
      " 0.         0.2965167  0.06616182 0.0147627  0.0147627 ], Predicted Values: tensor([    0.0000,     0.1569,     0.8256,     0.0000,     0.0102,     0.0000,\n",
      "            0.0000,     0.0035,     0.0024,     0.0009,     0.0004],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 0.])\n",
      "tensor([[1., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1), Probabilities: [0.         0.2965167  0.2965167  0.         0.         0.06616182\n",
      " 0.2965167  0.0147627  0.0147627  0.0147627  0.        ], Predicted Values: tensor([0.0000, 0.1526, 0.8002, 0.0000, 0.0000, 0.0317, 0.0051, 0.0071, 0.0020,\n",
      "        0.0014, 0.0000], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 1., 0., 0., 1., 1., 1., 1., 0., 1.])\n",
      "tensor([[1., 0., 0., 1., 1., 0., 0., 0., 0., 1., 0.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0), Probabilities: [0.         0.23133667 0.23133667 0.         0.         0.05161819\n",
      " 0.23133667 0.01151757 0.01151757 0.         0.23133667], Predicted Values: tensor([    0.0000,     0.1526,     0.8011,     0.0000,     0.0000,     0.0316,\n",
      "            0.0051,     0.0071,     0.0021,     0.0000,     0.0004],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 1., 0., 0., 1., 1., 1., 0., 1., 1.])\n",
      "tensor([[1., 0., 0., 1., 1., 0., 0., 0., 1., 0., 0.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0), Probabilities: [0.         0.23133667 0.23133667 0.         0.         0.05161819\n",
      " 0.23133667 0.01151757 0.         0.23133667 0.01151757], Predicted Values: tensor([    0.0000,     0.1527,     0.8016,     0.0000,     0.0000,     0.0317,\n",
      "            0.0051,     0.0071,     0.0000,     0.0014,     0.0004],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 1., 0., 0., 1., 1., 0., 1., 1., 1.])\n",
      "tensor([[1., 0., 0., 1., 1., 0., 0., 1., 0., 0., 0.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0), Probabilities: [0.         0.28202106 0.28202106 0.         0.         0.0629274\n",
      " 0.28202106 0.         0.0629274  0.014041   0.014041  ], Predicted Values: tensor([    0.0000,     0.1517,     0.7959,     0.0000,     0.0000,     0.0315,\n",
      "            0.0005,     0.0000,     0.0187,     0.0013,     0.0003],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 1., 0., 0., 1., 0., 1., 1., 1., 1.])\n",
      "tensor([[1., 0., 0., 1., 1., 0., 1., 0., 0., 0., 0.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0), Probabilities: [0.         0.38526418 0.38526418 0.         0.         0.08596406\n",
      " 0.         0.01918117 0.08596406 0.01918117 0.01918117], Predicted Values: tensor([    0.0000,     0.1532,     0.8038,     0.0000,     0.0000,     0.0318,\n",
      "            0.0000,     0.0071,     0.0023,     0.0014,     0.0004],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1.])\n",
      "tensor([[1., 0., 0., 1., 1., 1., 0., 0., 0., 0., 0.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0), Probabilities: [0.         0.24100095 0.24100095 0.         0.         0.\n",
      " 0.24100095 0.24100095 0.01199873 0.01199873 0.01199873], Predicted Values: tensor([    0.0000,     0.1567,     0.8242,     0.0000,     0.0000,     0.0000,\n",
      "            0.0086,     0.0073,     0.0021,     0.0009,     0.0002],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 0., 1., 1., 1., 1., 1., 1., 0., 0.])\n",
      "tensor([[1., 0., 1., 0., 0., 0., 0., 0., 0., 1., 1.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1), Probabilities: [0.         0.38526418 0.         0.38526418 0.08596406 0.08596406\n",
      " 0.01918117 0.01918117 0.01918117 0.         0.        ], Predicted Values: tensor([0.0000, 0.3991, 0.0000, 0.5726, 0.0095, 0.0097, 0.0049, 0.0032, 0.0010,\n",
      "        0.0000, 0.0000], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0.])\n",
      "tensor([[1., 0., 1., 0., 0., 0., 0., 0., 1., 0., 1.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1), Probabilities: [0.         0.28202106 0.         0.28202106 0.0629274  0.0629274\n",
      " 0.014041   0.014041   0.         0.28202106 0.        ], Predicted Values: tensor([0.0000, 0.3989, 0.0000, 0.5717, 0.0094, 0.0097, 0.0049, 0.0032, 0.0000,\n",
      "        0.0022, 0.0000], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 0., 1., 1., 1., 1., 1., 0., 0., 1.])\n",
      "tensor([[1., 0., 1., 0., 0., 0., 0., 0., 1., 1., 0.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0), Probabilities: [0.         0.28202106 0.         0.28202106 0.0629274  0.0629274\n",
      " 0.014041   0.014041   0.         0.         0.28202106], Predicted Values: tensor([0.0000, 0.3990, 0.0000, 0.5725, 0.0095, 0.0097, 0.0049, 0.0032, 0.0000,\n",
      "        0.0000, 0.0013], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0.])\n",
      "tensor([[1., 0., 1., 0., 0., 0., 0., 1., 0., 0., 1.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1), Probabilities: [0.         0.36114582 0.         0.36114582 0.08058252 0.08058252\n",
      " 0.01798039 0.         0.08058252 0.01798039 0.        ], Predicted Values: tensor([    0.0000,     0.3979,     0.0000,     0.5707,     0.0094,     0.0097,\n",
      "            0.0005,     0.0000,     0.0096,     0.0022,     0.0000],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 0., 1., 1., 1., 1., 0., 1., 0., 1.])\n",
      "tensor([[1., 0., 1., 0., 0., 0., 0., 1., 0., 1., 0.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0), Probabilities: [0.         0.26887665 0.         0.26887665 0.05999449 0.05999449\n",
      " 0.01338658 0.         0.05999449 0.         0.26887665], Predicted Values: tensor([    0.0000,     0.3982,     0.0000,     0.5717,     0.0095,     0.0097,\n",
      "            0.0005,     0.0000,     0.0096,     0.0000,     0.0008],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 0., 1., 1., 1., 1., 0., 0., 1., 1.])\n",
      "tensor([[1., 0., 1., 0., 0., 0., 0., 1., 1., 0., 0.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0), Probabilities: [0.         0.28202106 0.         0.28202106 0.0629274  0.0629274\n",
      " 0.014041   0.         0.         0.28202106 0.014041  ], Predicted Values: tensor([    0.0000,     0.4015,     0.0000,     0.5757,     0.0095,     0.0097,\n",
      "            0.0005,     0.0000,     0.0000,     0.0022,     0.0008],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 0., 1., 1., 1., 0., 1., 1., 1., 0.])\n",
      "tensor([[1., 0., 1., 0., 0., 0., 1., 0., 0., 0., 1.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1), Probabilities: [0.         0.36114582 0.         0.36114582 0.08058252 0.08058252\n",
      " 0.         0.01798039 0.08058252 0.01798039 0.        ], Predicted Values: tensor([0.0000, 0.4005, 0.0000, 0.5736, 0.0095, 0.0097, 0.0000, 0.0033, 0.0012,\n",
      "        0.0022, 0.0000], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 0., 1., 1., 1., 0., 1., 1., 0., 1.])\n",
      "tensor([[1., 0., 1., 0., 0., 0., 1., 0., 0., 1., 0.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0), Probabilities: [0.         0.26887665 0.         0.26887665 0.05999449 0.05999449\n",
      " 0.         0.01338658 0.05999449 0.         0.26887665], Predicted Values: tensor([0.0000, 0.4007, 0.0000, 0.5744, 0.0095, 0.0097, 0.0000, 0.0033, 0.0012,\n",
      "        0.0000, 0.0012], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 0., 1., 1., 1., 0., 1., 0., 1., 1.])\n",
      "tensor([[1., 0., 1., 0., 0., 0., 1., 0., 1., 0., 0.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0), Probabilities: [0.         0.28202106 0.         0.28202106 0.0629274  0.0629274\n",
      " 0.         0.014041   0.         0.28202106 0.014041  ], Predicted Values: tensor([0.0000, 0.4005, 0.0000, 0.5736, 0.0095, 0.0097, 0.0000, 0.0033, 0.0000,\n",
      "        0.0022, 0.0012], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 0., 1., 1., 1., 0., 0., 1., 1., 1.])\n",
      "tensor([[1., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0), Probabilities: [0.         0.28202106 0.         0.28202106 0.0629274  0.0629274\n",
      " 0.         0.         0.28202106 0.014041   0.014041  ], Predicted Values: tensor([0.0000, 0.3975, 0.0000, 0.5696, 0.0095, 0.0096, 0.0000, 0.0000, 0.0109,\n",
      "        0.0022, 0.0008], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 0., 1., 1., 0., 1., 1., 1., 1., 0.])\n",
      "tensor([[1., 0., 1., 0., 0., 1., 0., 0., 0., 0., 1.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1), Probabilities: [0.         0.2965167  0.         0.2965167  0.06616182 0.\n",
      " 0.0147627  0.2965167  0.0147627  0.0147627  0.        ], Predicted Values: tensor([0.0000, 0.4009, 0.0000, 0.5757, 0.0095, 0.0000, 0.0080, 0.0033, 0.0011,\n",
      "        0.0015, 0.0000], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1.])\n",
      "tensor([[1., 0., 1., 0., 0., 1., 0., 0., 0., 1., 0.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0), Probabilities: [0.         0.23133667 0.         0.23133667 0.05161819 0.\n",
      " 0.01151757 0.23133667 0.01151757 0.         0.23133667], Predicted Values: tensor([0.0000, 0.4010, 0.0000, 0.5765, 0.0095, 0.0000, 0.0080, 0.0033, 0.0011,\n",
      "        0.0000, 0.0006], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1.])\n",
      "tensor([[1., 0., 1., 0., 0., 1., 0., 0., 1., 0., 0.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0), Probabilities: [0.         0.23133667 0.         0.23133667 0.05161819 0.\n",
      " 0.01151757 0.23133667 0.         0.23133667 0.01151757], Predicted Values: tensor([0.0000, 0.4011, 0.0000, 0.5760, 0.0095, 0.0000, 0.0080, 0.0033, 0.0000,\n",
      "        0.0015, 0.0006], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 0., 1., 1., 0., 1., 0., 1., 1., 1.])\n",
      "tensor([[1., 0., 1., 0., 0., 1., 0., 1., 0., 0., 0.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0), Probabilities: [0.         0.38526418 0.         0.38526418 0.08596406 0.\n",
      " 0.01918117 0.         0.08596406 0.01918117 0.01918117], Predicted Values: tensor([    0.0000,     0.4014,     0.0000,     0.5767,     0.0095,     0.0000,\n",
      "            0.0008,     0.0000,     0.0097,     0.0015,     0.0004],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1.])\n",
      "tensor([[1., 0., 1., 0., 0., 1., 1., 0., 0., 0., 0.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0), Probabilities: [0.         0.28202106 0.         0.28202106 0.0629274  0.\n",
      " 0.         0.28202106 0.0629274  0.014041   0.014041  ], Predicted Values: tensor([    0.0000,     0.4041,     0.0000,     0.5797,     0.0096,     0.0000,\n",
      "            0.0000,     0.0033,     0.0012,     0.0015,     0.0006],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 0., 1., 0., 1., 1., 1., 1., 1., 0.])\n",
      "tensor([[1., 0., 1., 0., 1., 0., 0., 0., 0., 0., 1.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1), Probabilities: [0.         0.2965167  0.         0.2965167  0.         0.06616182\n",
      " 0.2965167  0.0147627  0.0147627  0.0147627  0.        ], Predicted Values: tensor([0.0000, 0.4009, 0.0000, 0.5745, 0.0000, 0.0097, 0.0049, 0.0068, 0.0011,\n",
      "        0.0022, 0.0000], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1.])\n",
      "tensor([[1., 0., 1., 0., 1., 0., 0., 0., 0., 1., 0.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0), Probabilities: [0.         0.23133667 0.         0.23133667 0.         0.05161819\n",
      " 0.23133667 0.01151757 0.01151757 0.         0.23133667], Predicted Values: tensor([0.0000, 0.4013, 0.0000, 0.5756, 0.0000, 0.0097, 0.0049, 0.0068, 0.0011,\n",
      "        0.0000, 0.0007], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 0., 1., 0., 1., 1., 1., 0., 1., 1.])\n",
      "tensor([[1., 0., 1., 0., 1., 0., 0., 0., 1., 0., 0.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0), Probabilities: [0.         0.23133667 0.         0.23133667 0.         0.05161819\n",
      " 0.23133667 0.01151757 0.         0.23133667 0.01151757], Predicted Values: tensor([0.0000, 0.4011, 0.0000, 0.5747, 0.0000, 0.0097, 0.0049, 0.0068, 0.0000,\n",
      "        0.0022, 0.0007], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 0., 1., 0., 1., 1., 0., 1., 1., 1.])\n",
      "tensor([[1., 0., 1., 0., 1., 0., 0., 1., 0., 0., 0.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0), Probabilities: [0.         0.28202106 0.         0.28202106 0.         0.0629274\n",
      " 0.28202106 0.         0.0629274  0.014041   0.014041  ], Predicted Values: tensor([    0.0000,     0.4016,     0.0000,     0.5758,     0.0000,     0.0097,\n",
      "            0.0005,     0.0000,     0.0097,     0.0022,     0.0004],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "tensor([[1., 0., 1., 0., 1., 0., 1., 0., 0., 0., 0.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0), Probabilities: [0.         0.38526418 0.         0.38526418 0.         0.08596406\n",
      " 0.         0.01918117 0.08596406 0.01918117 0.01918117], Predicted Values: tensor([0.0000, 0.4028, 0.0000, 0.5766, 0.0000, 0.0097, 0.0000, 0.0069, 0.0012,\n",
      "        0.0022, 0.0006], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1.])\n",
      "tensor([[1., 0., 1., 0., 1., 1., 0., 0., 0., 0., 0.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0), Probabilities: [0.         0.24100095 0.         0.24100095 0.         0.\n",
      " 0.24100095 0.24100095 0.01199873 0.01199873 0.01199873], Predicted Values: tensor([    0.0000,     0.4033,     0.0000,     0.5789,     0.0000,     0.0000,\n",
      "            0.0080,     0.0069,     0.0011,     0.0015,     0.0003],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0.])\n",
      "tensor([[1., 0., 1., 1., 0., 0., 0., 0., 0., 0., 1.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1), Probabilities: [0.         0.41283446 0.         0.         0.09211582 0.41283446\n",
      " 0.02055382 0.02055382 0.02055382 0.02055382 0.        ], Predicted Values: tensor([0.0000, 0.9011, 0.0000, 0.0000, 0.0180, 0.0632, 0.0094, 0.0062, 0.0012,\n",
      "        0.0009, 0.0000], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 0., 0., 1., 1., 1., 1., 1., 0., 1.])\n",
      "tensor([[1., 0., 1., 1., 0., 0., 0., 0., 0., 1., 0.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0), Probabilities: [0.         0.2965167  0.         0.         0.06616182 0.2965167\n",
      " 0.0147627  0.0147627  0.0147627  0.         0.2965167 ], Predicted Values: tensor([    0.0000,     0.9014,     0.0000,     0.0000,     0.0181,     0.0632,\n",
      "            0.0094,     0.0062,     0.0012,     0.0000,     0.0005],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 0., 0., 1., 1., 1., 1., 0., 1., 1.])\n",
      "tensor([[1., 0., 1., 1., 0., 0., 0., 0., 1., 0., 0.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0), Probabilities: [0.         0.2965167  0.         0.         0.06616182 0.2965167\n",
      " 0.0147627  0.0147627  0.         0.2965167  0.0147627 ], Predicted Values: tensor([    0.0000,     0.9017,     0.0000,     0.0000,     0.0181,     0.0632,\n",
      "            0.0094,     0.0062,     0.0000,     0.0009,     0.0005],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1.])\n",
      "tensor([[1., 0., 1., 1., 0., 0., 0., 1., 0., 0., 0.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0), Probabilities: [0.         0.38526418 0.         0.         0.08596406 0.38526418\n",
      " 0.01918117 0.         0.08596406 0.01918117 0.01918117], Predicted Values: tensor([    0.0000,     0.9051,     0.0000,     0.0000,     0.0182,     0.0635,\n",
      "            0.0010,     0.0000,     0.0110,     0.0009,     0.0003],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1.])\n",
      "tensor([[1., 0., 1., 1., 0., 0., 1., 0., 0., 0., 0.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0), Probabilities: [0.         0.38526418 0.         0.         0.08596406 0.38526418\n",
      " 0.         0.01918117 0.08596406 0.01918117 0.01918117], Predicted Values: tensor([    0.0000,     0.9089,     0.0000,     0.0000,     0.0183,     0.0638,\n",
      "            0.0000,     0.0063,     0.0014,     0.0009,     0.0004],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 0., 0., 1., 0., 1., 1., 1., 1., 1.])\n",
      "tensor([[1., 0., 1., 1., 0., 1., 0., 0., 0., 0., 0.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0), Probabilities: [0.         0.41283446 0.         0.         0.09211582 0.\n",
      " 0.02055382 0.41283446 0.02055382 0.02055382 0.02055382], Predicted Values: tensor([    0.0000,     0.9559,     0.0000,     0.0000,     0.0192,     0.0000,\n",
      "            0.0162,     0.0066,     0.0013,     0.0007,     0.0002],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1.])\n",
      "tensor([[1., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0), Probabilities: [0.        0.3125832 0.        0.        0.        0.3125832 0.3125832\n",
      " 0.0155626 0.0155626 0.0155626 0.0155626], Predicted Values: tensor([    0.0000,     0.9114,     0.0000,     0.0000,     0.0000,     0.0638,\n",
      "            0.0094,     0.0130,     0.0012,     0.0009,     0.0003],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 0.])\n",
      "tensor([[1., 1., 0., 0., 0., 0., 0., 0., 0., 1., 1.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1), Probabilities: [0.         0.         0.41283446 0.41283446 0.09211582 0.02055382\n",
      " 0.02055382 0.02055382 0.02055382 0.         0.        ], Predicted Values: tensor([0.0000, 0.0000, 0.4598, 0.5095, 0.0080, 0.0136, 0.0042, 0.0028, 0.0022,\n",
      "        0.0000, 0.0000], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0.])\n",
      "tensor([[1., 1., 0., 0., 0., 0., 0., 0., 1., 0., 1.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1), Probabilities: [0.         0.         0.2965167  0.2965167  0.06616182 0.0147627\n",
      " 0.0147627  0.0147627  0.         0.2965167  0.        ], Predicted Values: tensor([0.0000, 0.0000, 0.4603, 0.5095, 0.0080, 0.0136, 0.0042, 0.0028, 0.0000,\n",
      "        0.0017, 0.0000], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 1., 1., 1., 1., 1., 1., 0., 0., 1.])\n",
      "tensor([[1., 1., 0., 0., 0., 0., 0., 0., 1., 1., 0.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0), Probabilities: [0.         0.         0.2965167  0.2965167  0.06616182 0.0147627\n",
      " 0.0147627  0.0147627  0.         0.         0.2965167 ], Predicted Values: tensor([0.0000, 0.0000, 0.4604, 0.5097, 0.0081, 0.0136, 0.0042, 0.0028, 0.0000,\n",
      "        0.0000, 0.0013], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 0.])\n",
      "tensor([[1., 1., 0., 0., 0., 0., 0., 1., 0., 0., 1.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1), Probabilities: [0.         0.         0.38526418 0.38526418 0.08596406 0.01918117\n",
      " 0.01918117 0.         0.08596406 0.01918117 0.        ], Predicted Values: tensor([    0.0000,     0.0000,     0.4539,     0.5030,     0.0079,     0.0134,\n",
      "            0.0004,     0.0000,     0.0196,     0.0017,     0.0000],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 1., 1., 1., 1., 1., 0., 1., 0., 1.])\n",
      "tensor([[1., 1., 0., 0., 0., 0., 0., 1., 0., 1., 0.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0), Probabilities: [0.         0.         0.28202106 0.28202106 0.0629274  0.014041\n",
      " 0.014041   0.         0.0629274  0.         0.28202106], Predicted Values: tensor([    0.0000,     0.0000,     0.4542,     0.5034,     0.0080,     0.0134,\n",
      "            0.0004,     0.0000,     0.0197,     0.0000,     0.0008],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 1., 1., 1., 1., 1., 0., 0., 1., 1.])\n",
      "tensor([[1., 1., 0., 0., 0., 0., 0., 1., 1., 0., 0.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0), Probabilities: [0.         0.         0.2965167  0.2965167  0.06616182 0.0147627\n",
      " 0.0147627  0.         0.         0.2965167  0.0147627 ], Predicted Values: tensor([    0.0000,     0.0000,     0.4628,     0.5124,     0.0081,     0.0137,\n",
      "            0.0004,     0.0000,     0.0000,     0.0017,     0.0009],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 1., 1., 1., 1., 0., 1., 1., 1., 0.])\n",
      "tensor([[1., 1., 0., 0., 0., 0., 1., 0., 0., 0., 1.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1), Probabilities: [0.         0.         0.38526418 0.38526418 0.08596406 0.01918117\n",
      " 0.         0.01918117 0.08596406 0.01918117 0.        ], Predicted Values: tensor([0.0000, 0.0000, 0.4611, 0.5103, 0.0081, 0.0136, 0.0000, 0.0028, 0.0025,\n",
      "        0.0017, 0.0000], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 1., 1., 1., 1., 0., 1., 1., 0., 1.])\n",
      "tensor([[1., 1., 0., 0., 0., 0., 1., 0., 0., 1., 0.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0), Probabilities: [0.         0.         0.28202106 0.28202106 0.0629274  0.014041\n",
      " 0.         0.014041   0.0629274  0.         0.28202106], Predicted Values: tensor([0.0000, 0.0000, 0.4612, 0.5106, 0.0081, 0.0136, 0.0000, 0.0028, 0.0025,\n",
      "        0.0000, 0.0012], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 1., 1., 1., 1., 0., 1., 0., 1., 1.])\n",
      "tensor([[1., 1., 0., 0., 0., 0., 1., 0., 1., 0., 0.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0), Probabilities: [0.         0.         0.2965167  0.2965167  0.06616182 0.0147627\n",
      " 0.         0.0147627  0.         0.2965167  0.0147627 ], Predicted Values: tensor([0.0000, 0.0000, 0.4618, 0.5107, 0.0081, 0.0136, 0.0000, 0.0028, 0.0000,\n",
      "        0.0017, 0.0012], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 1., 1., 1., 1., 0., 0., 1., 1., 1.])\n",
      "tensor([[1., 1., 0., 0., 0., 0., 1., 1., 0., 0., 0.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0), Probabilities: [0.         0.         0.2965167  0.2965167  0.06616182 0.0147627\n",
      " 0.         0.         0.2965167  0.0147627  0.0147627 ], Predicted Values: tensor([0.0000, 0.0000, 0.4528, 0.5012, 0.0079, 0.0134, 0.0000, 0.0000, 0.0222,\n",
      "        0.0017, 0.0008], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0.])\n",
      "tensor([[1., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1), Probabilities: [0.         0.         0.2965167  0.2965167  0.06616182 0.\n",
      " 0.0147627  0.2965167  0.0147627  0.0147627  0.        ], Predicted Values: tensor([0.0000, 0.0000, 0.4646, 0.5143, 0.0081, 0.0000, 0.0068, 0.0028, 0.0022,\n",
      "        0.0012, 0.0000], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1.])\n",
      "tensor([[1., 1., 0., 0., 0., 1., 0., 0., 0., 1., 0.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0), Probabilities: [0.         0.         0.23133667 0.23133667 0.05161819 0.\n",
      " 0.01151757 0.23133667 0.01151757 0.         0.23133667], Predicted Values: tensor([0.0000, 0.0000, 0.4648, 0.5146, 0.0081, 0.0000, 0.0068, 0.0028, 0.0022,\n",
      "        0.0000, 0.0006], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 1., 1., 1., 0., 1., 1., 0., 1., 1.])\n",
      "tensor([[1., 1., 0., 0., 0., 1., 0., 0., 1., 0., 0.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0), Probabilities: [0.         0.         0.23133667 0.23133667 0.05161819 0.\n",
      " 0.01151757 0.23133667 0.         0.23133667 0.01151757], Predicted Values: tensor([0.0000, 0.0000, 0.4656, 0.5149, 0.0081, 0.0000, 0.0068, 0.0028, 0.0000,\n",
      "        0.0012, 0.0006], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 1., 1., 1., 0., 1., 0., 1., 1., 1.])\n",
      "tensor([[1., 1., 0., 0., 0., 1., 0., 1., 0., 0., 0.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0), Probabilities: [0.         0.         0.38526418 0.38526418 0.08596406 0.\n",
      " 0.01918117 0.         0.08596406 0.01918117 0.01918117], Predicted Values: tensor([    0.0000,     0.0000,     0.4603,     0.5096,     0.0080,     0.0000,\n",
      "            0.0007,     0.0000,     0.0199,     0.0011,     0.0004],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1.])\n",
      "tensor([[1., 1., 0., 0., 0., 1., 1., 0., 0., 0., 0.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0), Probabilities: [0.         0.         0.28202106 0.28202106 0.0629274  0.\n",
      " 0.         0.28202106 0.0629274  0.014041   0.014041  ], Predicted Values: tensor([0.0000, 0.0000, 0.4677, 0.5171, 0.0082, 0.0000, 0.0000, 0.0028, 0.0025,\n",
      "        0.0012, 0.0006], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0.])\n",
      "tensor([[1., 1., 0., 0., 1., 0., 0., 0., 0., 0., 1.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1), Probabilities: [0.        0.        0.3125832 0.3125832 0.        0.0155626 0.3125832\n",
      " 0.0155626 0.0155626 0.0155626 0.       ], Predicted Values: tensor([0.0000, 0.0000, 0.4614, 0.5111, 0.0000, 0.0136, 0.0042, 0.0057, 0.0022,\n",
      "        0.0017, 0.0000], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 1., 1., 0., 1., 1., 1., 1., 0., 1.])\n",
      "tensor([[1., 1., 0., 0., 1., 0., 0., 0., 0., 1., 0.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0), Probabilities: [0.         0.         0.24100095 0.24100095 0.         0.01199873\n",
      " 0.24100095 0.01199873 0.01199873 0.         0.24100095], Predicted Values: tensor([0.0000, 0.0000, 0.4619, 0.5117, 0.0000, 0.0136, 0.0042, 0.0058, 0.0022,\n",
      "        0.0000, 0.0007], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 1., 1., 0., 1., 1., 1., 0., 1., 1.])\n",
      "tensor([[1., 1., 0., 0., 1., 0., 0., 0., 1., 0., 0.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0), Probabilities: [0.         0.         0.24100095 0.24100095 0.         0.01199873\n",
      " 0.24100095 0.01199873 0.         0.24100095 0.01199873], Predicted Values: tensor([0.0000, 0.0000, 0.4623, 0.5117, 0.0000, 0.0136, 0.0042, 0.0058, 0.0000,\n",
      "        0.0017, 0.0007], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 1., 1., 0., 1., 1., 0., 1., 1., 1.])\n",
      "tensor([[1., 1., 0., 0., 1., 0., 0., 1., 0., 0., 0.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0), Probabilities: [0.         0.         0.2965167  0.2965167  0.         0.0147627\n",
      " 0.2965167  0.         0.06616182 0.0147627  0.0147627 ], Predicted Values: tensor([    0.0000,     0.0000,     0.4574,     0.5067,     0.0000,     0.0135,\n",
      "            0.0004,     0.0000,     0.0199,     0.0017,     0.0004],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 1., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "tensor([[1., 1., 0., 0., 1., 0., 1., 0., 0., 0., 0.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0), Probabilities: [0.         0.         0.41283446 0.41283446 0.         0.02055382\n",
      " 0.         0.02055382 0.09211582 0.02055382 0.02055382], Predicted Values: tensor([0.0000, 0.0000, 0.4632, 0.5125, 0.0000, 0.0137, 0.0000, 0.0058, 0.0025,\n",
      "        0.0017, 0.0006], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 1., 1., 0., 0., 1., 1., 1., 1., 1.])\n",
      "tensor([[1., 1., 0., 0., 1., 1., 0., 0., 0., 0., 0.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0), Probabilities: [0.         0.         0.24100095 0.24100095 0.         0.\n",
      " 0.24100095 0.24100095 0.01199873 0.01199873 0.01199873], Predicted Values: tensor([    0.0000,     0.0000,     0.4669,     0.5167,     0.0000,     0.0000,\n",
      "            0.0069,     0.0058,     0.0022,     0.0012,     0.0003],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 1., 0., 1., 1., 1., 1., 1., 1., 0.])\n",
      "tensor([[1., 1., 0., 1., 0., 0., 0., 0., 0., 0., 1.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1), Probabilities: [0.         0.         0.60775178 0.         0.13560775 0.13560775\n",
      " 0.03025818 0.03025818 0.03025818 0.03025818 0.        ], Predicted Values: tensor([    0.0000,     0.0000,     0.9456,     0.0000,     0.0069,     0.0400,\n",
      "            0.0036,     0.0024,     0.0011,     0.0003,     0.0000],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 1., 0., 1., 1., 1., 1., 1., 0., 1.])\n",
      "tensor([[1., 1., 0., 1., 0., 0., 0., 0., 0., 1., 0.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0), Probabilities: [0.         0.         0.38526418 0.         0.08596406 0.08596406\n",
      " 0.01918117 0.01918117 0.01918117 0.         0.38526418], Predicted Values: tensor([    0.0000,     0.0000,     0.9458,     0.0000,     0.0069,     0.0400,\n",
      "            0.0036,     0.0024,     0.0011,     0.0000,     0.0002],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1.])\n",
      "tensor([[1., 1., 0., 1., 0., 0., 0., 0., 1., 0., 0.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0), Probabilities: [0.         0.         0.38526418 0.         0.08596406 0.08596406\n",
      " 0.01918117 0.01918117 0.         0.38526418 0.01918117], Predicted Values: tensor([    0.0000,     0.0000,     0.9465,     0.0000,     0.0069,     0.0400,\n",
      "            0.0036,     0.0024,     0.0000,     0.0003,     0.0002],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 1., 0., 1., 1., 1., 0., 1., 1., 1.])\n",
      "tensor([[1., 1., 0., 1., 0., 0., 0., 1., 0., 0., 0.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0), Probabilities: [0.         0.         0.54982767 0.         0.12268314 0.12268314\n",
      " 0.02737431 0.         0.12268314 0.02737431 0.02737431], Predicted Values: tensor([    0.0000,     0.0000,     0.9422,     0.0000,     0.0069,     0.0399,\n",
      "            0.0004,     0.0000,     0.0101,     0.0003,     0.0001],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 1., 0., 1., 1., 0., 1., 1., 1., 1.])\n",
      "tensor([[1., 1., 0., 1., 0., 0., 1., 0., 0., 0., 0.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0), Probabilities: [0.         0.         0.54982767 0.         0.12268314 0.12268314\n",
      " 0.         0.02737431 0.12268314 0.02737431 0.02737431], Predicted Values: tensor([    0.0000,     0.0000,     0.9487,     0.0000,     0.0070,     0.0402,\n",
      "            0.0000,     0.0024,     0.0013,     0.0003,     0.0002],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 1., 0., 1., 0., 1., 1., 1., 1., 1.])\n",
      "tensor([[1., 1., 0., 1., 0., 1., 0., 0., 0., 0., 0.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0), Probabilities: [0.         0.         0.41283446 0.         0.09211582 0.\n",
      " 0.02055382 0.41283446 0.02055382 0.02055382 0.02055382], Predicted Values: tensor([    0.0000,     0.0000,     0.9828,     0.0000,     0.0072,     0.0000,\n",
      "            0.0061,     0.0025,     0.0011,     0.0002,     0.0001],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1.])\n",
      "tensor([[1., 1., 0., 1., 1., 0., 0., 0., 0., 0., 0.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0), Probabilities: [0.         0.         0.41283446 0.         0.         0.09211582\n",
      " 0.41283446 0.02055382 0.02055382 0.02055382 0.02055382], Predicted Values: tensor([    0.0000,     0.0000,     0.9498,     0.0000,     0.0000,     0.0401,\n",
      "            0.0036,     0.0049,     0.0011,     0.0003,     0.0001],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0.])\n",
      "tensor([[1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 1.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1), Probabilities: [0.         0.         0.         0.41283446 0.41283446 0.09211582\n",
      " 0.02055382 0.02055382 0.02055382 0.02055382 0.        ], Predicted Values: tensor([    0.0000,     0.0000,     0.0000,     0.9622,     0.0097,     0.0181,\n",
      "            0.0051,     0.0033,     0.0008,     0.0008,     0.0000],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1.])\n",
      "tensor([[1., 1., 1., 0., 0., 0., 0., 0., 0., 1., 0.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0), Probabilities: [0.         0.         0.         0.2965167  0.2965167  0.06616182\n",
      " 0.0147627  0.0147627  0.0147627  0.         0.2965167 ], Predicted Values: tensor([    0.0000,     0.0000,     0.0000,     0.9625,     0.0098,     0.0180,\n",
      "            0.0050,     0.0033,     0.0008,     0.0000,     0.0005],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 0., 1., 1., 1., 1., 1., 0., 1., 1.])\n",
      "tensor([[1., 1., 1., 0., 0., 0., 0., 0., 1., 0., 0.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0), Probabilities: [0.         0.         0.         0.2965167  0.2965167  0.06616182\n",
      " 0.0147627  0.0147627  0.         0.2965167  0.0147627 ], Predicted Values: tensor([    0.0000,     0.0000,     0.0000,     0.9625,     0.0098,     0.0180,\n",
      "            0.0050,     0.0033,     0.0000,     0.0008,     0.0005],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 0., 1., 1., 1., 1., 0., 1., 1., 1.])\n",
      "tensor([[1., 1., 1., 0., 0., 0., 0., 1., 0., 0., 0.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0), Probabilities: [0.         0.         0.         0.38526418 0.38526418 0.08596406\n",
      " 0.01918117 0.         0.08596406 0.01918117 0.01918117], Predicted Values: tensor([    0.0000,     0.0000,     0.0000,     0.9628,     0.0098,     0.0181,\n",
      "            0.0005,     0.0000,     0.0077,     0.0008,     0.0003],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1.])\n",
      "tensor([[1., 1., 1., 0., 0., 0., 1., 0., 0., 0., 0.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0), Probabilities: [0.         0.         0.         0.38526418 0.38526418 0.08596406\n",
      " 0.         0.01918117 0.08596406 0.01918117 0.01918117], Predicted Values: tensor([    0.0000,     0.0000,     0.0000,     0.9664,     0.0098,     0.0181,\n",
      "            0.0000,     0.0034,     0.0010,     0.0008,     0.0005],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 0., 1., 1., 0., 1., 1., 1., 1., 1.])\n",
      "tensor([[1., 1., 1., 0., 0., 1., 0., 0., 0., 0., 0.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0), Probabilities: [0.        0.        0.        0.3125832 0.3125832 0.        0.0155626\n",
      " 0.3125832 0.0155626 0.0155626 0.0155626], Predicted Values: tensor([    0.0000,     0.0000,     0.0000,     0.9768,     0.0099,     0.0000,\n",
      "            0.0083,     0.0034,     0.0009,     0.0005,     0.0003],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 0., 1., 0., 1., 1., 1., 1., 1., 1.])\n",
      "tensor([[1., 1., 1., 0., 1., 0., 0., 0., 0., 0., 0.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0), Probabilities: [0.         0.         0.         0.41283446 0.         0.09211582\n",
      " 0.41283446 0.02055382 0.02055382 0.02055382 0.02055382], Predicted Values: tensor([    0.0000,     0.0000,     0.0000,     0.9679,     0.0000,     0.0181,\n",
      "            0.0051,     0.0070,     0.0008,     0.0008,     0.0003],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1.])\n",
      "tensor([[1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0), Probabilities: [0.         0.         0.         0.         0.44465485 0.44465485\n",
      " 0.02213806 0.02213806 0.02213806 0.02213806 0.02213806], Predicted Values: tensor([0.0000, 0.0000, 0.0000, 0.0000, 0.1209, 0.7656, 0.0626, 0.0413, 0.0062,\n",
      "        0.0021, 0.0013], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0.])\n",
      "tensor([[1., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1), Probabilities: [0.         0.31752471 0.31752471 0.31752471 0.01580862 0.01580862\n",
      " 0.01580862 0.         0.         0.         0.        ], Predicted Values: tensor([0.0000, 0.1484, 0.3857, 0.4432, 0.0114, 0.0107, 0.0006, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0.])\n",
      "tensor([[1., 0., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1), Probabilities: [0.         0.31752471 0.31752471 0.31752471 0.01580862 0.01580862\n",
      " 0.         0.01580862 0.         0.         0.        ], Predicted Values: tensor([0.0000, 0.1480, 0.3846, 0.4414, 0.0114, 0.0106, 0.0000, 0.0039, 0.0000,\n",
      "        0.0000, 0.0000], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 1., 1., 1., 1., 0., 0., 1., 0., 0.])\n",
      "tensor([[1., 0., 0., 0., 0., 0., 1., 1., 0., 1., 1.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1), Probabilities: [0.         0.24392778 0.24392778 0.24392778 0.01214445 0.01214445\n",
      " 0.         0.         0.24392778 0.         0.        ], Predicted Values: tensor([0.0000, 0.1427, 0.3706, 0.4257, 0.0110, 0.0103, 0.0000, 0.0000, 0.0397,\n",
      "        0.0000, 0.0000], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 1., 1., 1., 1., 0., 0., 0., 1., 0.])\n",
      "tensor([[1., 0., 0., 0., 0., 0., 1., 1., 1., 0., 1.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1), Probabilities: [0.         0.24392778 0.24392778 0.24392778 0.01214445 0.01214445\n",
      " 0.         0.         0.         0.24392778 0.        ], Predicted Values: tensor([0.0000, 0.1476, 0.3834, 0.4400, 0.0114, 0.0106, 0.0000, 0.0000, 0.0000,\n",
      "        0.0070, 0.0000], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 1., 1., 1., 1., 0., 0., 0., 0., 1.])\n",
      "tensor([[1., 0., 0., 0., 0., 0., 1., 1., 1., 1., 0.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0), Probabilities: [0.         0.24392778 0.24392778 0.24392778 0.01214445 0.01214445\n",
      " 0.         0.         0.         0.         0.24392778], Predicted Values: tensor([0.0000, 0.1482, 0.3851, 0.4419, 0.0114, 0.0106, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0028], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 1., 1., 1., 0., 1., 1., 0., 0., 0.])\n",
      "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 1., 1., 1.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1), Probabilities: [0.         0.24392778 0.24392778 0.24392778 0.01214445 0.\n",
      " 0.01214445 0.24392778 0.         0.         0.        ], Predicted Values: tensor([0.0000, 0.1479, 0.3852, 0.4421, 0.0113, 0.0000, 0.0096, 0.0039, 0.0000,\n",
      "        0.0000, 0.0000], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 1., 1., 1., 0., 1., 0., 1., 0., 0.])\n",
      "tensor([[1., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1), Probabilities: [0.         0.30095967 0.30095967 0.30095967 0.0149839  0.\n",
      " 0.0149839  0.         0.06715318 0.         0.        ], Predicted Values: tensor([0.0000, 0.1444, 0.3761, 0.4320, 0.0111, 0.0000, 0.0010, 0.0000, 0.0354,\n",
      "        0.0000, 0.0000], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 1., 1., 1., 0., 1., 0., 0., 1., 0.])\n",
      "tensor([[1., 0., 0., 0., 0., 1., 0., 1., 1., 0., 1.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1), Probabilities: [0.         0.24392778 0.24392778 0.24392778 0.01214445 0.\n",
      " 0.01214445 0.         0.         0.24392778 0.        ], Predicted Values: tensor([0.0000, 0.1491, 0.3882, 0.4455, 0.0114, 0.0000, 0.0010, 0.0000, 0.0000,\n",
      "        0.0048, 0.0000], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1.])\n",
      "tensor([[1., 0., 0., 0., 0., 1., 0., 1., 1., 1., 0.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0), Probabilities: [0.         0.24392778 0.24392778 0.24392778 0.01214445 0.\n",
      " 0.01214445 0.         0.         0.         0.24392778], Predicted Values: tensor([0.0000, 0.1495, 0.3895, 0.4471, 0.0115, 0.0000, 0.0010, 0.0000, 0.0000,\n",
      "        0.0000, 0.0014], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 1., 1., 1., 0., 0., 1., 1., 0., 0.])\n",
      "tensor([[1., 0., 0., 0., 0., 1., 1., 0., 0., 1., 1.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1), Probabilities: [0.         0.23403215 0.23403215 0.23403215 0.01165177 0.\n",
      " 0.         0.23403215 0.05221963 0.         0.        ], Predicted Values: tensor([0.0000, 0.1487, 0.3871, 0.4442, 0.0114, 0.0000, 0.0000, 0.0040, 0.0045,\n",
      "        0.0000, 0.0000], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 1., 1., 1., 0., 0., 1., 0., 1., 0.])\n",
      "tensor([[1., 0., 0., 0., 0., 1., 1., 0., 1., 0., 1.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1), Probabilities: [0.         0.19802815 0.19802815 0.19802815 0.00985924 0.\n",
      " 0.         0.19802815 0.         0.19802815 0.        ], Predicted Values: tensor([0.0000, 0.1488, 0.3872, 0.4438, 0.0114, 0.0000, 0.0000, 0.0040, 0.0000,\n",
      "        0.0048, 0.0000], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 1., 1., 1., 0., 0., 1., 0., 0., 1.])\n",
      "tensor([[1., 0., 0., 0., 0., 1., 1., 0., 1., 1., 0.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0), Probabilities: [0.         0.19802815 0.19802815 0.19802815 0.00985924 0.\n",
      " 0.         0.19802815 0.         0.         0.19802815], Predicted Values: tensor([0.0000, 0.1490, 0.3883, 0.4452, 0.0115, 0.0000, 0.0000, 0.0040, 0.0000,\n",
      "        0.0000, 0.0020], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 1., 1., 1., 0., 0., 0., 1., 1., 0.])\n",
      "tensor([[1., 0., 0., 0., 0., 1., 1., 1., 0., 0., 1.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1), Probabilities: [0.         0.24392778 0.24392778 0.24392778 0.01214445 0.\n",
      " 0.         0.         0.24392778 0.01214445 0.        ], Predicted Values: tensor([0.0000, 0.1434, 0.3731, 0.4281, 0.0110, 0.0000, 0.0000, 0.0000, 0.0398,\n",
      "        0.0046, 0.0000], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 1., 1., 1., 0., 0., 0., 1., 0., 1.])\n",
      "tensor([[1., 0., 0., 0., 0., 1., 1., 1., 0., 1., 0.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0), Probabilities: [0.         0.19802815 0.19802815 0.19802815 0.00985924 0.\n",
      " 0.         0.         0.19802815 0.         0.19802815], Predicted Values: tensor([0.0000, 0.1437, 0.3743, 0.4296, 0.0111, 0.0000, 0.0000, 0.0000, 0.0400,\n",
      "        0.0000, 0.0013], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 1., 1., 1., 0., 0., 0., 0., 1., 1.])\n",
      "tensor([[1., 0., 0., 0., 0., 1., 1., 1., 1., 0., 0.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0), Probabilities: [0.         0.24392778 0.24392778 0.24392778 0.01214445 0.\n",
      " 0.         0.         0.         0.24392778 0.01214445], Predicted Values: tensor([0.0000, 0.1491, 0.3883, 0.4451, 0.0115, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0048, 0.0013], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 1., 1., 0., 1., 1., 1., 0., 0., 0.])\n",
      "tensor([[1., 0., 0., 0., 1., 0., 0., 0., 1., 1., 1.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1), Probabilities: [0.         0.24392778 0.24392778 0.24392778 0.         0.01214445\n",
      " 0.24392778 0.01214445 0.         0.         0.        ], Predicted Values: tensor([0.0000, 0.1482, 0.3850, 0.4422, 0.0000, 0.0106, 0.0059, 0.0081, 0.0000,\n",
      "        0.0000, 0.0000], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 1., 1., 0., 1., 1., 0., 1., 0., 0.])\n",
      "tensor([[1., 0., 0., 0., 1., 0., 0., 1., 0., 1., 1.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1), Probabilities: [0.         0.23403215 0.23403215 0.23403215 0.         0.01165177\n",
      " 0.23403215 0.         0.05221963 0.         0.        ], Predicted Values: tensor([0.0000, 0.1449, 0.3761, 0.4324, 0.0000, 0.0104, 0.0006, 0.0000, 0.0356,\n",
      "        0.0000, 0.0000], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 1., 1., 0., 1., 1., 0., 0., 1., 0.])\n",
      "tensor([[1., 0., 0., 0., 1., 0., 0., 1., 1., 0., 1.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1), Probabilities: [0.         0.19802815 0.19802815 0.19802815 0.         0.00985924\n",
      " 0.19802815 0.         0.         0.19802815 0.        ], Predicted Values: tensor([0.0000, 0.1492, 0.3874, 0.4449, 0.0000, 0.0107, 0.0006, 0.0000, 0.0000,\n",
      "        0.0071, 0.0000], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 1., 1., 0., 1., 1., 0., 0., 0., 1.])\n",
      "tensor([[1., 0., 0., 0., 1., 0., 0., 1., 1., 1., 0.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0), Probabilities: [0.         0.19802815 0.19802815 0.19802815 0.         0.00985924\n",
      " 0.19802815 0.         0.         0.         0.19802815], Predicted Values: tensor([0.0000, 0.1499, 0.3896, 0.4475, 0.0000, 0.0107, 0.0006, 0.0000, 0.0000,\n",
      "        0.0000, 0.0016], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 1., 1., 0., 1., 0., 1., 1., 0., 0.])\n",
      "tensor([[1., 0., 0., 0., 1., 0., 1., 0., 0., 1., 1.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1), Probabilities: [0.         0.30095967 0.30095967 0.30095967 0.         0.0149839\n",
      " 0.         0.0149839  0.06715318 0.         0.        ], Predicted Values: tensor([0.0000, 0.1485, 0.3855, 0.4427, 0.0000, 0.0107, 0.0000, 0.0082, 0.0045,\n",
      "        0.0000, 0.0000], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 1., 1., 0., 1., 0., 1., 0., 1., 0.])\n",
      "tensor([[1., 0., 0., 0., 1., 0., 1., 0., 1., 0., 1.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1), Probabilities: [0.         0.24392778 0.24392778 0.24392778 0.         0.01214445\n",
      " 0.         0.01214445 0.         0.24392778 0.        ], Predicted Values: tensor([0.0000, 0.1482, 0.3847, 0.4413, 0.0000, 0.0106, 0.0000, 0.0082, 0.0000,\n",
      "        0.0070, 0.0000], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 1., 1., 0., 1., 0., 1., 0., 0., 1.])\n",
      "tensor([[1., 0., 0., 0., 1., 0., 1., 0., 1., 1., 0.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0), Probabilities: [0.         0.24392778 0.24392778 0.24392778 0.         0.01214445\n",
      " 0.         0.01214445 0.         0.         0.24392778], Predicted Values: tensor([0.0000, 0.1488, 0.3865, 0.4435, 0.0000, 0.0107, 0.0000, 0.0082, 0.0000,\n",
      "        0.0000, 0.0023], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 1., 1., 0., 1., 0., 0., 1., 1., 0.])\n",
      "tensor([[1., 0., 0., 0., 1., 0., 1., 1., 0., 0., 1.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1), Probabilities: [0.         0.24392778 0.24392778 0.24392778 0.         0.01214445\n",
      " 0.         0.         0.24392778 0.01214445 0.        ], Predicted Values: tensor([0.0000, 0.1434, 0.3722, 0.4273, 0.0000, 0.0103, 0.0000, 0.0000, 0.0399,\n",
      "        0.0068, 0.0000], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 1., 1., 0., 1., 0., 0., 1., 0., 1.])\n",
      "tensor([[1., 0., 0., 0., 1., 0., 1., 1., 0., 1., 0.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0), Probabilities: [0.         0.19802815 0.19802815 0.19802815 0.         0.00985924\n",
      " 0.         0.         0.19802815 0.         0.19802815], Predicted Values: tensor([0.0000, 0.1441, 0.3742, 0.4297, 0.0000, 0.0103, 0.0000, 0.0000, 0.0402,\n",
      "        0.0000, 0.0014], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 1., 1., 0., 1., 0., 0., 0., 1., 1.])\n",
      "tensor([[1., 0., 0., 0., 1., 0., 1., 1., 1., 0., 0.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0), Probabilities: [0.         0.24392778 0.24392778 0.24392778 0.         0.01214445\n",
      " 0.         0.         0.         0.24392778 0.01214445], Predicted Values: tensor([0.0000, 0.1492, 0.3873, 0.4443, 0.0000, 0.0107, 0.0000, 0.0000, 0.0000,\n",
      "        0.0071, 0.0015], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 1., 1., 0., 0., 1., 1., 1., 0., 0.])\n",
      "tensor([[1., 0., 0., 0., 1., 1., 0., 0., 0., 1., 1.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1), Probabilities: [0.         0.19802815 0.19802815 0.19802815 0.         0.\n",
      " 0.19802815 0.19802815 0.00985924 0.         0.        ], Predicted Values: tensor([0.0000, 0.1484, 0.3862, 0.4436, 0.0000, 0.0000, 0.0096, 0.0082, 0.0040,\n",
      "        0.0000, 0.0000], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 1., 1., 0., 0., 1., 1., 0., 1., 0.])\n",
      "tensor([[1., 0., 0., 0., 1., 1., 0., 0., 1., 0., 1.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1), Probabilities: [0.         0.16666667 0.16666667 0.16666667 0.         0.\n",
      " 0.16666667 0.16666667 0.         0.16666667 0.        ], Predicted Values: tensor([0.0000, 0.1484, 0.3861, 0.4430, 0.0000, 0.0000, 0.0096, 0.0082, 0.0000,\n",
      "        0.0048, 0.0000], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 1., 1., 0., 0., 1., 1., 0., 0., 1.])\n",
      "tensor([[1., 0., 0., 0., 1., 1., 0., 0., 1., 1., 0.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0), Probabilities: [0.         0.16666667 0.16666667 0.16666667 0.         0.\n",
      " 0.16666667 0.16666667 0.         0.         0.16666667], Predicted Values: tensor([0.0000, 0.1488, 0.3875, 0.4447, 0.0000, 0.0000, 0.0096, 0.0082, 0.0000,\n",
      "        0.0000, 0.0012], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 1., 1., 0., 0., 1., 0., 1., 1., 0.])\n",
      "tensor([[1., 0., 0., 0., 1., 1., 0., 1., 0., 0., 1.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1), Probabilities: [0.         0.23403215 0.23403215 0.23403215 0.         0.\n",
      " 0.23403215 0.         0.05221963 0.01165177 0.        ], Predicted Values: tensor([0.0000, 0.1455, 0.3785, 0.4346, 0.0000, 0.0000, 0.0010, 0.0000, 0.0357,\n",
      "        0.0047, 0.0000], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 1., 1., 0., 0., 1., 0., 1., 0., 1.])\n",
      "tensor([[1., 0., 0., 0., 1., 1., 0., 1., 0., 1., 0.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0), Probabilities: [0.         0.19145608 0.19145608 0.19145608 0.         0.\n",
      " 0.19145608 0.         0.04271962 0.         0.19145608], Predicted Values: tensor([0.0000, 0.1460, 0.3800, 0.4364, 0.0000, 0.0000, 0.0010, 0.0000, 0.0359,\n",
      "        0.0000, 0.0007], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 1., 1., 0., 0., 1., 0., 0., 1., 1.])\n",
      "tensor([[1., 0., 0., 0., 1., 1., 0., 1., 1., 0., 0.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0), Probabilities: [0.         0.19802815 0.19802815 0.19802815 0.         0.\n",
      " 0.19802815 0.         0.         0.19802815 0.00985924], Predicted Values: tensor([0.0000, 0.1507, 0.3924, 0.4502, 0.0000, 0.0000, 0.0010, 0.0000, 0.0000,\n",
      "        0.0048, 0.0007], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 1., 1., 0., 0., 0., 1., 1., 1., 0.])\n",
      "tensor([[1., 0., 0., 0., 1., 1., 1., 0., 0., 0., 1.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1), Probabilities: [0.         0.23403215 0.23403215 0.23403215 0.         0.\n",
      " 0.         0.23403215 0.05221963 0.01165177 0.        ], Predicted Values: tensor([0.0000, 0.1492, 0.3881, 0.4451, 0.0000, 0.0000, 0.0000, 0.0083, 0.0045,\n",
      "        0.0048, 0.0000], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 1., 1., 0., 0., 0., 1., 1., 0., 1.])\n",
      "tensor([[1., 0., 0., 0., 1., 1., 1., 0., 0., 1., 0.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0), Probabilities: [0.         0.19145608 0.19145608 0.19145608 0.         0.\n",
      " 0.         0.19145608 0.04271962 0.         0.19145608], Predicted Values: tensor([0.0000, 0.1497, 0.3895, 0.4469, 0.0000, 0.0000, 0.0000, 0.0083, 0.0046,\n",
      "        0.0000, 0.0011], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 1., 1., 0., 0., 0., 1., 0., 1., 1.])\n",
      "tensor([[1., 0., 0., 0., 1., 1., 1., 0., 1., 0., 0.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0), Probabilities: [0.         0.19802815 0.19802815 0.19802815 0.         0.\n",
      " 0.         0.19802815 0.         0.19802815 0.00985924], Predicted Values: tensor([0.0000, 0.1497, 0.3896, 0.4465, 0.0000, 0.0000, 0.0000, 0.0083, 0.0000,\n",
      "        0.0048, 0.0011], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 1., 1., 0., 0., 0., 0., 1., 1., 1.])\n",
      "tensor([[1., 0., 0., 0., 1., 1., 1., 1., 0., 0., 0.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0), Probabilities: [0.         0.24392778 0.24392778 0.24392778 0.         0.\n",
      " 0.         0.         0.24392778 0.01214445 0.01214445], Predicted Values: tensor([0.0000, 0.1449, 0.3769, 0.4324, 0.0000, 0.0000, 0.0000, 0.0000, 0.0404,\n",
      "        0.0047, 0.0007], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 1., 0., 1., 1., 1., 1., 0., 0., 0.])\n",
      "tensor([[1., 0., 0., 1., 0., 0., 0., 0., 1., 1., 1.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1), Probabilities: [0.         0.42149785 0.42149785 0.         0.02098514 0.09404888\n",
      " 0.02098514 0.02098514 0.         0.         0.        ], Predicted Values: tensor([0.0000, 0.1521, 0.7980, 0.0000, 0.0099, 0.0316, 0.0051, 0.0034, 0.0000,\n",
      "        0.0000, 0.0000], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 1., 0., 1., 1., 1., 0., 1., 0., 0.])\n",
      "tensor([[1., 0., 0., 1., 0., 0., 0., 1., 0., 1., 1.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1), Probabilities: [0.         0.39279852 0.39279852 0.         0.01955629 0.0876452\n",
      " 0.01955629 0.         0.0876452  0.         0.        ], Predicted Values: tensor([    0.0000,     0.1505,     0.7894,     0.0000,     0.0098,     0.0313,\n",
      "            0.0005,     0.0000,     0.0185,     0.0000,     0.0000],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 1., 0., 1., 1., 1., 0., 0., 1., 0.])\n",
      "tensor([[1., 0., 0., 1., 0., 0., 0., 1., 1., 0., 1.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1), Probabilities: [0.         0.30095967 0.30095967 0.         0.0149839  0.06715318\n",
      " 0.0149839  0.         0.         0.30095967 0.        ], Predicted Values: tensor([    0.0000,     0.1531,     0.8032,     0.0000,     0.0099,     0.0318,\n",
      "            0.0005,     0.0000,     0.0000,     0.0014,     0.0000],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 1., 0., 1., 1., 1., 0., 0., 0., 1.])\n",
      "tensor([[1., 0., 0., 1., 0., 0., 0., 1., 1., 1., 0.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0), Probabilities: [0.         0.30095967 0.30095967 0.         0.0149839  0.06715318\n",
      " 0.0149839  0.         0.         0.         0.30095967], Predicted Values: tensor([    0.0000,     0.1531,     0.8040,     0.0000,     0.0100,     0.0318,\n",
      "            0.0005,     0.0000,     0.0000,     0.0000,     0.0005],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 1., 0., 1., 1., 0., 1., 1., 0., 0.])\n",
      "tensor([[1., 0., 0., 1., 0., 0., 1., 0., 0., 1., 1.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1), Probabilities: [0.         0.39279852 0.39279852 0.         0.01955629 0.0876452\n",
      " 0.         0.01955629 0.0876452  0.         0.        ], Predicted Values: tensor([0.0000, 0.1525, 0.8001, 0.0000, 0.0099, 0.0317, 0.0000, 0.0034, 0.0023,\n",
      "        0.0000, 0.0000], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 1., 0., 1., 1., 0., 1., 0., 1., 0.])\n",
      "tensor([[1., 0., 0., 1., 0., 0., 1., 0., 1., 0., 1.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1), Probabilities: [0.         0.30095967 0.30095967 0.         0.0149839  0.06715318\n",
      " 0.         0.0149839  0.         0.30095967 0.        ], Predicted Values: tensor([0.0000, 0.1527, 0.8009, 0.0000, 0.0099, 0.0317, 0.0000, 0.0034, 0.0000,\n",
      "        0.0014, 0.0000], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 1., 0., 1., 1., 0., 1., 0., 0., 1.])\n",
      "tensor([[1., 0., 0., 1., 0., 0., 1., 0., 1., 1., 0.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0), Probabilities: [0.         0.30095967 0.30095967 0.         0.0149839  0.06715318\n",
      " 0.         0.0149839  0.         0.         0.30095967], Predicted Values: tensor([    0.0000,     0.1527,     0.8015,     0.0000,     0.0099,     0.0317,\n",
      "            0.0000,     0.0034,     0.0000,     0.0000,     0.0007],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 1., 0., 1., 1., 0., 0., 1., 1., 0.])\n",
      "tensor([[1., 0., 0., 1., 0., 0., 1., 1., 0., 0., 1.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1), Probabilities: [0.         0.30095967 0.30095967 0.         0.0149839  0.06715318\n",
      " 0.         0.         0.30095967 0.0149839  0.        ], Predicted Values: tensor([0.0000, 0.1501, 0.7867, 0.0000, 0.0098, 0.0312, 0.0000, 0.0000, 0.0209,\n",
      "        0.0013, 0.0000], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 1., 0., 1., 1., 0., 0., 1., 0., 1.])\n",
      "tensor([[1., 0., 0., 1., 0., 0., 1., 1., 0., 1., 0.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0), Probabilities: [0.         0.23403215 0.23403215 0.         0.01165177 0.05221963\n",
      " 0.         0.         0.23403215 0.         0.23403215], Predicted Values: tensor([    0.0000,     0.1501,     0.7875,     0.0000,     0.0098,     0.0312,\n",
      "            0.0000,     0.0000,     0.0210,     0.0000,     0.0005],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 1., 0., 1., 1., 0., 0., 0., 1., 1.])\n",
      "tensor([[1., 0., 0., 1., 0., 0., 1., 1., 1., 0., 0.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0), Probabilities: [0.         0.30095967 0.30095967 0.         0.0149839  0.06715318\n",
      " 0.         0.         0.         0.30095967 0.0149839 ], Predicted Values: tensor([    0.0000,     0.1531,     0.8033,     0.0000,     0.0100,     0.0318,\n",
      "            0.0000,     0.0000,     0.0000,     0.0014,     0.0005],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 1., 0., 1., 0., 1., 1., 1., 0., 0.])\n",
      "tensor([[1., 0., 0., 1., 0., 1., 0., 0., 0., 1., 1.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1), Probabilities: [0.         0.31752471 0.31752471 0.         0.01580862 0.\n",
      " 0.01580862 0.31752471 0.01580862 0.         0.        ], Predicted Values: tensor([0.0000, 0.1559, 0.8198, 0.0000, 0.0101, 0.0000, 0.0086, 0.0035, 0.0021,\n",
      "        0.0000, 0.0000], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 1., 0., 1., 0., 1., 1., 0., 1., 0.])\n",
      "tensor([[1., 0., 0., 1., 0., 1., 0., 0., 1., 0., 1.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1), Probabilities: [0.         0.24392778 0.24392778 0.         0.01214445 0.\n",
      " 0.01214445 0.24392778 0.         0.24392778 0.        ], Predicted Values: tensor([0.0000, 0.1561, 0.8208, 0.0000, 0.0101, 0.0000, 0.0086, 0.0035, 0.0000,\n",
      "        0.0009, 0.0000], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 1., 0., 1., 0., 1., 1., 0., 0., 1.])\n",
      "tensor([[1., 0., 0., 1., 0., 1., 0., 0., 1., 1., 0.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0), Probabilities: [0.         0.24392778 0.24392778 0.         0.01214445 0.\n",
      " 0.01214445 0.24392778 0.         0.         0.24392778], Predicted Values: tensor([    0.0000,     0.1561,     0.8214,     0.0000,     0.0101,     0.0000,\n",
      "            0.0085,     0.0035,     0.0000,     0.0000,     0.0004],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 1., 0., 1., 0., 1., 0., 1., 1., 0.])\n",
      "tensor([[1., 0., 0., 1., 0., 1., 0., 1., 0., 0., 1.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1), Probabilities: [0.         0.42149785 0.42149785 0.         0.02098514 0.\n",
      " 0.02098514 0.         0.09404888 0.02098514 0.        ], Predicted Values: tensor([0.0000, 0.1549, 0.8142, 0.0000, 0.0101, 0.0000, 0.0009, 0.0000, 0.0190,\n",
      "        0.0009, 0.0000], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 1., 0., 1., 0., 1., 0., 1., 0., 1.])\n",
      "tensor([[1., 0., 0., 1., 0., 1., 0., 1., 0., 1., 0.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0), Probabilities: [0.         0.30095967 0.30095967 0.         0.0149839  0.\n",
      " 0.0149839  0.         0.06715318 0.         0.30095967], Predicted Values: tensor([    0.0000,     0.1549,     0.8148,     0.0000,     0.0101,     0.0000,\n",
      "            0.0009,     0.0000,     0.0191,     0.0000,     0.0002],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 1., 0., 1., 0., 1., 0., 0., 1., 1.])\n",
      "tensor([[1., 0., 0., 1., 0., 1., 0., 1., 1., 0., 0.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0), Probabilities: [0.         0.31752471 0.31752471 0.         0.01580862 0.\n",
      " 0.01580862 0.         0.         0.31752471 0.01580862], Predicted Values: tensor([    0.0000,     0.1578,     0.8299,     0.0000,     0.0103,     0.0000,\n",
      "            0.0009,     0.0000,     0.0000,     0.0009,     0.0002],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 1., 0., 1., 0., 0., 1., 1., 1., 0.])\n",
      "tensor([[1., 0., 0., 1., 0., 1., 1., 0., 0., 0., 1.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1), Probabilities: [0.         0.30095967 0.30095967 0.         0.0149839  0.\n",
      " 0.         0.30095967 0.06715318 0.0149839  0.        ], Predicted Values: tensor([0.0000, 0.1571, 0.8258, 0.0000, 0.0102, 0.0000, 0.0000, 0.0035, 0.0024,\n",
      "        0.0009, 0.0000], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 1., 0., 1., 0., 0., 1., 1., 0., 1.])\n",
      "tensor([[1., 0., 0., 1., 0., 1., 1., 0., 0., 1., 0.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0), Probabilities: [0.         0.23403215 0.23403215 0.         0.01165177 0.\n",
      " 0.         0.23403215 0.05221963 0.         0.23403215], Predicted Values: tensor([    0.0000,     0.1571,     0.8263,     0.0000,     0.0102,     0.0000,\n",
      "            0.0000,     0.0035,     0.0024,     0.0000,     0.0004],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 1., 0., 1., 0., 0., 1., 0., 1., 1.])\n",
      "tensor([[1., 0., 0., 1., 0., 1., 1., 0., 1., 0., 0.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0), Probabilities: [0.         0.24392778 0.24392778 0.         0.01214445 0.\n",
      " 0.         0.24392778 0.         0.24392778 0.01214445], Predicted Values: tensor([    0.0000,     0.1574,     0.8276,     0.0000,     0.0102,     0.0000,\n",
      "            0.0000,     0.0035,     0.0000,     0.0009,     0.0004],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 1., 0., 1., 0., 0., 0., 1., 1., 1.])\n",
      "tensor([[1., 0., 0., 1., 0., 1., 1., 1., 0., 0., 0.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0), Probabilities: [0.         0.31752471 0.31752471 0.         0.01580862 0.\n",
      " 0.         0.         0.31752471 0.01580862 0.01580862], Predicted Values: tensor([    0.0000,     0.1546,     0.8126,     0.0000,     0.0101,     0.0000,\n",
      "            0.0000,     0.0000,     0.0216,     0.0009,     0.0002],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 1., 0., 0., 1., 1., 1., 1., 0., 0.])\n",
      "tensor([[1., 0., 0., 1., 1., 0., 0., 0., 0., 1., 1.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1), Probabilities: [0.         0.30095967 0.30095967 0.         0.         0.06715318\n",
      " 0.30095967 0.0149839  0.0149839  0.         0.        ], Predicted Values: tensor([0.0000, 0.1528, 0.8012, 0.0000, 0.0000, 0.0317, 0.0051, 0.0071, 0.0021,\n",
      "        0.0000, 0.0000], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 1., 0., 0., 1., 1., 1., 0., 1., 0.])\n",
      "tensor([[1., 0., 0., 1., 1., 0., 0., 0., 1., 0., 1.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1), Probabilities: [0.         0.23403215 0.23403215 0.         0.         0.05221963\n",
      " 0.23403215 0.01165177 0.         0.23403215 0.        ], Predicted Values: tensor([0.0000, 0.1529, 0.8018, 0.0000, 0.0000, 0.0317, 0.0051, 0.0071, 0.0000,\n",
      "        0.0014, 0.0000], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 1., 0., 0., 1., 1., 1., 0., 0., 1.])\n",
      "tensor([[1., 0., 0., 1., 1., 0., 0., 0., 1., 1., 0.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0), Probabilities: [0.         0.23403215 0.23403215 0.         0.         0.05221963\n",
      " 0.23403215 0.01165177 0.         0.         0.23403215], Predicted Values: tensor([    0.0000,     0.1530,     0.8027,     0.0000,     0.0000,     0.0317,\n",
      "            0.0051,     0.0071,     0.0000,     0.0000,     0.0004],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 1., 0., 0., 1., 1., 0., 1., 1., 0.])\n",
      "tensor([[1., 0., 0., 1., 1., 0., 0., 1., 0., 0., 1.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1), Probabilities: [0.         0.28603731 0.28603731 0.         0.         0.06382355\n",
      " 0.28603731 0.         0.06382355 0.01424096 0.        ], Predicted Values: tensor([    0.0000,     0.1519,     0.7960,     0.0000,     0.0000,     0.0315,\n",
      "            0.0005,     0.0000,     0.0187,     0.0013,     0.0000],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 1., 0., 0., 1., 1., 0., 1., 0., 1.])\n",
      "tensor([[1., 0., 0., 1., 1., 0., 0., 1., 0., 1., 0.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0), Probabilities: [0.         0.22490811 0.22490811 0.         0.         0.05018378\n",
      " 0.22490811 0.         0.05018378 0.         0.22490811], Predicted Values: tensor([    0.0000,     0.1520,     0.7969,     0.0000,     0.0000,     0.0315,\n",
      "            0.0005,     0.0000,     0.0188,     0.0000,     0.0003],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 1., 0., 0., 1., 1., 0., 0., 1., 1.])\n",
      "tensor([[1., 0., 0., 1., 1., 0., 0., 1., 1., 0., 0.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0), Probabilities: [0.         0.23403215 0.23403215 0.         0.         0.05221963\n",
      " 0.23403215 0.         0.         0.23403215 0.01165177], Predicted Values: tensor([    0.0000,     0.1546,     0.8111,     0.0000,     0.0000,     0.0321,\n",
      "            0.0005,     0.0000,     0.0000,     0.0014,     0.0003],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 1., 0., 0., 1., 0., 1., 1., 1., 0.])\n",
      "tensor([[1., 0., 0., 1., 1., 0., 1., 0., 0., 0., 1.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1), Probabilities: [0.         0.39279852 0.39279852 0.         0.         0.0876452\n",
      " 0.         0.01955629 0.0876452  0.01955629 0.        ], Predicted Values: tensor([0.0000, 0.1534, 0.8039, 0.0000, 0.0000, 0.0318, 0.0000, 0.0071, 0.0023,\n",
      "        0.0014, 0.0000], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 1., 0., 0., 1., 0., 1., 1., 0., 1.])\n",
      "tensor([[1., 0., 0., 1., 1., 0., 1., 0., 0., 1., 0.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0), Probabilities: [0.         0.28603731 0.28603731 0.         0.         0.06382355\n",
      " 0.         0.01424096 0.06382355 0.         0.28603731], Predicted Values: tensor([    0.0000,     0.1535,     0.8048,     0.0000,     0.0000,     0.0318,\n",
      "            0.0000,     0.0071,     0.0023,     0.0000,     0.0004],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 1., 0., 0., 1., 0., 1., 0., 1., 1.])\n",
      "tensor([[1., 0., 0., 1., 1., 0., 1., 0., 1., 0., 0.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0), Probabilities: [0.         0.30095967 0.30095967 0.         0.         0.06715318\n",
      " 0.         0.0149839  0.         0.30095967 0.0149839 ], Predicted Values: tensor([    0.0000,     0.1536,     0.8056,     0.0000,     0.0000,     0.0319,\n",
      "            0.0000,     0.0071,     0.0000,     0.0014,     0.0004],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 1., 0., 0., 1., 0., 0., 1., 1., 1.])\n",
      "tensor([[1., 0., 0., 1., 1., 0., 1., 1., 0., 0., 0.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0), Probabilities: [0.         0.30095967 0.30095967 0.         0.         0.06715318\n",
      " 0.         0.         0.30095967 0.0149839  0.0149839 ], Predicted Values: tensor([    0.0000,     0.1515,     0.7942,     0.0000,     0.0000,     0.0314,\n",
      "            0.0000,     0.0000,     0.0212,     0.0013,     0.0002],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 1., 0., 0., 0., 1., 1., 1., 1., 0.])\n",
      "tensor([[1., 0., 0., 1., 1., 1., 0., 0., 0., 0., 1.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1), Probabilities: [0.         0.24392778 0.24392778 0.         0.         0.\n",
      " 0.24392778 0.24392778 0.01214445 0.01214445 0.        ], Predicted Values: tensor([0.0000, 0.1569, 0.8242, 0.0000, 0.0000, 0.0000, 0.0086, 0.0073, 0.0021,\n",
      "        0.0009, 0.0000], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 1., 0., 0., 0., 1., 1., 1., 0., 1.])\n",
      "tensor([[1., 0., 0., 1., 1., 1., 0., 0., 0., 1., 0.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0), Probabilities: [0.         0.19802815 0.19802815 0.         0.         0.\n",
      " 0.19802815 0.19802815 0.00985924 0.         0.19802815], Predicted Values: tensor([    0.0000,     0.1569,     0.8249,     0.0000,     0.0000,     0.0000,\n",
      "            0.0086,     0.0073,     0.0021,     0.0000,     0.0002],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 1., 0., 0., 0., 1., 1., 0., 1., 1.])\n",
      "tensor([[1., 0., 0., 1., 1., 1., 0., 0., 1., 0., 0.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0), Probabilities: [0.         0.19802815 0.19802815 0.         0.         0.\n",
      " 0.19802815 0.19802815 0.         0.19802815 0.00985924], Predicted Values: tensor([    0.0000,     0.1571,     0.8259,     0.0000,     0.0000,     0.0000,\n",
      "            0.0086,     0.0073,     0.0000,     0.0009,     0.0002],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 1., 0., 0., 0., 1., 0., 1., 1., 1.])\n",
      "tensor([[1., 0., 0., 1., 1., 1., 0., 1., 0., 0., 0.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0), Probabilities: [0.         0.30095967 0.30095967 0.         0.         0.\n",
      " 0.30095967 0.         0.06715318 0.0149839  0.0149839 ], Predicted Values: tensor([    0.0000,     0.1565,     0.8222,     0.0000,     0.0000,     0.0000,\n",
      "            0.0009,     0.0000,     0.0193,     0.0009,     0.0001],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 1., 0., 0., 0., 0., 1., 1., 1., 1.])\n",
      "tensor([[1., 0., 0., 1., 1., 1., 1., 0., 0., 0., 0.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0), Probabilities: [0.         0.30095967 0.30095967 0.         0.         0.\n",
      " 0.         0.30095967 0.06715318 0.0149839  0.0149839 ], Predicted Values: tensor([    0.0000,     0.1581,     0.8309,     0.0000,     0.0000,     0.0000,\n",
      "            0.0000,     0.0074,     0.0024,     0.0009,     0.0002],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 0., 1., 1., 1., 1., 1., 0., 0., 0.])\n",
      "tensor([[1., 0., 1., 0., 0., 0., 0., 0., 1., 1., 1.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1), Probabilities: [0.         0.39279852 0.         0.39279852 0.0876452  0.0876452\n",
      " 0.01955629 0.01955629 0.         0.         0.        ], Predicted Values: tensor([0.0000, 0.3997, 0.0000, 0.5730, 0.0095, 0.0097, 0.0049, 0.0032, 0.0000,\n",
      "        0.0000, 0.0000], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 0., 1., 1., 1., 1., 0., 1., 0., 0.])\n",
      "tensor([[1., 0., 1., 0., 0., 0., 0., 1., 0., 1., 1.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1), Probabilities: [0.         0.36775826 0.         0.36775826 0.08205796 0.08205796\n",
      " 0.01830961 0.         0.08205796 0.         0.        ], Predicted Values: tensor([    0.0000,     0.3988,     0.0000,     0.5719,     0.0094,     0.0097,\n",
      "            0.0005,     0.0000,     0.0096,     0.0000,     0.0000],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 0., 1., 1., 1., 1., 0., 0., 1., 0.])\n",
      "tensor([[1., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1), Probabilities: [0.         0.28603731 0.         0.28603731 0.06382355 0.06382355\n",
      " 0.01424096 0.         0.         0.28603731 0.        ], Predicted Values: tensor([    0.0000,     0.4020,     0.0000,     0.5760,     0.0095,     0.0098,\n",
      "            0.0005,     0.0000,     0.0000,     0.0022,     0.0000],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 0., 1., 1., 1., 1., 0., 0., 0., 1.])\n",
      "tensor([[1., 0., 1., 0., 0., 0., 0., 1., 1., 1., 0.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0), Probabilities: [0.         0.28603731 0.         0.28603731 0.06382355 0.06382355\n",
      " 0.01424096 0.         0.         0.         0.28603731], Predicted Values: tensor([    0.0000,     0.4023,     0.0000,     0.5770,     0.0095,     0.0098,\n",
      "            0.0005,     0.0000,     0.0000,     0.0000,     0.0008],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 0., 1., 1., 1., 0., 1., 1., 0., 0.])\n",
      "tensor([[1., 0., 1., 0., 0., 0., 1., 0., 0., 1., 1.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1), Probabilities: [0.         0.36775826 0.         0.36775826 0.08205796 0.08205796\n",
      " 0.         0.01830961 0.08205796 0.         0.        ], Predicted Values: tensor([0.0000, 0.4014, 0.0000, 0.5749, 0.0095, 0.0097, 0.0000, 0.0033, 0.0012,\n",
      "        0.0000, 0.0000], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 0., 1., 1., 1., 0., 1., 0., 1., 0.])\n",
      "tensor([[1., 0., 1., 0., 0., 0., 1., 0., 1., 0., 1.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1), Probabilities: [0.         0.28603731 0.         0.28603731 0.06382355 0.06382355\n",
      " 0.         0.01424096 0.         0.28603731 0.        ], Predicted Values: tensor([0.0000, 0.4012, 0.0000, 0.5741, 0.0095, 0.0097, 0.0000, 0.0033, 0.0000,\n",
      "        0.0022, 0.0000], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 0., 1., 1., 1., 0., 1., 0., 0., 1.])\n",
      "tensor([[1., 0., 1., 0., 0., 0., 1., 0., 1., 1., 0.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0), Probabilities: [0.         0.28603731 0.         0.28603731 0.06382355 0.06382355\n",
      " 0.         0.01424096 0.         0.         0.28603731], Predicted Values: tensor([0.0000, 0.4014, 0.0000, 0.5749, 0.0095, 0.0097, 0.0000, 0.0033, 0.0000,\n",
      "        0.0000, 0.0012], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 0., 1., 1., 1., 0., 0., 1., 1., 0.])\n",
      "tensor([[1., 0., 1., 0., 0., 0., 1., 1., 0., 0., 1.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1), Probabilities: [0.         0.28603731 0.         0.28603731 0.06382355 0.06382355\n",
      " 0.         0.         0.28603731 0.01424096 0.        ], Predicted Values: tensor([0.0000, 0.3980, 0.0000, 0.5698, 0.0094, 0.0097, 0.0000, 0.0000, 0.0109,\n",
      "        0.0022, 0.0000], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 0., 1., 1., 1., 0., 0., 1., 0., 1.])\n",
      "tensor([[1., 0., 1., 0., 0., 0., 1., 1., 0., 1., 0.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0), Probabilities: [0.         0.22490811 0.         0.22490811 0.05018378 0.05018378\n",
      " 0.         0.         0.22490811 0.         0.22490811], Predicted Values: tensor([0.0000, 0.3983, 0.0000, 0.5708, 0.0095, 0.0097, 0.0000, 0.0000, 0.0109,\n",
      "        0.0000, 0.0008], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 0., 1., 1., 1., 0., 0., 0., 1., 1.])\n",
      "tensor([[1., 0., 1., 0., 0., 0., 1., 1., 1., 0., 0.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0), Probabilities: [0.         0.28603731 0.         0.28603731 0.06382355 0.06382355\n",
      " 0.         0.         0.         0.28603731 0.01424096], Predicted Values: tensor([0.0000, 0.4021, 0.0000, 0.5756, 0.0095, 0.0098, 0.0000, 0.0000, 0.0000,\n",
      "        0.0022, 0.0008], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 0., 1., 1., 0., 1., 1., 1., 0., 0.])\n",
      "tensor([[1., 0., 1., 0., 0., 1., 0., 0., 0., 1., 1.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1), Probabilities: [0.         0.30095967 0.         0.30095967 0.06715318 0.\n",
      " 0.0149839  0.30095967 0.0149839  0.         0.        ], Predicted Values: tensor([0.0000, 0.4015, 0.0000, 0.5766, 0.0095, 0.0000, 0.0080, 0.0033, 0.0011,\n",
      "        0.0000, 0.0000], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 0., 1., 1., 0., 1., 1., 0., 1., 0.])\n",
      "tensor([[1., 0., 1., 0., 0., 1., 0., 0., 1., 0., 1.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1), Probabilities: [0.         0.23403215 0.         0.23403215 0.05221963 0.\n",
      " 0.01165177 0.23403215 0.         0.23403215 0.        ], Predicted Values: tensor([0.0000, 0.4016, 0.0000, 0.5761, 0.0095, 0.0000, 0.0080, 0.0033, 0.0000,\n",
      "        0.0015, 0.0000], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 0., 1., 1., 0., 1., 1., 0., 0., 1.])\n",
      "tensor([[1., 0., 1., 0., 0., 1., 0., 0., 1., 1., 0.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0), Probabilities: [0.         0.23403215 0.         0.23403215 0.05221963 0.\n",
      " 0.01165177 0.23403215 0.         0.         0.23403215], Predicted Values: tensor([0.0000, 0.4017, 0.0000, 0.5769, 0.0095, 0.0000, 0.0080, 0.0033, 0.0000,\n",
      "        0.0000, 0.0006], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 0., 1., 1., 0., 1., 0., 1., 1., 0.])\n",
      "tensor([[1., 0., 1., 0., 0., 1., 0., 1., 0., 0., 1.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1), Probabilities: [0.         0.39279852 0.         0.39279852 0.0876452  0.\n",
      " 0.01955629 0.         0.0876452  0.01955629 0.        ], Predicted Values: tensor([0.0000, 0.4018, 0.0000, 0.5767, 0.0095, 0.0000, 0.0008, 0.0000, 0.0097,\n",
      "        0.0015, 0.0000], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 0., 1., 1., 0., 1., 0., 1., 0., 1.])\n",
      "tensor([[1., 0., 1., 0., 0., 1., 0., 1., 0., 1., 0.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0), Probabilities: [0.         0.28603731 0.         0.28603731 0.06382355 0.\n",
      " 0.01424096 0.         0.06382355 0.         0.28603731], Predicted Values: tensor([    0.0000,     0.4020,     0.0000,     0.5775,     0.0095,     0.0000,\n",
      "            0.0008,     0.0000,     0.0097,     0.0000,     0.0004],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 0., 1., 1., 0., 1., 0., 0., 1., 1.])\n",
      "tensor([[1., 0., 1., 0., 0., 1., 0., 1., 1., 0., 0.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0), Probabilities: [0.         0.30095967 0.         0.30095967 0.06715318 0.\n",
      " 0.0149839  0.         0.         0.30095967 0.0149839 ], Predicted Values: tensor([    0.0000,     0.4056,     0.0000,     0.5821,     0.0096,     0.0000,\n",
      "            0.0008,     0.0000,     0.0000,     0.0015,     0.0004],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 0., 1., 1., 0., 0., 1., 1., 1., 0.])\n",
      "tensor([[1., 0., 1., 0., 0., 1., 1., 0., 0., 0., 1.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1), Probabilities: [0.         0.28603731 0.         0.28603731 0.06382355 0.\n",
      " 0.         0.28603731 0.06382355 0.01424096 0.        ], Predicted Values: tensor([0.0000, 0.4045, 0.0000, 0.5798, 0.0096, 0.0000, 0.0000, 0.0033, 0.0012,\n",
      "        0.0015, 0.0000], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 0., 1., 1., 0., 0., 1., 1., 0., 1.])\n",
      "tensor([[1., 0., 1., 0., 0., 1., 1., 0., 0., 1., 0.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0), Probabilities: [0.         0.22490811 0.         0.22490811 0.05018378 0.\n",
      " 0.         0.22490811 0.05018378 0.         0.22490811], Predicted Values: tensor([    0.0000,     0.4047,     0.0000,     0.5806,     0.0096,     0.0000,\n",
      "            0.0000,     0.0033,     0.0012,     0.0000,     0.0006],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 0., 1., 1., 0., 0., 1., 0., 1., 1.])\n",
      "tensor([[1., 0., 1., 0., 0., 1., 1., 0., 1., 0., 0.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0), Probabilities: [0.         0.23403215 0.         0.23403215 0.05221963 0.\n",
      " 0.         0.23403215 0.         0.23403215 0.01165177], Predicted Values: tensor([    0.0000,     0.4048,     0.0000,     0.5802,     0.0096,     0.0000,\n",
      "            0.0000,     0.0033,     0.0000,     0.0015,     0.0006],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 0., 1., 1., 0., 0., 0., 1., 1., 1.])\n",
      "tensor([[1., 0., 1., 0., 0., 1., 1., 1., 0., 0., 0.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0), Probabilities: [0.         0.30095967 0.         0.30095967 0.06715318 0.\n",
      " 0.         0.         0.30095967 0.0149839  0.0149839 ], Predicted Values: tensor([    0.0000,     0.4016,     0.0000,     0.5760,     0.0095,     0.0000,\n",
      "            0.0000,     0.0000,     0.0110,     0.0015,     0.0004],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 0., 1., 0., 1., 1., 1., 1., 0., 0.])\n",
      "tensor([[1., 0., 1., 0., 1., 0., 0., 0., 0., 1., 1.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1), Probabilities: [0.         0.30095967 0.         0.30095967 0.         0.06715318\n",
      " 0.30095967 0.0149839  0.0149839  0.         0.        ], Predicted Values: tensor([0.0000, 0.4018, 0.0000, 0.5757, 0.0000, 0.0097, 0.0049, 0.0068, 0.0011,\n",
      "        0.0000, 0.0000], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 0., 1., 0., 1., 1., 1., 0., 1., 0.])\n",
      "tensor([[1., 0., 1., 0., 1., 0., 0., 0., 1., 0., 1.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1), Probabilities: [0.         0.23403215 0.         0.23403215 0.         0.05221963\n",
      " 0.23403215 0.01165177 0.         0.23403215 0.        ], Predicted Values: tensor([0.0000, 0.4016, 0.0000, 0.5748, 0.0000, 0.0097, 0.0049, 0.0068, 0.0000,\n",
      "        0.0022, 0.0000], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 0., 1., 0., 1., 1., 1., 0., 0., 1.])\n",
      "tensor([[1., 0., 1., 0., 1., 0., 0., 0., 1., 1., 0.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0), Probabilities: [0.         0.23403215 0.         0.23403215 0.         0.05221963\n",
      " 0.23403215 0.01165177 0.         0.         0.23403215], Predicted Values: tensor([0.0000, 0.4019, 0.0000, 0.5760, 0.0000, 0.0097, 0.0049, 0.0068, 0.0000,\n",
      "        0.0000, 0.0007], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 0., 1., 0., 1., 1., 0., 1., 1., 0.])\n",
      "tensor([[1., 0., 1., 0., 1., 0., 0., 1., 0., 0., 1.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1), Probabilities: [0.         0.28603731 0.         0.28603731 0.         0.06382355\n",
      " 0.28603731 0.         0.06382355 0.01424096 0.        ], Predicted Values: tensor([    0.0000,     0.4020,     0.0000,     0.5758,     0.0000,     0.0097,\n",
      "            0.0005,     0.0000,     0.0097,     0.0022,     0.0000],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 0., 1., 0., 1., 1., 0., 1., 0., 1.])\n",
      "tensor([[1., 0., 1., 0., 1., 0., 0., 1., 0., 1., 0.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0), Probabilities: [0.         0.22490811 0.         0.22490811 0.         0.05018378\n",
      " 0.22490811 0.         0.05018378 0.         0.22490811], Predicted Values: tensor([    0.0000,     0.4025,     0.0000,     0.5771,     0.0000,     0.0097,\n",
      "            0.0005,     0.0000,     0.0098,     0.0000,     0.0004],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 0., 1., 0., 1., 1., 0., 0., 1., 1.])\n",
      "tensor([[1., 0., 1., 0., 1., 0., 0., 1., 1., 0., 0.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0), Probabilities: [0.         0.23403215 0.         0.23403215 0.         0.05221963\n",
      " 0.23403215 0.         0.         0.23403215 0.01165177], Predicted Values: tensor([    0.0000,     0.4058,     0.0000,     0.5812,     0.0000,     0.0098,\n",
      "            0.0005,     0.0000,     0.0000,     0.0022,     0.0004],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 0., 1., 0., 1., 0., 1., 1., 1., 0.])\n",
      "tensor([[1., 0., 1., 0., 1., 0., 1., 0., 0., 0., 1.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1), Probabilities: [0.         0.39279852 0.         0.39279852 0.         0.0876452\n",
      " 0.         0.01955629 0.0876452  0.01955629 0.        ], Predicted Values: tensor([0.0000, 0.4032, 0.0000, 0.5767, 0.0000, 0.0098, 0.0000, 0.0068, 0.0012,\n",
      "        0.0022, 0.0000], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 0., 1., 0., 1., 0., 1., 1., 0., 1.])\n",
      "tensor([[1., 0., 1., 0., 1., 0., 1., 0., 0., 1., 0.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0), Probabilities: [0.         0.28603731 0.         0.28603731 0.         0.06382355\n",
      " 0.         0.01424096 0.06382355 0.         0.28603731], Predicted Values: tensor([0.0000, 0.4036, 0.0000, 0.5779, 0.0000, 0.0098, 0.0000, 0.0069, 0.0012,\n",
      "        0.0000, 0.0006], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 1.])\n",
      "tensor([[1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 0.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0), Probabilities: [0.         0.30095967 0.         0.30095967 0.         0.06715318\n",
      " 0.         0.0149839  0.         0.30095967 0.0149839 ], Predicted Values: tensor([0.0000, 0.4035, 0.0000, 0.5771, 0.0000, 0.0098, 0.0000, 0.0069, 0.0000,\n",
      "        0.0022, 0.0006], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 0., 1., 0., 1., 0., 0., 1., 1., 1.])\n",
      "tensor([[1., 0., 1., 0., 1., 0., 1., 1., 0., 0., 0.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0), Probabilities: [0.         0.30095967 0.         0.30095967 0.         0.06715318\n",
      " 0.         0.         0.30095967 0.0149839  0.0149839 ], Predicted Values: tensor([    0.0000,     0.4017,     0.0000,     0.5749,     0.0000,     0.0097,\n",
      "            0.0000,     0.0000,     0.0111,     0.0022,     0.0004],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 0., 1., 0., 0., 1., 1., 1., 1., 0.])\n",
      "tensor([[1., 0., 1., 0., 1., 1., 0., 0., 0., 0., 1.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1), Probabilities: [0.         0.24392778 0.         0.24392778 0.         0.\n",
      " 0.24392778 0.24392778 0.01214445 0.01214445 0.        ], Predicted Values: tensor([0.0000, 0.4037, 0.0000, 0.5789, 0.0000, 0.0000, 0.0080, 0.0069, 0.0011,\n",
      "        0.0015, 0.0000], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 0., 1., 0., 0., 1., 1., 1., 0., 1.])\n",
      "tensor([[1., 0., 1., 0., 1., 1., 0., 0., 0., 1., 0.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0), Probabilities: [0.         0.19802815 0.         0.19802815 0.         0.\n",
      " 0.19802815 0.19802815 0.00985924 0.         0.19802815], Predicted Values: tensor([    0.0000,     0.4039,     0.0000,     0.5798,     0.0000,     0.0000,\n",
      "            0.0080,     0.0069,     0.0011,     0.0000,     0.0003],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 0., 1., 0., 0., 1., 1., 0., 1., 1.])\n",
      "tensor([[1., 0., 1., 0., 1., 1., 0., 0., 1., 0., 0.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0), Probabilities: [0.         0.19802815 0.         0.19802815 0.         0.\n",
      " 0.19802815 0.19802815 0.         0.19802815 0.00985924], Predicted Values: tensor([    0.0000,     0.4040,     0.0000,     0.5793,     0.0000,     0.0000,\n",
      "            0.0080,     0.0069,     0.0000,     0.0015,     0.0003],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 0., 1., 0., 0., 1., 0., 1., 1., 1.])\n",
      "tensor([[1., 0., 1., 0., 1., 1., 0., 1., 0., 0., 0.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0), Probabilities: [0.         0.30095967 0.         0.30095967 0.         0.\n",
      " 0.30095967 0.         0.06715318 0.0149839  0.0149839 ], Predicted Values: tensor([    0.0000,     0.4056,     0.0000,     0.5820,     0.0000,     0.0000,\n",
      "            0.0008,     0.0000,     0.0098,     0.0015,     0.0002],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 0., 1., 0., 0., 0., 1., 1., 1., 1.])\n",
      "tensor([[1., 0., 1., 0., 1., 1., 1., 0., 0., 0., 0.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0), Probabilities: [0.         0.30095967 0.         0.30095967 0.         0.\n",
      " 0.         0.30095967 0.06715318 0.0149839  0.0149839 ], Predicted Values: tensor([    0.0000,     0.4069,     0.0000,     0.5831,     0.0000,     0.0000,\n",
      "            0.0000,     0.0070,     0.0012,     0.0015,     0.0003],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 0., 0., 1., 1., 1., 1., 1., 0., 0.])\n",
      "tensor([[1., 0., 1., 1., 0., 0., 0., 0., 0., 1., 1.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1), Probabilities: [0.         0.42149785 0.         0.         0.09404888 0.42149785\n",
      " 0.02098514 0.02098514 0.02098514 0.         0.        ], Predicted Values: tensor([0.0000, 0.9019, 0.0000, 0.0000, 0.0181, 0.0633, 0.0094, 0.0062, 0.0012,\n",
      "        0.0000, 0.0000], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 0., 0., 1., 1., 1., 1., 0., 1., 0.])\n",
      "tensor([[1., 0., 1., 1., 0., 0., 0., 0., 1., 0., 1.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1), Probabilities: [0.         0.30095967 0.         0.         0.06715318 0.30095967\n",
      " 0.0149839  0.0149839  0.         0.30095967 0.        ], Predicted Values: tensor([0.0000, 0.9022, 0.0000, 0.0000, 0.0180, 0.0633, 0.0094, 0.0062, 0.0000,\n",
      "        0.0009, 0.0000], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 0., 0., 1., 1., 1., 1., 0., 0., 1.])\n",
      "tensor([[1., 0., 1., 1., 0., 0., 0., 0., 1., 1., 0.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0), Probabilities: [0.         0.30095967 0.         0.         0.06715318 0.30095967\n",
      " 0.0149839  0.0149839  0.         0.         0.30095967], Predicted Values: tensor([    0.0000,     0.9026,     0.0000,     0.0000,     0.0181,     0.0633,\n",
      "            0.0094,     0.0062,     0.0000,     0.0000,     0.0005],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 0., 0., 1., 1., 1., 0., 1., 1., 0.])\n",
      "tensor([[1., 0., 1., 1., 0., 0., 0., 1., 0., 0., 1.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1), Probabilities: [0.         0.39279852 0.         0.         0.0876452  0.39279852\n",
      " 0.01955629 0.         0.0876452  0.01955629 0.        ], Predicted Values: tensor([0.0000, 0.9054, 0.0000, 0.0000, 0.0181, 0.0636, 0.0010, 0.0000, 0.0110,\n",
      "        0.0009, 0.0000], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 0., 0., 1., 1., 1., 0., 1., 0., 1.])\n",
      "tensor([[1., 0., 1., 1., 0., 0., 0., 1., 0., 1., 0.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0), Probabilities: [0.         0.28603731 0.         0.         0.06382355 0.28603731\n",
      " 0.01424096 0.         0.06382355 0.         0.28603731], Predicted Values: tensor([    0.0000,     0.9059,     0.0000,     0.0000,     0.0182,     0.0636,\n",
      "            0.0010,     0.0000,     0.0110,     0.0000,     0.0003],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 0., 0., 1., 1., 1., 0., 0., 1., 1.])\n",
      "tensor([[1., 0., 1., 1., 0., 0., 0., 1., 1., 0., 0.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0), Probabilities: [0.         0.30095967 0.         0.         0.06715318 0.30095967\n",
      " 0.0149839  0.         0.         0.30095967 0.0149839 ], Predicted Values: tensor([    0.0000,     0.9152,     0.0000,     0.0000,     0.0183,     0.0642,\n",
      "            0.0010,     0.0000,     0.0000,     0.0009,     0.0003],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 0., 0., 1., 1., 0., 1., 1., 1., 0.])\n",
      "tensor([[1., 0., 1., 1., 0., 0., 1., 0., 0., 0., 1.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1), Probabilities: [0.         0.39279852 0.         0.         0.0876452  0.39279852\n",
      " 0.         0.01955629 0.0876452  0.01955629 0.        ], Predicted Values: tensor([0.0000, 0.9094, 0.0000, 0.0000, 0.0182, 0.0639, 0.0000, 0.0063, 0.0014,\n",
      "        0.0009, 0.0000], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 0., 0., 1., 1., 0., 1., 1., 0., 1.])\n",
      "tensor([[1., 0., 1., 1., 0., 0., 1., 0., 0., 1., 0.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0), Probabilities: [0.         0.28603731 0.         0.         0.06382355 0.28603731\n",
      " 0.         0.01424096 0.06382355 0.         0.28603731], Predicted Values: tensor([    0.0000,     0.9098,     0.0000,     0.0000,     0.0183,     0.0639,\n",
      "            0.0000,     0.0063,     0.0014,     0.0000,     0.0004],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 0., 0., 1., 1., 0., 1., 0., 1., 1.])\n",
      "tensor([[1., 0., 1., 1., 0., 0., 1., 0., 1., 0., 0.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0), Probabilities: [0.         0.30095967 0.         0.         0.06715318 0.30095967\n",
      " 0.         0.0149839  0.         0.30095967 0.0149839 ], Predicted Values: tensor([    0.0000,     0.9102,     0.0000,     0.0000,     0.0183,     0.0639,\n",
      "            0.0000,     0.0063,     0.0000,     0.0009,     0.0004],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 0., 0., 1., 1., 0., 0., 1., 1., 1.])\n",
      "tensor([[1., 0., 1., 1., 0., 0., 1., 1., 0., 0., 0.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0), Probabilities: [0.         0.30095967 0.         0.         0.06715318 0.30095967\n",
      " 0.         0.         0.30095967 0.0149839  0.0149839 ], Predicted Values: tensor([    0.0000,     0.9046,     0.0000,     0.0000,     0.0182,     0.0635,\n",
      "            0.0000,     0.0000,     0.0125,     0.0009,     0.0003],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 0., 0., 1., 0., 1., 1., 1., 1., 0.])\n",
      "tensor([[1., 0., 1., 1., 0., 1., 0., 0., 0., 0., 1.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1), Probabilities: [0.         0.42149785 0.         0.         0.09404888 0.\n",
      " 0.02098514 0.42149785 0.02098514 0.02098514 0.        ], Predicted Values: tensor([    0.0000,     0.9562,     0.0000,     0.0000,     0.0191,     0.0000,\n",
      "            0.0162,     0.0066,     0.0013,     0.0007,     0.0000],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 0., 0., 1., 0., 1., 1., 1., 0., 1.])\n",
      "tensor([[1., 0., 1., 1., 0., 1., 0., 0., 0., 1., 0.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0), Probabilities: [0.         0.30095967 0.         0.         0.06715318 0.\n",
      " 0.0149839  0.30095967 0.0149839  0.         0.30095967], Predicted Values: tensor([    0.0000,     0.9566,     0.0000,     0.0000,     0.0192,     0.0000,\n",
      "            0.0162,     0.0066,     0.0013,     0.0000,     0.0002],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 0., 0., 1., 0., 1., 1., 0., 1., 1.])\n",
      "tensor([[1., 0., 1., 1., 0., 1., 0., 0., 1., 0., 0.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0), Probabilities: [0.         0.30095967 0.         0.         0.06715318 0.\n",
      " 0.0149839  0.30095967 0.         0.30095967 0.0149839 ], Predicted Values: tensor([    0.0000,     0.9572,     0.0000,     0.0000,     0.0192,     0.0000,\n",
      "            0.0161,     0.0066,     0.0000,     0.0007,     0.0002],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 0., 0., 1., 0., 1., 0., 1., 1., 1.])\n",
      "tensor([[1., 0., 1., 1., 0., 1., 0., 1., 0., 0., 0.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0), Probabilities: [0.         0.62671503 0.         0.         0.13983903 0.\n",
      " 0.0312023  0.         0.13983903 0.0312023  0.0312023 ], Predicted Values: tensor([    0.0000,     0.9664,     0.0000,     0.0000,     0.0194,     0.0000,\n",
      "            0.0017,     0.0000,     0.0117,     0.0007,     0.0002],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 0., 0., 1., 0., 0., 1., 1., 1., 1.])\n",
      "tensor([[1., 0., 1., 1., 0., 1., 1., 0., 0., 0., 0.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0), Probabilities: [0.         0.39279852 0.         0.         0.0876452  0.\n",
      " 0.         0.39279852 0.0876452  0.01955629 0.01955629], Predicted Values: tensor([    0.0000,     0.9714,     0.0000,     0.0000,     0.0195,     0.0000,\n",
      "            0.0000,     0.0067,     0.0015,     0.0007,     0.0002],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 0., 0., 0., 1., 1., 1., 1., 1., 0.])\n",
      "tensor([[1., 0., 1., 1., 1., 0., 0., 0., 0., 0., 1.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1), Probabilities: [0.         0.31752471 0.         0.         0.         0.31752471\n",
      " 0.31752471 0.01580862 0.01580862 0.01580862 0.        ], Predicted Values: tensor([0.0000, 0.9116, 0.0000, 0.0000, 0.0000, 0.0639, 0.0094, 0.0130, 0.0012,\n",
      "        0.0009, 0.0000], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 0., 0., 0., 1., 1., 1., 1., 0., 1.])\n",
      "tensor([[1., 0., 1., 1., 1., 0., 0., 0., 0., 1., 0.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0), Probabilities: [0.         0.24392778 0.         0.         0.         0.24392778\n",
      " 0.24392778 0.01214445 0.01214445 0.         0.24392778], Predicted Values: tensor([    0.0000,     0.9122,     0.0000,     0.0000,     0.0000,     0.0639,\n",
      "            0.0094,     0.0130,     0.0012,     0.0000,     0.0003],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 0., 0., 0., 1., 1., 1., 0., 1., 1.])\n",
      "tensor([[1., 0., 1., 1., 1., 0., 0., 0., 1., 0., 0.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0), Probabilities: [0.         0.24392778 0.         0.         0.         0.24392778\n",
      " 0.24392778 0.01214445 0.         0.24392778 0.01214445], Predicted Values: tensor([    0.0000,     0.9125,     0.0000,     0.0000,     0.0000,     0.0639,\n",
      "            0.0094,     0.0130,     0.0000,     0.0009,     0.0003],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 0., 0., 0., 1., 1., 0., 1., 1., 1.])\n",
      "tensor([[1., 0., 1., 1., 1., 0., 0., 1., 0., 0., 0.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0), Probabilities: [0.         0.30095967 0.         0.         0.         0.30095967\n",
      " 0.30095967 0.         0.06715318 0.0149839  0.0149839 ], Predicted Values: tensor([    0.0000,     0.9221,     0.0000,     0.0000,     0.0000,     0.0646,\n",
      "            0.0010,     0.0000,     0.0112,     0.0009,     0.0002],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 0., 0., 0., 1., 0., 1., 1., 1., 1.])\n",
      "tensor([[1., 0., 1., 1., 1., 0., 1., 0., 0., 0., 0.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0), Probabilities: [0.         0.42149785 0.         0.         0.         0.42149785\n",
      " 0.         0.02098514 0.09404888 0.02098514 0.02098514], Predicted Values: tensor([    0.0000,     0.9198,     0.0000,     0.0000,     0.0000,     0.0644,\n",
      "            0.0000,     0.0132,     0.0014,     0.0009,     0.0002],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 0., 0., 0., 0., 1., 1., 1., 1., 1.])\n",
      "tensor([[1., 0., 1., 1., 1., 1., 0., 0., 0., 0., 0.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0), Probabilities: [0.         0.31752471 0.         0.         0.         0.\n",
      " 0.31752471 0.31752471 0.01580862 0.01580862 0.01580862], Predicted Values: tensor([    0.0000,     0.9678,     0.0000,     0.0000,     0.0000,     0.0000,\n",
      "            0.0163,     0.0139,     0.0013,     0.0007,     0.0001],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 1., 1., 1., 1., 1., 1., 0., 0., 0.])\n",
      "tensor([[1., 1., 0., 0., 0., 0., 0., 0., 1., 1., 1.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1), Probabilities: [0.         0.         0.42149785 0.42149785 0.09404888 0.02098514\n",
      " 0.02098514 0.02098514 0.         0.         0.        ], Predicted Values: tensor([0.0000, 0.0000, 0.4610, 0.5104, 0.0080, 0.0136, 0.0042, 0.0028, 0.0000,\n",
      "        0.0000, 0.0000], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 1., 1., 1., 1., 1., 0., 1., 0., 0.])\n",
      "tensor([[1., 1., 0., 0., 0., 0., 0., 1., 0., 1., 1.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1), Probabilities: [0.         0.         0.39279852 0.39279852 0.0876452  0.01955629\n",
      " 0.01955629 0.         0.0876452  0.         0.        ], Predicted Values: tensor([    0.0000,     0.0000,     0.4546,     0.5039,     0.0079,     0.0135,\n",
      "            0.0004,     0.0000,     0.0197,     0.0000,     0.0000],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 1., 1., 1., 1., 1., 0., 0., 1., 0.])\n",
      "tensor([[1., 1., 0., 0., 0., 0., 0., 1., 1., 0., 1.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1), Probabilities: [0.         0.         0.30095967 0.30095967 0.06715318 0.0149839\n",
      " 0.0149839  0.         0.         0.30095967 0.        ], Predicted Values: tensor([    0.0000,     0.0000,     0.4632,     0.5129,     0.0081,     0.0137,\n",
      "            0.0004,     0.0000,     0.0000,     0.0017,     0.0000],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 1., 1., 1., 1., 1., 0., 0., 0., 1.])\n",
      "tensor([[1., 1., 0., 0., 0., 0., 0., 1., 1., 1., 0.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0), Probabilities: [0.         0.         0.30095967 0.30095967 0.06715318 0.0149839\n",
      " 0.0149839  0.         0.         0.         0.30095967], Predicted Values: tensor([    0.0000,     0.0000,     0.4635,     0.5134,     0.0081,     0.0137,\n",
      "            0.0004,     0.0000,     0.0000,     0.0000,     0.0009],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 1., 1., 1., 1., 0., 1., 1., 0., 0.])\n",
      "tensor([[1., 1., 0., 0., 0., 0., 1., 0., 0., 1., 1.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1), Probabilities: [0.         0.         0.39279852 0.39279852 0.0876452  0.01955629\n",
      " 0.         0.01955629 0.0876452  0.         0.        ], Predicted Values: tensor([0.0000, 0.0000, 0.4618, 0.5112, 0.0081, 0.0137, 0.0000, 0.0028, 0.0025,\n",
      "        0.0000, 0.0000], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 1., 1., 1., 1., 0., 1., 0., 1., 0.])\n",
      "tensor([[1., 1., 0., 0., 0., 0., 1., 0., 1., 0., 1.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1), Probabilities: [0.         0.         0.30095967 0.30095967 0.06715318 0.0149839\n",
      " 0.         0.0149839  0.         0.30095967 0.        ], Predicted Values: tensor([0.0000, 0.0000, 0.4624, 0.5114, 0.0081, 0.0137, 0.0000, 0.0028, 0.0000,\n",
      "        0.0017, 0.0000], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 1., 1., 1., 1., 0., 1., 0., 0., 1.])\n",
      "tensor([[1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 0.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0), Probabilities: [0.         0.         0.30095967 0.30095967 0.06715318 0.0149839\n",
      " 0.         0.0149839  0.         0.         0.30095967], Predicted Values: tensor([0.0000, 0.0000, 0.4625, 0.5117, 0.0081, 0.0137, 0.0000, 0.0028, 0.0000,\n",
      "        0.0000, 0.0012], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 1., 1., 1., 1., 0., 0., 1., 1., 0.])\n",
      "tensor([[1., 1., 0., 0., 0., 0., 1., 1., 0., 0., 1.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1), Probabilities: [0.         0.         0.30095967 0.30095967 0.06715318 0.0149839\n",
      " 0.         0.         0.30095967 0.0149839  0.        ], Predicted Values: tensor([0.0000, 0.0000, 0.4531, 0.5016, 0.0079, 0.0134, 0.0000, 0.0000, 0.0222,\n",
      "        0.0017, 0.0000], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 1., 1., 1., 1., 0., 0., 1., 0., 1.])\n",
      "tensor([[1., 1., 0., 0., 0., 0., 1., 1., 0., 1., 0.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0), Probabilities: [0.         0.         0.23403215 0.23403215 0.05221963 0.01165177\n",
      " 0.         0.         0.23403215 0.         0.23403215], Predicted Values: tensor([0.0000, 0.0000, 0.4534, 0.5021, 0.0080, 0.0134, 0.0000, 0.0000, 0.0223,\n",
      "        0.0000, 0.0008], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 1., 1., 1., 1., 0., 0., 0., 1., 1.])\n",
      "tensor([[1., 1., 0., 0., 0., 0., 1., 1., 1., 0., 0.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0), Probabilities: [0.         0.         0.30095967 0.30095967 0.06715318 0.0149839\n",
      " 0.         0.         0.         0.30095967 0.0149839 ], Predicted Values: tensor([0.0000, 0.0000, 0.4633, 0.5124, 0.0081, 0.0137, 0.0000, 0.0000, 0.0000,\n",
      "        0.0017, 0.0008], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 1., 1., 1., 0., 1., 1., 1., 0., 0.])\n",
      "tensor([[1., 1., 0., 0., 0., 1., 0., 0., 0., 1., 1.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1), Probabilities: [0.         0.         0.30095967 0.30095967 0.06715318 0.\n",
      " 0.0149839  0.30095967 0.0149839  0.         0.        ], Predicted Values: tensor([0.0000, 0.0000, 0.4651, 0.5150, 0.0081, 0.0000, 0.0068, 0.0028, 0.0022,\n",
      "        0.0000, 0.0000], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 1., 1., 1., 0., 1., 1., 0., 1., 0.])\n",
      "tensor([[1., 1., 0., 0., 0., 1., 0., 0., 1., 0., 1.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1), Probabilities: [0.         0.         0.23403215 0.23403215 0.05221963 0.\n",
      " 0.01165177 0.23403215 0.         0.23403215 0.        ], Predicted Values: tensor([0.0000, 0.0000, 0.4658, 0.5152, 0.0081, 0.0000, 0.0068, 0.0028, 0.0000,\n",
      "        0.0012, 0.0000], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 1., 1., 1., 0., 1., 1., 0., 0., 1.])\n",
      "tensor([[1., 1., 0., 0., 0., 1., 0., 0., 1., 1., 0.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0), Probabilities: [0.         0.         0.23403215 0.23403215 0.05221963 0.\n",
      " 0.01165177 0.23403215 0.         0.         0.23403215], Predicted Values: tensor([0.0000, 0.0000, 0.4660, 0.5156, 0.0081, 0.0000, 0.0068, 0.0028, 0.0000,\n",
      "        0.0000, 0.0006], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 1., 1., 1., 0., 1., 0., 1., 1., 0.])\n",
      "tensor([[1., 1., 0., 0., 0., 1., 0., 1., 0., 0., 1.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1), Probabilities: [0.         0.         0.39279852 0.39279852 0.0876452  0.\n",
      " 0.01955629 0.         0.0876452  0.01955629 0.        ], Predicted Values: tensor([0.0000, 0.0000, 0.4604, 0.5098, 0.0080, 0.0000, 0.0007, 0.0000, 0.0199,\n",
      "        0.0012, 0.0000], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 1., 1., 1., 0., 1., 0., 1., 0., 1.])\n",
      "tensor([[1., 1., 0., 0., 0., 1., 0., 1., 0., 1., 0.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0), Probabilities: [0.         0.         0.28603731 0.28603731 0.06382355 0.\n",
      " 0.01424096 0.         0.06382355 0.         0.28603731], Predicted Values: tensor([    0.0000,     0.0000,     0.4607,     0.5102,     0.0080,     0.0000,\n",
      "            0.0007,     0.0000,     0.0199,     0.0000,     0.0004],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 1., 1., 1., 0., 1., 0., 0., 1., 1.])\n",
      "tensor([[1., 1., 0., 0., 0., 1., 0., 1., 1., 0., 0.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0), Probabilities: [0.         0.         0.30095967 0.30095967 0.06715318 0.\n",
      " 0.0149839  0.         0.         0.30095967 0.0149839 ], Predicted Values: tensor([    0.0000,     0.0000,     0.4698,     0.5197,     0.0082,     0.0000,\n",
      "            0.0007,     0.0000,     0.0000,     0.0012,     0.0004],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 1., 1., 1., 0., 0., 1., 1., 1., 0.])\n",
      "tensor([[1., 1., 0., 0., 0., 1., 1., 0., 0., 0., 1.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1), Probabilities: [0.         0.         0.28603731 0.28603731 0.06382355 0.\n",
      " 0.         0.28603731 0.06382355 0.01424096 0.        ], Predicted Values: tensor([0.0000, 0.0000, 0.4679, 0.5174, 0.0082, 0.0000, 0.0000, 0.0028, 0.0025,\n",
      "        0.0012, 0.0000], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 1., 1., 1., 0., 0., 1., 1., 0., 1.])\n",
      "tensor([[1., 1., 0., 0., 0., 1., 1., 0., 0., 1., 0.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0), Probabilities: [0.         0.         0.22490811 0.22490811 0.05018378 0.\n",
      " 0.         0.22490811 0.05018378 0.         0.22490811], Predicted Values: tensor([0.0000, 0.0000, 0.4681, 0.5178, 0.0082, 0.0000, 0.0000, 0.0028, 0.0025,\n",
      "        0.0000, 0.0006], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 1., 1., 1., 0., 0., 1., 0., 1., 1.])\n",
      "tensor([[1., 1., 0., 0., 0., 1., 1., 0., 1., 0., 0.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0), Probabilities: [0.         0.         0.23403215 0.23403215 0.05221963 0.\n",
      " 0.         0.23403215 0.         0.23403215 0.01165177], Predicted Values: tensor([0.0000, 0.0000, 0.4690, 0.5182, 0.0082, 0.0000, 0.0000, 0.0028, 0.0000,\n",
      "        0.0012, 0.0006], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 1., 1., 1., 0., 0., 0., 1., 1., 1.])\n",
      "tensor([[1., 1., 0., 0., 0., 1., 1., 1., 0., 0., 0.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0), Probabilities: [0.         0.         0.30095967 0.30095967 0.06715318 0.\n",
      " 0.         0.         0.30095967 0.0149839  0.0149839 ], Predicted Values: tensor([    0.0000,     0.0000,     0.4596,     0.5083,     0.0080,     0.0000,\n",
      "            0.0000,     0.0000,     0.0225,     0.0011,     0.0004],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 1., 1., 0., 1., 1., 1., 1., 0., 0.])\n",
      "tensor([[1., 1., 0., 0., 1., 0., 0., 0., 0., 1., 1.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1), Probabilities: [0.         0.         0.31752471 0.31752471 0.         0.01580862\n",
      " 0.31752471 0.01580862 0.01580862 0.         0.        ], Predicted Values: tensor([0.0000, 0.0000, 0.4621, 0.5121, 0.0000, 0.0136, 0.0042, 0.0058, 0.0022,\n",
      "        0.0000, 0.0000], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 1., 1., 0., 1., 1., 1., 0., 1., 0.])\n",
      "tensor([[1., 1., 0., 0., 1., 0., 0., 0., 1., 0., 1.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1), Probabilities: [0.         0.         0.24392778 0.24392778 0.         0.01214445\n",
      " 0.24392778 0.01214445 0.         0.24392778 0.        ], Predicted Values: tensor([0.0000, 0.0000, 0.4626, 0.5121, 0.0000, 0.0137, 0.0042, 0.0058, 0.0000,\n",
      "        0.0017, 0.0000], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 1., 1., 0., 1., 1., 1., 0., 0., 1.])\n",
      "tensor([[1., 1., 0., 0., 1., 0., 0., 0., 1., 1., 0.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0), Probabilities: [0.         0.         0.24392778 0.24392778 0.         0.01214445\n",
      " 0.24392778 0.01214445 0.         0.         0.24392778], Predicted Values: tensor([0.0000, 0.0000, 0.4630, 0.5127, 0.0000, 0.0137, 0.0042, 0.0058, 0.0000,\n",
      "        0.0000, 0.0007], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 1., 1., 0., 1., 1., 0., 1., 1., 0.])\n",
      "tensor([[1., 1., 0., 0., 1., 0., 0., 1., 0., 0., 1.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1), Probabilities: [0.         0.         0.30095967 0.30095967 0.         0.0149839\n",
      " 0.30095967 0.         0.06715318 0.0149839  0.        ], Predicted Values: tensor([    0.0000,     0.0000,     0.4575,     0.5070,     0.0000,     0.0135,\n",
      "            0.0004,     0.0000,     0.0199,     0.0017,     0.0000],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 1., 1., 0., 1., 1., 0., 1., 0., 1.])\n",
      "tensor([[1., 1., 0., 0., 1., 0., 0., 1., 0., 1., 0.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0), Probabilities: [0.         0.         0.23403215 0.23403215 0.         0.01165177\n",
      " 0.23403215 0.         0.05221963 0.         0.23403215], Predicted Values: tensor([    0.0000,     0.0000,     0.4580,     0.5076,     0.0000,     0.0135,\n",
      "            0.0004,     0.0000,     0.0199,     0.0000,     0.0004],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 1., 1., 0., 1., 1., 0., 0., 1., 1.])\n",
      "tensor([[1., 1., 0., 0., 1., 0., 0., 1., 1., 0., 0.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0), Probabilities: [0.         0.         0.24392778 0.24392778 0.         0.01214445\n",
      " 0.24392778 0.         0.         0.24392778 0.01214445], Predicted Values: tensor([    0.0000,     0.0000,     0.4668,     0.5168,     0.0000,     0.0138,\n",
      "            0.0004,     0.0000,     0.0000,     0.0017,     0.0005],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 1., 1., 0., 1., 0., 1., 1., 1., 0.])\n",
      "tensor([[1., 1., 0., 0., 1., 0., 1., 0., 0., 0., 1.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1), Probabilities: [0.         0.         0.42149785 0.42149785 0.         0.02098514\n",
      " 0.         0.02098514 0.09404888 0.02098514 0.        ], Predicted Values: tensor([0.0000, 0.0000, 0.4634, 0.5129, 0.0000, 0.0137, 0.0000, 0.0058, 0.0025,\n",
      "        0.0017, 0.0000], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 1., 1., 0., 1., 0., 1., 1., 0., 1.])\n",
      "tensor([[1., 1., 0., 0., 1., 0., 1., 0., 0., 1., 0.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0), Probabilities: [0.         0.         0.30095967 0.30095967 0.         0.0149839\n",
      " 0.         0.0149839  0.06715318 0.         0.30095967], Predicted Values: tensor([0.0000, 0.0000, 0.4639, 0.5135, 0.0000, 0.0137, 0.0000, 0.0058, 0.0025,\n",
      "        0.0000, 0.0007], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 1., 1., 0., 1., 0., 1., 0., 1., 1.])\n",
      "tensor([[1., 1., 0., 0., 1., 0., 1., 0., 1., 0., 0.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0), Probabilities: [0.         0.         0.31752471 0.31752471 0.         0.01580862\n",
      " 0.         0.01580862 0.         0.31752471 0.01580862], Predicted Values: tensor([0.0000, 0.0000, 0.4645, 0.5136, 0.0000, 0.0137, 0.0000, 0.0058, 0.0000,\n",
      "        0.0017, 0.0007], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 1., 1., 0., 1., 0., 0., 1., 1., 1.])\n",
      "tensor([[1., 1., 0., 0., 1., 0., 1., 1., 0., 0., 0.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0), Probabilities: [0.         0.         0.31752471 0.31752471 0.         0.01580862\n",
      " 0.         0.         0.31752471 0.01580862 0.01580862], Predicted Values: tensor([    0.0000,     0.0000,     0.4565,     0.5053,     0.0000,     0.0135,\n",
      "            0.0000,     0.0000,     0.0225,     0.0017,     0.0004],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 1., 1., 0., 0., 1., 1., 1., 1., 0.])\n",
      "tensor([[1., 1., 0., 0., 1., 1., 0., 0., 0., 0., 1.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1), Probabilities: [0.         0.         0.24392778 0.24392778 0.         0.\n",
      " 0.24392778 0.24392778 0.01214445 0.01214445 0.        ], Predicted Values: tensor([0.0000, 0.0000, 0.4670, 0.5169, 0.0000, 0.0000, 0.0069, 0.0058, 0.0022,\n",
      "        0.0012, 0.0000], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 1., 1., 0., 0., 1., 1., 1., 0., 1.])\n",
      "tensor([[1., 1., 0., 0., 1., 1., 0., 0., 0., 1., 0.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0), Probabilities: [0.         0.         0.19802815 0.19802815 0.         0.\n",
      " 0.19802815 0.19802815 0.00985924 0.         0.19802815], Predicted Values: tensor([    0.0000,     0.0000,     0.4674,     0.5174,     0.0000,     0.0000,\n",
      "            0.0069,     0.0058,     0.0022,     0.0000,     0.0003],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 1., 1., 0., 0., 1., 1., 0., 1., 1.])\n",
      "tensor([[1., 1., 0., 0., 1., 1., 0., 0., 1., 0., 0.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0), Probabilities: [0.         0.         0.19802815 0.19802815 0.         0.\n",
      " 0.19802815 0.19802815 0.         0.19802815 0.00985924], Predicted Values: tensor([    0.0000,     0.0000,     0.4681,     0.5177,     0.0000,     0.0000,\n",
      "            0.0069,     0.0058,     0.0000,     0.0012,     0.0003],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 1., 1., 0., 0., 1., 0., 1., 1., 1.])\n",
      "tensor([[1., 1., 0., 0., 1., 1., 0., 1., 0., 0., 0.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0), Probabilities: [0.         0.         0.30095967 0.30095967 0.         0.\n",
      " 0.30095967 0.         0.06715318 0.0149839  0.0149839 ], Predicted Values: tensor([    0.0000,     0.0000,     0.4641,     0.5137,     0.0000,     0.0000,\n",
      "            0.0007,     0.0000,     0.0201,     0.0012,     0.0002],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 1., 1., 0., 0., 0., 1., 1., 1., 1.])\n",
      "tensor([[1., 1., 0., 0., 1., 1., 1., 0., 0., 0., 0.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0), Probabilities: [0.         0.         0.30095967 0.30095967 0.         0.\n",
      " 0.         0.30095967 0.06715318 0.0149839  0.0149839 ], Predicted Values: tensor([    0.0000,     0.0000,     0.4702,     0.5199,     0.0000,     0.0000,\n",
      "            0.0000,     0.0059,     0.0025,     0.0012,     0.0003],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 1., 0., 1., 1., 1., 1., 1., 0., 0.])\n",
      "tensor([[1., 1., 0., 1., 0., 0., 0., 0., 0., 1., 1.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1), Probabilities: [0.         0.         0.62671503 0.         0.13983903 0.13983903\n",
      " 0.0312023  0.0312023  0.0312023  0.         0.        ], Predicted Values: tensor([0.0000, 0.0000, 0.9459, 0.0000, 0.0069, 0.0401, 0.0036, 0.0024, 0.0011,\n",
      "        0.0000, 0.0000], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 1., 0., 1., 1., 1., 1., 0., 1., 0.])\n",
      "tensor([[1., 1., 0., 1., 0., 0., 0., 0., 1., 0., 1.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1), Probabilities: [0.         0.         0.39279852 0.         0.0876452  0.0876452\n",
      " 0.01955629 0.01955629 0.         0.39279852 0.        ], Predicted Values: tensor([    0.0000,     0.0000,     0.9467,     0.0000,     0.0069,     0.0401,\n",
      "            0.0036,     0.0024,     0.0000,     0.0003,     0.0000],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 1., 0., 1., 1., 1., 1., 0., 0., 1.])\n",
      "tensor([[1., 1., 0., 1., 0., 0., 0., 0., 1., 1., 0.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0), Probabilities: [0.         0.         0.39279852 0.         0.0876452  0.0876452\n",
      " 0.01955629 0.01955629 0.         0.         0.39279852], Predicted Values: tensor([    0.0000,     0.0000,     0.9468,     0.0000,     0.0069,     0.0401,\n",
      "            0.0036,     0.0024,     0.0000,     0.0000,     0.0002],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 1., 0., 1., 1., 1., 0., 1., 1., 0.])\n",
      "tensor([[1., 1., 0., 1., 0., 0., 0., 1., 0., 0., 1.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1), Probabilities: [0.         0.         0.56530243 0.         0.12613602 0.12613602\n",
      " 0.02814475 0.         0.12613602 0.02814475 0.        ], Predicted Values: tensor([    0.0000,     0.0000,     0.9423,     0.0000,     0.0069,     0.0400,\n",
      "            0.0004,     0.0000,     0.0101,     0.0003,     0.0000],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 1., 0., 1., 1., 1., 0., 1., 0., 1.])\n",
      "tensor([[1., 1., 0., 1., 0., 0., 0., 1., 0., 1., 0.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0), Probabilities: [0.         0.         0.36775826 0.         0.08205796 0.08205796\n",
      " 0.01830961 0.         0.08205796 0.         0.36775826], Predicted Values: tensor([    0.0000,     0.0000,     0.9425,     0.0000,     0.0069,     0.0399,\n",
      "            0.0004,     0.0000,     0.0102,     0.0000,     0.0001],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 1., 0., 1., 1., 1., 0., 0., 1., 1.])\n",
      "tensor([[1., 1., 0., 1., 0., 0., 0., 1., 1., 0., 0.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0), Probabilities: [0.         0.         0.39279852 0.         0.0876452  0.0876452\n",
      " 0.01955629 0.         0.         0.39279852 0.01955629], Predicted Values: tensor([    0.0000,     0.0000,     0.9519,     0.0000,     0.0070,     0.0403,\n",
      "            0.0004,     0.0000,     0.0000,     0.0003,     0.0001],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 1., 0., 1., 1., 0., 1., 1., 1., 0.])\n",
      "tensor([[1., 1., 0., 1., 0., 0., 1., 0., 0., 0., 1.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1), Probabilities: [0.         0.         0.56530243 0.         0.12613602 0.12613602\n",
      " 0.         0.02814475 0.12613602 0.02814475 0.        ], Predicted Values: tensor([    0.0000,     0.0000,     0.9488,     0.0000,     0.0070,     0.0402,\n",
      "            0.0000,     0.0024,     0.0013,     0.0003,     0.0000],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 1., 0., 1., 1., 0., 1., 1., 0., 1.])\n",
      "tensor([[1., 1., 0., 1., 0., 0., 1., 0., 0., 1., 0.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0), Probabilities: [0.         0.         0.36775826 0.         0.08205796 0.08205796\n",
      " 0.         0.01830961 0.08205796 0.         0.36775826], Predicted Values: tensor([    0.0000,     0.0000,     0.9490,     0.0000,     0.0070,     0.0402,\n",
      "            0.0000,     0.0024,     0.0013,     0.0000,     0.0002],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 1., 0., 1., 1., 0., 1., 0., 1., 1.])\n",
      "tensor([[1., 1., 0., 1., 0., 0., 1., 0., 1., 0., 0.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0), Probabilities: [0.         0.         0.39279852 0.         0.0876452  0.0876452\n",
      " 0.         0.01955629 0.         0.39279852 0.01955629], Predicted Values: tensor([    0.0000,     0.0000,     0.9499,     0.0000,     0.0070,     0.0402,\n",
      "            0.0000,     0.0024,     0.0000,     0.0003,     0.0002],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 1., 0., 1., 1., 0., 0., 1., 1., 1.])\n",
      "tensor([[1., 1., 0., 1., 0., 0., 1., 1., 0., 0., 0.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0), Probabilities: [0.         0.         0.39279852 0.         0.0876452  0.0876452\n",
      " 0.         0.         0.39279852 0.01955629 0.01955629], Predicted Values: tensor([    0.0000,     0.0000,     0.9412,     0.0000,     0.0069,     0.0399,\n",
      "            0.0000,     0.0000,     0.0115,     0.0003,     0.0001],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 1., 0., 1., 0., 1., 1., 1., 1., 0.])\n",
      "tensor([[1., 1., 0., 1., 0., 1., 0., 0., 0., 0., 1.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1), Probabilities: [0.         0.         0.42149785 0.         0.09404888 0.\n",
      " 0.02098514 0.42149785 0.02098514 0.02098514 0.        ], Predicted Values: tensor([    0.0000,     0.0000,     0.9829,     0.0000,     0.0072,     0.0000,\n",
      "            0.0061,     0.0025,     0.0011,     0.0002,     0.0000],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 1., 0., 1., 0., 1., 1., 1., 0., 1.])\n",
      "tensor([[1., 1., 0., 1., 0., 1., 0., 0., 0., 1., 0.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0), Probabilities: [0.         0.         0.30095967 0.         0.06715318 0.\n",
      " 0.0149839  0.30095967 0.0149839  0.         0.30095967], Predicted Values: tensor([    0.0000,     0.0000,     0.9830,     0.0000,     0.0072,     0.0000,\n",
      "            0.0061,     0.0025,     0.0012,     0.0000,     0.0001],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 1., 0., 1., 0., 1., 1., 0., 1., 1.])\n",
      "tensor([[1., 1., 0., 1., 0., 1., 0., 0., 1., 0., 0.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0), Probabilities: [0.         0.         0.30095967 0.         0.06715318 0.\n",
      " 0.0149839  0.30095967 0.         0.30095967 0.0149839 ], Predicted Values: tensor([    0.0000,     0.0000,     0.9840,     0.0000,     0.0072,     0.0000,\n",
      "            0.0061,     0.0025,     0.0000,     0.0002,     0.0001],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 1., 0., 1., 0., 1., 0., 1., 1., 1.])\n",
      "tensor([[1., 1., 0., 1., 0., 1., 0., 1., 0., 0., 0.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0), Probabilities: [0.         0.         0.62671503 0.         0.13983903 0.\n",
      " 0.0312023  0.         0.13983903 0.0312023  0.0312023 ], Predicted Values: tensor([    0.0000,     0.0000,     0.9814,     0.0000,     0.0072,     0.0000,\n",
      "            0.0006,     0.0000,     0.0105,     0.0002,     0.0001],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 1., 0., 1., 0., 0., 1., 1., 1., 1.])\n",
      "tensor([[1., 1., 0., 1., 0., 1., 1., 0., 0., 0., 0.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0), Probabilities: [0.         0.         0.39279852 0.         0.0876452  0.\n",
      " 0.         0.39279852 0.0876452  0.01955629 0.01955629], Predicted Values: tensor([    0.0000,     0.0000,     0.9886,     0.0000,     0.0072,     0.0000,\n",
      "            0.0000,     0.0025,     0.0013,     0.0002,     0.0001],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 1., 0., 0., 1., 1., 1., 1., 1., 0.])\n",
      "tensor([[1., 1., 0., 1., 1., 0., 0., 0., 0., 0., 1.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1), Probabilities: [0.         0.         0.42149785 0.         0.         0.09404888\n",
      " 0.42149785 0.02098514 0.02098514 0.02098514 0.        ], Predicted Values: tensor([    0.0000,     0.0000,     0.9498,     0.0000,     0.0000,     0.0402,\n",
      "            0.0036,     0.0049,     0.0011,     0.0003,     0.0000],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 1., 0., 0., 1., 1., 1., 1., 0., 1.])\n",
      "tensor([[1., 1., 0., 1., 1., 0., 0., 0., 0., 1., 0.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0), Probabilities: [0.         0.         0.30095967 0.         0.         0.06715318\n",
      " 0.30095967 0.0149839  0.0149839  0.         0.30095967], Predicted Values: tensor([    0.0000,     0.0000,     0.9501,     0.0000,     0.0000,     0.0402,\n",
      "            0.0036,     0.0049,     0.0011,     0.0000,     0.0001],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 1., 0., 0., 1., 1., 1., 0., 1., 1.])\n",
      "tensor([[1., 1., 0., 1., 1., 0., 0., 0., 1., 0., 0.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0), Probabilities: [0.         0.         0.30095967 0.         0.         0.06715318\n",
      " 0.30095967 0.0149839  0.         0.30095967 0.0149839 ], Predicted Values: tensor([    0.0000,     0.0000,     0.9509,     0.0000,     0.0000,     0.0402,\n",
      "            0.0036,     0.0049,     0.0000,     0.0003,     0.0001],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 1., 0., 0., 1., 1., 0., 1., 1., 1.])\n",
      "tensor([[1., 1., 0., 1., 1., 0., 0., 1., 0., 0., 0.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0), Probabilities: [0.         0.         0.39279852 0.         0.         0.0876452\n",
      " 0.39279852 0.         0.0876452  0.01955629 0.01955629], Predicted Values: tensor([    0.0000,     0.0000,     0.9488,     0.0000,     0.0000,     0.0401,\n",
      "            0.0004,     0.0000,     0.0103,     0.0003,     0.0001],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 1., 0., 0., 1., 0., 1., 1., 1., 1.])\n",
      "tensor([[1., 1., 0., 1., 1., 0., 1., 0., 0., 0., 0.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0), Probabilities: [0.         0.         0.62671503 0.         0.         0.13983903\n",
      " 0.         0.0312023  0.13983903 0.0312023  0.0312023 ], Predicted Values: tensor([    0.0000,     0.0000,     0.9530,     0.0000,     0.0000,     0.0403,\n",
      "            0.0000,     0.0050,     0.0013,     0.0003,     0.0001],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 1., 0., 0., 0., 1., 1., 1., 1., 1.])\n",
      "tensor([[1., 1., 0., 1., 1., 1., 0., 0., 0., 0., 0.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0), Probabilities: [0.         0.         0.31752471 0.         0.         0.\n",
      " 0.31752471 0.31752471 0.01580862 0.01580862 0.01580862], Predicted Values: tensor([    0.0000,     0.0000,     0.9873,     0.0000,     0.0000,     0.0000,\n",
      "            0.0061,     0.0052,     0.0012,     0.0002,     0.0001],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 0., 1., 1., 1., 1., 1., 1., 0., 0.])\n",
      "tensor([[1., 1., 1., 0., 0., 0., 0., 0., 0., 1., 1.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1), Probabilities: [0.         0.         0.         0.42149785 0.42149785 0.09404888\n",
      " 0.02098514 0.02098514 0.02098514 0.         0.        ], Predicted Values: tensor([    0.0000,     0.0000,     0.0000,     0.9630,     0.0097,     0.0181,\n",
      "            0.0051,     0.0033,     0.0008,     0.0000,     0.0000],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 0., 1., 1., 1., 1., 1., 0., 1., 0.])\n",
      "tensor([[1., 1., 1., 0., 0., 0., 0., 0., 1., 0., 1.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1), Probabilities: [0.         0.         0.         0.30095967 0.30095967 0.06715318\n",
      " 0.0149839  0.0149839  0.         0.30095967 0.        ], Predicted Values: tensor([    0.0000,     0.0000,     0.0000,     0.9630,     0.0097,     0.0181,\n",
      "            0.0050,     0.0033,     0.0000,     0.0008,     0.0000],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 0., 1., 1., 1., 1., 1., 0., 0., 1.])\n",
      "tensor([[1., 1., 1., 0., 0., 0., 0., 0., 1., 1., 0.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0), Probabilities: [0.         0.         0.         0.30095967 0.30095967 0.06715318\n",
      " 0.0149839  0.0149839  0.         0.         0.30095967], Predicted Values: tensor([    0.0000,     0.0000,     0.0000,     0.9633,     0.0098,     0.0181,\n",
      "            0.0050,     0.0033,     0.0000,     0.0000,     0.0005],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 0., 1., 1., 1., 1., 0., 1., 1., 0.])\n",
      "tensor([[1., 1., 1., 0., 0., 0., 0., 1., 0., 0., 1.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1), Probabilities: [0.         0.         0.         0.39279852 0.39279852 0.0876452\n",
      " 0.01955629 0.         0.0876452  0.01955629 0.        ], Predicted Values: tensor([    0.0000,     0.0000,     0.0000,     0.9631,     0.0097,     0.0181,\n",
      "            0.0005,     0.0000,     0.0077,     0.0008,     0.0000],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 0., 1., 1., 1., 1., 0., 1., 0., 1.])\n",
      "tensor([[1., 1., 1., 0., 0., 0., 0., 1., 0., 1., 0.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0), Probabilities: [0.         0.         0.         0.28603731 0.28603731 0.06382355\n",
      " 0.01424096 0.         0.06382355 0.         0.28603731], Predicted Values: tensor([    0.0000,     0.0000,     0.0000,     0.9636,     0.0098,     0.0181,\n",
      "            0.0005,     0.0000,     0.0077,     0.0000,     0.0003],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 0., 1., 1., 1., 1., 0., 0., 1., 1.])\n",
      "tensor([[1., 1., 1., 0., 0., 0., 0., 1., 1., 0., 0.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0), Probabilities: [0.         0.         0.         0.30095967 0.30095967 0.06715318\n",
      " 0.0149839  0.         0.         0.30095967 0.0149839 ], Predicted Values: tensor([    0.0000,     0.0000,     0.0000,     0.9703,     0.0098,     0.0182,\n",
      "            0.0005,     0.0000,     0.0000,     0.0008,     0.0003],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 0., 1., 1., 1., 0., 1., 1., 1., 0.])\n",
      "tensor([[1., 1., 1., 0., 0., 0., 1., 0., 0., 0., 1.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1), Probabilities: [0.         0.         0.         0.39279852 0.39279852 0.0876452\n",
      " 0.         0.01955629 0.0876452  0.01955629 0.        ], Predicted Values: tensor([    0.0000,     0.0000,     0.0000,     0.9669,     0.0098,     0.0182,\n",
      "            0.0000,     0.0034,     0.0010,     0.0008,     0.0000],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 0., 1., 1., 1., 0., 1., 1., 0., 1.])\n",
      "tensor([[1., 1., 1., 0., 0., 0., 1., 0., 0., 1., 0.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0), Probabilities: [0.         0.         0.         0.28603731 0.28603731 0.06382355\n",
      " 0.         0.01424096 0.06382355 0.         0.28603731], Predicted Values: tensor([    0.0000,     0.0000,     0.0000,     0.9672,     0.0098,     0.0182,\n",
      "            0.0000,     0.0034,     0.0010,     0.0000,     0.0005],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 0., 1., 1., 1., 0., 1., 0., 1., 1.])\n",
      "tensor([[1., 1., 1., 0., 0., 0., 1., 0., 1., 0., 0.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0), Probabilities: [0.         0.         0.         0.30095967 0.30095967 0.06715318\n",
      " 0.         0.0149839  0.         0.30095967 0.0149839 ], Predicted Values: tensor([    0.0000,     0.0000,     0.0000,     0.9673,     0.0098,     0.0182,\n",
      "            0.0000,     0.0034,     0.0000,     0.0008,     0.0005],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 0., 1., 1., 1., 0., 0., 1., 1., 1.])\n",
      "tensor([[1., 1., 1., 0., 0., 0., 1., 1., 0., 0., 0.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0), Probabilities: [0.         0.         0.         0.30095967 0.30095967 0.06715318\n",
      " 0.         0.         0.30095967 0.0149839  0.0149839 ], Predicted Values: tensor([    0.0000,     0.0000,     0.0000,     0.9623,     0.0098,     0.0181,\n",
      "            0.0000,     0.0000,     0.0088,     0.0008,     0.0003],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 0., 1., 1., 0., 1., 1., 1., 1., 0.])\n",
      "tensor([[1., 1., 1., 0., 0., 1., 0., 0., 0., 0., 1.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1), Probabilities: [0.         0.         0.         0.31752471 0.31752471 0.\n",
      " 0.01580862 0.31752471 0.01580862 0.01580862 0.        ], Predicted Values: tensor([    0.0000,     0.0000,     0.0000,     0.9770,     0.0099,     0.0000,\n",
      "            0.0083,     0.0034,     0.0009,     0.0005,     0.0000],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 0., 1., 1., 0., 1., 1., 1., 0., 1.])\n",
      "tensor([[1., 1., 1., 0., 0., 1., 0., 0., 0., 1., 0.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0), Probabilities: [0.         0.         0.         0.24392778 0.24392778 0.\n",
      " 0.01214445 0.24392778 0.01214445 0.         0.24392778], Predicted Values: tensor([    0.0000,     0.0000,     0.0000,     0.9773,     0.0099,     0.0000,\n",
      "            0.0083,     0.0034,     0.0009,     0.0000,     0.0003],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 0., 1., 1., 0., 1., 1., 0., 1., 1.])\n",
      "tensor([[1., 1., 1., 0., 0., 1., 0., 0., 1., 0., 0.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0), Probabilities: [0.         0.         0.         0.24392778 0.24392778 0.\n",
      " 0.01214445 0.24392778 0.         0.24392778 0.01214445], Predicted Values: tensor([    0.0000,     0.0000,     0.0000,     0.9776,     0.0099,     0.0000,\n",
      "            0.0083,     0.0034,     0.0000,     0.0005,     0.0003],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 0., 1., 1., 0., 1., 0., 1., 1., 1.])\n",
      "tensor([[1., 1., 1., 0., 0., 1., 0., 1., 0., 0., 0.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0), Probabilities: [0.         0.         0.         0.42149785 0.42149785 0.\n",
      " 0.02098514 0.         0.09404888 0.02098514 0.02098514], Predicted Values: tensor([    0.0000,     0.0000,     0.0000,     0.9807,     0.0099,     0.0000,\n",
      "            0.0009,     0.0000,     0.0079,     0.0005,     0.0002],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 0., 1., 1., 0., 0., 1., 1., 1., 1.])\n",
      "tensor([[1., 1., 1., 0., 0., 1., 1., 0., 0., 0., 0.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0), Probabilities: [0.         0.         0.         0.30095967 0.30095967 0.\n",
      " 0.         0.30095967 0.06715318 0.0149839  0.0149839 ], Predicted Values: tensor([    0.0000,     0.0000,     0.0000,     0.9848,     0.0100,     0.0000,\n",
      "            0.0000,     0.0035,     0.0010,     0.0005,     0.0002],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 0., 1., 0., 1., 1., 1., 1., 1., 0.])\n",
      "tensor([[1., 1., 1., 0., 1., 0., 0., 0., 0., 0., 1.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1), Probabilities: [0.         0.         0.         0.42149785 0.         0.09404888\n",
      " 0.42149785 0.02098514 0.02098514 0.02098514 0.        ], Predicted Values: tensor([    0.0000,     0.0000,     0.0000,     0.9682,     0.0000,     0.0182,\n",
      "            0.0051,     0.0070,     0.0008,     0.0008,     0.0000],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 0., 1., 0., 1., 1., 1., 1., 0., 1.])\n",
      "tensor([[1., 1., 1., 0., 1., 0., 0., 0., 0., 1., 0.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0), Probabilities: [0.         0.         0.         0.30095967 0.         0.06715318\n",
      " 0.30095967 0.0149839  0.0149839  0.         0.30095967], Predicted Values: tensor([    0.0000,     0.0000,     0.0000,     0.9687,     0.0000,     0.0181,\n",
      "            0.0051,     0.0070,     0.0009,     0.0000,     0.0003],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 0., 1., 0., 1., 1., 1., 0., 1., 1.])\n",
      "tensor([[1., 1., 1., 0., 1., 0., 0., 0., 1., 0., 0.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0), Probabilities: [0.         0.         0.         0.30095967 0.         0.06715318\n",
      " 0.30095967 0.0149839  0.         0.30095967 0.0149839 ], Predicted Values: tensor([    0.0000,     0.0000,     0.0000,     0.9688,     0.0000,     0.0182,\n",
      "            0.0051,     0.0070,     0.0000,     0.0008,     0.0003],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 0., 1., 0., 1., 1., 0., 1., 1., 1.])\n",
      "tensor([[1., 1., 1., 0., 1., 0., 0., 1., 0., 0., 0.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0), Probabilities: [0.         0.         0.         0.39279852 0.         0.0876452\n",
      " 0.39279852 0.         0.0876452  0.01955629 0.01955629], Predicted Values: tensor([    0.0000,     0.0000,     0.0000,     0.9725,     0.0000,     0.0182,\n",
      "            0.0005,     0.0000,     0.0078,     0.0008,     0.0002],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "tensor([[1., 1., 1., 0., 1., 0., 1., 0., 0., 0., 0.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0), Probabilities: [0.         0.         0.         0.62671503 0.         0.13983903\n",
      " 0.         0.0312023  0.13983903 0.0312023  0.0312023 ], Predicted Values: tensor([    0.0000,     0.0000,     0.0000,     0.9727,     0.0000,     0.0183,\n",
      "            0.0000,     0.0071,     0.0010,     0.0008,     0.0003],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 0., 1., 0., 0., 1., 1., 1., 1., 1.])\n",
      "tensor([[1., 1., 1., 0., 1., 1., 0., 0., 0., 0., 0.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0), Probabilities: [0.         0.         0.         0.31752471 0.         0.\n",
      " 0.31752471 0.31752471 0.01580862 0.01580862 0.01580862], Predicted Values: tensor([    0.0000,     0.0000,     0.0000,     0.9830,     0.0000,     0.0000,\n",
      "            0.0084,     0.0071,     0.0009,     0.0005,     0.0001],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 0.])\n",
      "tensor([[1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 1.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1), Probabilities: [0.         0.         0.         0.         0.4547215  0.4547215\n",
      " 0.02263925 0.02263925 0.02263925 0.02263925 0.        ], Predicted Values: tensor([0.0000, 0.0000, 0.0000, 0.0000, 0.1207, 0.7670, 0.0627, 0.0412, 0.0062,\n",
      "        0.0021, 0.0000], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 0., 0., 1., 1., 1., 1., 1., 0., 1.])\n",
      "tensor([[1., 1., 1., 1., 0., 0., 0., 0., 0., 1., 0.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0), Probabilities: [0.         0.         0.         0.         0.31752471 0.31752471\n",
      " 0.01580862 0.01580862 0.01580862 0.         0.31752471], Predicted Values: tensor([0.0000, 0.0000, 0.0000, 0.0000, 0.1211, 0.7673, 0.0627, 0.0413, 0.0062,\n",
      "        0.0000, 0.0013], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 0., 0., 1., 1., 1., 1., 0., 1., 1.])\n",
      "tensor([[1., 1., 1., 1., 0., 0., 0., 0., 1., 0., 0.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0), Probabilities: [0.         0.         0.         0.         0.31752471 0.31752471\n",
      " 0.01580862 0.01580862 0.         0.31752471 0.01580862], Predicted Values: tensor([0.0000, 0.0000, 0.0000, 0.0000, 0.1215, 0.7707, 0.0629, 0.0415, 0.0000,\n",
      "        0.0021, 0.0013], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 0., 0., 1., 1., 1., 0., 1., 1., 1.])\n",
      "tensor([[1., 1., 1., 1., 0., 0., 0., 1., 0., 0., 0.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0), Probabilities: [0.         0.         0.         0.         0.42149785 0.42149785\n",
      " 0.02098514 0.         0.09404888 0.02098514 0.02098514], Predicted Values: tensor([0.0000, 0.0000, 0.0000, 0.0000, 0.1268, 0.8035, 0.0069, 0.0000, 0.0597,\n",
      "        0.0022, 0.0009], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 0., 0., 1., 1., 0., 1., 1., 1., 1.])\n",
      "tensor([[1., 1., 1., 1., 0., 0., 1., 0., 0., 0., 0.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0), Probabilities: [0.         0.         0.         0.         0.42149785 0.42149785\n",
      " 0.         0.02098514 0.09404888 0.02098514 0.02098514], Predicted Values: tensor([0.0000, 0.0000, 0.0000, 0.0000, 0.1289, 0.8159, 0.0000, 0.0442, 0.0075,\n",
      "        0.0022, 0.0013], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 0., 0., 1., 0., 1., 1., 1., 1., 1.])\n",
      "tensor([[1., 1., 1., 1., 0., 1., 0., 0., 0., 0., 0.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0), Probabilities: [0.         0.         0.         0.         0.4547215  0.\n",
      " 0.02263925 0.4547215  0.02263925 0.02263925 0.02263925], Predicted Values: tensor([0.0000, 0.0000, 0.0000, 0.0000, 0.4433, 0.0000, 0.3742, 0.1524, 0.0228,\n",
      "        0.0052, 0.0022], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1.])\n",
      "tensor([[1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0), Probabilities: [0.         0.         0.         0.         0.         0.4547215\n",
      " 0.4547215  0.02263925 0.02263925 0.02263925 0.02263925], Predicted Values: tensor([    0.0000,     0.0000,     0.0000,     0.0000,     0.0000,     0.8296,\n",
      "            0.0677,     0.0929,     0.0068,     0.0023,     0.0007],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0.])\n",
      "tensor([[1., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1), Probabilities: [0.         0.32262497 0.32262497 0.32262497 0.01606255 0.01606255\n",
      " 0.         0.         0.         0.         0.        ], Predicted Values: tensor([0.0000, 0.1487, 0.3860, 0.4431, 0.0114, 0.0107, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 1., 1., 1., 0., 1., 0., 0., 0., 0.])\n",
      "tensor([[1., 0., 0., 0., 0., 1., 0., 1., 1., 1., 1.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1), Probabilities: [0.         0.32262497 0.32262497 0.32262497 0.01606255 0.\n",
      " 0.01606255 0.         0.         0.         0.        ], Predicted Values: tensor([0.0000, 0.1498, 0.3900, 0.4477, 0.0115, 0.0000, 0.0010, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 1., 1., 1., 0., 0., 1., 0., 0., 0.])\n",
      "tensor([[1., 0., 0., 0., 0., 1., 1., 0., 1., 1., 1.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1), Probabilities: [0.         0.24692656 0.24692656 0.24692656 0.01229375 0.\n",
      " 0.         0.24692656 0.         0.         0.        ], Predicted Values: tensor([0.0000, 0.1495, 0.3890, 0.4460, 0.0115, 0.0000, 0.0000, 0.0040, 0.0000,\n",
      "        0.0000, 0.0000], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 1., 1., 1., 0., 0., 0., 1., 0., 0.])\n",
      "tensor([[1., 0., 0., 0., 0., 1., 1., 1., 0., 1., 1.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1), Probabilities: [0.         0.24692656 0.24692656 0.24692656 0.01229375 0.\n",
      " 0.         0.         0.24692656 0.         0.        ], Predicted Values: tensor([0.0000, 0.1441, 0.3747, 0.4301, 0.0111, 0.0000, 0.0000, 0.0000, 0.0400,\n",
      "        0.0000, 0.0000], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 1., 1., 1., 0., 0., 0., 0., 1., 0.])\n",
      "tensor([[1., 0., 0., 0., 0., 1., 1., 1., 1., 0., 1.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1), Probabilities: [0.         0.24692656 0.24692656 0.24692656 0.01229375 0.\n",
      " 0.         0.         0.         0.24692656 0.        ], Predicted Values: tensor([0.0000, 0.1494, 0.3887, 0.4456, 0.0115, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0048, 0.0000], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 1., 1., 1., 0., 0., 0., 0., 0., 1.])\n",
      "tensor([[1., 0., 0., 0., 0., 1., 1., 1., 1., 1., 0.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0), Probabilities: [0.         0.24692656 0.24692656 0.24692656 0.01229375 0.\n",
      " 0.         0.         0.         0.         0.24692656], Predicted Values: tensor([0.0000, 0.1498, 0.3900, 0.4473, 0.0115, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0013], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 1., 1., 0., 1., 1., 0., 0., 0., 0.])\n",
      "tensor([[1., 0., 0., 0., 1., 0., 0., 1., 1., 1., 1.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1), Probabilities: [0.         0.24692656 0.24692656 0.24692656 0.         0.01229375\n",
      " 0.24692656 0.         0.         0.         0.        ], Predicted Values: tensor([0.0000, 0.1503, 0.3901, 0.4482, 0.0000, 0.0108, 0.0006, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 1., 1., 0., 1., 0., 1., 0., 0., 0.])\n",
      "tensor([[1., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1), Probabilities: [0.         0.32262497 0.32262497 0.32262497 0.         0.01606255\n",
      " 0.         0.01606255 0.         0.         0.        ], Predicted Values: tensor([0.0000, 0.1493, 0.3873, 0.4445, 0.0000, 0.0107, 0.0000, 0.0082, 0.0000,\n",
      "        0.0000, 0.0000], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 1., 1., 0., 1., 0., 0., 1., 0., 0.])\n",
      "tensor([[1., 0., 0., 0., 1., 0., 1., 1., 0., 1., 1.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1), Probabilities: [0.         0.24692656 0.24692656 0.24692656 0.         0.01229375\n",
      " 0.         0.         0.24692656 0.         0.        ], Predicted Values: tensor([0.0000, 0.1444, 0.3746, 0.4303, 0.0000, 0.0104, 0.0000, 0.0000, 0.0403,\n",
      "        0.0000, 0.0000], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 1., 1., 0., 1., 0., 0., 0., 1., 0.])\n",
      "tensor([[1., 0., 0., 0., 1., 0., 1., 1., 1., 0., 1.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1), Probabilities: [0.         0.24692656 0.24692656 0.24692656 0.         0.01229375\n",
      " 0.         0.         0.         0.24692656 0.        ], Predicted Values: tensor([0.0000, 0.1495, 0.3878, 0.4449, 0.0000, 0.0107, 0.0000, 0.0000, 0.0000,\n",
      "        0.0071, 0.0000], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 1., 1., 0., 1., 0., 0., 0., 0., 1.])\n",
      "tensor([[1., 0., 0., 0., 1., 0., 1., 1., 1., 1., 0.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0), Probabilities: [0.         0.24692656 0.24692656 0.24692656 0.         0.01229375\n",
      " 0.         0.         0.         0.         0.24692656], Predicted Values: tensor([0.0000, 0.1502, 0.3900, 0.4476, 0.0000, 0.0108, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0015], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 1., 1., 0., 0., 1., 1., 0., 0., 0.])\n",
      "tensor([[1., 0., 0., 0., 1., 1., 0., 0., 1., 1., 1.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1), Probabilities: [0.  0.2 0.2 0.2 0.  0.  0.2 0.2 0.  0.  0. ], Predicted Values: tensor([0.0000, 0.1491, 0.3879, 0.4452, 0.0000, 0.0000, 0.0096, 0.0082, 0.0000,\n",
      "        0.0000, 0.0000], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 1., 1., 0., 0., 1., 0., 1., 0., 0.])\n",
      "tensor([[1., 0., 0., 0., 1., 1., 0., 1., 0., 1., 1.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1), Probabilities: [0.         0.23679119 0.23679119 0.23679119 0.         0.\n",
      " 0.23679119 0.         0.05283526 0.         0.        ], Predicted Values: tensor([0.0000, 0.1462, 0.3802, 0.4367, 0.0000, 0.0000, 0.0010, 0.0000, 0.0359,\n",
      "        0.0000, 0.0000], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 1., 1., 0., 0., 1., 0., 0., 1., 0.])\n",
      "tensor([[1., 0., 0., 0., 1., 1., 0., 1., 1., 0., 1.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1), Probabilities: [0.  0.2 0.2 0.2 0.  0.  0.2 0.  0.  0.2 0. ], Predicted Values: tensor([0.0000, 0.1510, 0.3926, 0.4505, 0.0000, 0.0000, 0.0010, 0.0000, 0.0000,\n",
      "        0.0048, 0.0000], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 1., 1., 0., 0., 1., 0., 0., 0., 1.])\n",
      "tensor([[1., 0., 0., 0., 1., 1., 0., 1., 1., 1., 0.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0), Probabilities: [0.  0.2 0.2 0.2 0.  0.  0.2 0.  0.  0.  0.2], Predicted Values: tensor([0.0000, 0.1515, 0.3942, 0.4525, 0.0000, 0.0000, 0.0010, 0.0000, 0.0000,\n",
      "        0.0000, 0.0008], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 1., 1., 0., 0., 0., 1., 1., 0., 0.])\n",
      "tensor([[1., 0., 0., 0., 1., 1., 1., 0., 0., 1., 1.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1), Probabilities: [0.         0.23679119 0.23679119 0.23679119 0.         0.\n",
      " 0.         0.23679119 0.05283526 0.         0.        ], Predicted Values: tensor([0.0000, 0.1500, 0.3898, 0.4473, 0.0000, 0.0000, 0.0000, 0.0083, 0.0046,\n",
      "        0.0000, 0.0000], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 1., 1., 0., 0., 0., 1., 0., 1., 0.])\n",
      "tensor([[1., 0., 0., 0., 1., 1., 1., 0., 1., 0., 1.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1), Probabilities: [0.  0.2 0.2 0.2 0.  0.  0.  0.2 0.  0.2 0. ], Predicted Values: tensor([0.0000, 0.1500, 0.3899, 0.4469, 0.0000, 0.0000, 0.0000, 0.0083, 0.0000,\n",
      "        0.0048, 0.0000], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 1., 1., 0., 0., 0., 1., 0., 0., 1.])\n",
      "tensor([[1., 0., 0., 0., 1., 1., 1., 0., 1., 1., 0.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0), Probabilities: [0.  0.2 0.2 0.2 0.  0.  0.  0.2 0.  0.  0.2], Predicted Values: tensor([0.0000, 0.1504, 0.3914, 0.4487, 0.0000, 0.0000, 0.0000, 0.0084, 0.0000,\n",
      "        0.0000, 0.0011], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 1., 1., 0., 0., 0., 0., 1., 1., 0.])\n",
      "tensor([[1., 0., 0., 0., 1., 1., 1., 1., 0., 0., 1.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1), Probabilities: [0.         0.24692656 0.24692656 0.24692656 0.         0.\n",
      " 0.         0.         0.24692656 0.01229375 0.        ], Predicted Values: tensor([0.0000, 0.1451, 0.3771, 0.4327, 0.0000, 0.0000, 0.0000, 0.0000, 0.0404,\n",
      "        0.0047, 0.0000], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 1., 1., 0., 0., 0., 0., 1., 0., 1.])\n",
      "tensor([[1., 0., 0., 0., 1., 1., 1., 1., 0., 1., 0.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0), Probabilities: [0.  0.2 0.2 0.2 0.  0.  0.  0.  0.2 0.  0.2], Predicted Values: tensor([0.0000, 0.1456, 0.3786, 0.4345, 0.0000, 0.0000, 0.0000, 0.0000, 0.0407,\n",
      "        0.0000, 0.0007], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 1., 1., 0., 0., 0., 0., 0., 1., 1.])\n",
      "tensor([[1., 0., 0., 0., 1., 1., 1., 1., 1., 0., 0.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0), Probabilities: [0.         0.24692656 0.24692656 0.24692656 0.         0.\n",
      " 0.         0.         0.         0.24692656 0.01229375], Predicted Values: tensor([0.0000, 0.1511, 0.3929, 0.4504, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0049, 0.0007], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 1., 0., 1., 1., 1., 0., 0., 0., 0.])\n",
      "tensor([[1., 0., 0., 1., 0., 0., 0., 1., 1., 1., 1.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1), Probabilities: [0.         0.43053263 0.43053263 0.         0.02143496 0.09606482\n",
      " 0.02143496 0.         0.         0.         0.        ], Predicted Values: tensor([    0.0000,     0.1534,     0.8043,     0.0000,     0.0100,     0.0319,\n",
      "            0.0005,     0.0000,     0.0000,     0.0000,     0.0000],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 1., 0., 1., 1., 0., 1., 0., 0., 0.])\n",
      "tensor([[1., 0., 0., 1., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1), Probabilities: [0.         0.43053263 0.43053263 0.         0.02143496 0.09606482\n",
      " 0.         0.02143496 0.         0.         0.        ], Predicted Values: tensor([0.0000, 0.1529, 0.8019, 0.0000, 0.0099, 0.0318, 0.0000, 0.0034, 0.0000,\n",
      "        0.0000, 0.0000], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 1., 0., 1., 1., 0., 0., 1., 0., 0.])\n",
      "tensor([[1., 0., 0., 1., 0., 0., 1., 1., 0., 1., 1.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1), Probabilities: [0.         0.30553782 0.30553782 0.         0.01521183 0.0681747\n",
      " 0.         0.         0.30553782 0.         0.        ], Predicted Values: tensor([0.0000, 0.1503, 0.7877, 0.0000, 0.0098, 0.0313, 0.0000, 0.0000, 0.0210,\n",
      "        0.0000, 0.0000], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 1., 0., 1., 1., 0., 0., 0., 1., 0.])\n",
      "tensor([[1., 0., 0., 1., 0., 0., 1., 1., 1., 0., 1.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1), Probabilities: [0.         0.30553782 0.30553782 0.         0.01521183 0.0681747\n",
      " 0.         0.         0.         0.30553782 0.        ], Predicted Values: tensor([0.0000, 0.1533, 0.8035, 0.0000, 0.0100, 0.0319, 0.0000, 0.0000, 0.0000,\n",
      "        0.0014, 0.0000], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 1., 0., 1., 1., 0., 0., 0., 0., 1.])\n",
      "tensor([[1., 0., 0., 1., 0., 0., 1., 1., 1., 1., 0.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0), Probabilities: [0.         0.30553782 0.30553782 0.         0.01521183 0.0681747\n",
      " 0.         0.         0.         0.         0.30553782], Predicted Values: tensor([    0.0000,     0.1533,     0.8043,     0.0000,     0.0100,     0.0319,\n",
      "            0.0000,     0.0000,     0.0000,     0.0000,     0.0005],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 1., 0., 1., 0., 1., 1., 0., 0., 0.])\n",
      "tensor([[1., 0., 0., 1., 0., 1., 0., 0., 1., 1., 1.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1), Probabilities: [0.         0.32262497 0.32262497 0.         0.01606255 0.\n",
      " 0.01606255 0.32262497 0.         0.         0.        ], Predicted Values: tensor([0.0000, 0.1563, 0.8215, 0.0000, 0.0101, 0.0000, 0.0086, 0.0035, 0.0000,\n",
      "        0.0000, 0.0000], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 1., 0., 1., 0., 1., 0., 1., 0., 0.])\n",
      "tensor([[1., 0., 0., 1., 0., 1., 0., 1., 0., 1., 1.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1), Probabilities: [0.         0.43053263 0.43053263 0.         0.02143496 0.\n",
      " 0.02143496 0.         0.09606482 0.         0.        ], Predicted Values: tensor([0.0000, 0.1551, 0.8149, 0.0000, 0.0101, 0.0000, 0.0009, 0.0000, 0.0191,\n",
      "        0.0000, 0.0000], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 1., 0., 1., 0., 1., 0., 0., 1., 0.])\n",
      "tensor([[1., 0., 0., 1., 0., 1., 0., 1., 1., 0., 1.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1), Probabilities: [0.         0.32262497 0.32262497 0.         0.01606255 0.\n",
      " 0.01606255 0.         0.         0.32262497 0.        ], Predicted Values: tensor([0.0000, 0.1580, 0.8300, 0.0000, 0.0102, 0.0000, 0.0009, 0.0000, 0.0000,\n",
      "        0.0009, 0.0000], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 1., 0., 1., 0., 1., 0., 0., 0., 1.])\n",
      "tensor([[1., 0., 0., 1., 0., 1., 0., 1., 1., 1., 0.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0), Probabilities: [0.         0.32262497 0.32262497 0.         0.01606255 0.\n",
      " 0.01606255 0.         0.         0.         0.32262497], Predicted Values: tensor([    0.0000,     0.1580,     0.8306,     0.0000,     0.0103,     0.0000,\n",
      "            0.0009,     0.0000,     0.0000,     0.0000,     0.0002],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 1., 0., 1., 0., 0., 1., 1., 0., 0.])\n",
      "tensor([[1., 0., 0., 1., 0., 1., 1., 0., 0., 1., 1.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1), Probabilities: [0.         0.30553782 0.30553782 0.         0.01521183 0.\n",
      " 0.         0.30553782 0.0681747  0.         0.        ], Predicted Values: tensor([0.0000, 0.1573, 0.8265, 0.0000, 0.0102, 0.0000, 0.0000, 0.0035, 0.0024,\n",
      "        0.0000, 0.0000], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 1., 0., 1., 0., 0., 1., 0., 1., 0.])\n",
      "tensor([[1., 0., 0., 1., 0., 1., 1., 0., 1., 0., 1.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1), Probabilities: [0.         0.24692656 0.24692656 0.         0.01229375 0.\n",
      " 0.         0.24692656 0.         0.24692656 0.        ], Predicted Values: tensor([0.0000, 0.1576, 0.8277, 0.0000, 0.0102, 0.0000, 0.0000, 0.0035, 0.0000,\n",
      "        0.0009, 0.0000], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 1., 0., 1., 0., 0., 1., 0., 0., 1.])\n",
      "tensor([[1., 0., 0., 1., 0., 1., 1., 0., 1., 1., 0.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0), Probabilities: [0.         0.24692656 0.24692656 0.         0.01229375 0.\n",
      " 0.         0.24692656 0.         0.         0.24692656], Predicted Values: tensor([    0.0000,     0.1575,     0.8283,     0.0000,     0.0102,     0.0000,\n",
      "            0.0000,     0.0035,     0.0000,     0.0000,     0.0004],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 1., 0., 1., 0., 0., 0., 1., 1., 0.])\n",
      "tensor([[1., 0., 0., 1., 0., 1., 1., 1., 0., 0., 1.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1), Probabilities: [0.         0.32262497 0.32262497 0.         0.01606255 0.\n",
      " 0.         0.         0.32262497 0.01606255 0.        ], Predicted Values: tensor([0.0000, 0.1548, 0.8127, 0.0000, 0.0100, 0.0000, 0.0000, 0.0000, 0.0216,\n",
      "        0.0009, 0.0000], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 1., 0., 1., 0., 0., 0., 1., 0., 1.])\n",
      "tensor([[1., 0., 0., 1., 0., 1., 1., 1., 0., 1., 0.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0), Probabilities: [0.         0.24692656 0.24692656 0.         0.01229375 0.\n",
      " 0.         0.         0.24692656 0.         0.24692656], Predicted Values: tensor([    0.0000,     0.1548,     0.8133,     0.0000,     0.0101,     0.0000,\n",
      "            0.0000,     0.0000,     0.0217,     0.0000,     0.0002],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 1., 0., 1., 0., 0., 0., 0., 1., 1.])\n",
      "tensor([[1., 0., 0., 1., 0., 1., 1., 1., 1., 0., 0.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0), Probabilities: [0.         0.32262497 0.32262497 0.         0.01606255 0.\n",
      " 0.         0.         0.         0.32262497 0.01606255], Predicted Values: tensor([    0.0000,     0.1580,     0.8305,     0.0000,     0.0103,     0.0000,\n",
      "            0.0000,     0.0000,     0.0000,     0.0009,     0.0002],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 1., 0., 0., 1., 1., 1., 0., 0., 0.])\n",
      "tensor([[1., 0., 0., 1., 1., 0., 0., 0., 1., 1., 1.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1), Probabilities: [0.         0.30553782 0.30553782 0.         0.         0.0681747\n",
      " 0.30553782 0.01521183 0.         0.         0.        ], Predicted Values: tensor([0.0000, 0.1532, 0.8029, 0.0000, 0.0000, 0.0318, 0.0051, 0.0071, 0.0000,\n",
      "        0.0000, 0.0000], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 1., 0., 0., 1., 1., 0., 1., 0., 0.])\n",
      "tensor([[1., 0., 0., 1., 1., 0., 0., 1., 0., 1., 1.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1), Probabilities: [0.         0.29016961 0.29016961 0.         0.         0.06474559\n",
      " 0.29016961 0.         0.06474559 0.         0.        ], Predicted Values: tensor([    0.0000,     0.1521,     0.7970,     0.0000,     0.0000,     0.0316,\n",
      "            0.0005,     0.0000,     0.0188,     0.0000,     0.0000],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 1., 0., 0., 1., 1., 0., 0., 1., 0.])\n",
      "tensor([[1., 0., 0., 1., 1., 0., 0., 1., 1., 0., 1.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1), Probabilities: [0.         0.23679119 0.23679119 0.         0.         0.05283526\n",
      " 0.23679119 0.         0.         0.23679119 0.        ], Predicted Values: tensor([    0.0000,     0.1548,     0.8111,     0.0000,     0.0000,     0.0321,\n",
      "            0.0005,     0.0000,     0.0000,     0.0014,     0.0000],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 1., 0., 0., 1., 1., 0., 0., 0., 1.])\n",
      "tensor([[1., 0., 0., 1., 1., 0., 0., 1., 1., 1., 0.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0), Probabilities: [0.         0.23679119 0.23679119 0.         0.         0.05283526\n",
      " 0.23679119 0.         0.         0.         0.23679119], Predicted Values: tensor([    0.0000,     0.1549,     0.8122,     0.0000,     0.0000,     0.0321,\n",
      "            0.0005,     0.0000,     0.0000,     0.0000,     0.0003],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 1., 0., 0., 1., 0., 1., 1., 0., 0.])\n",
      "tensor([[1., 0., 0., 1., 1., 0., 1., 0., 0., 1., 1.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1), Probabilities: [0.         0.40063342 0.40063342 0.         0.         0.0893934\n",
      " 0.         0.01994636 0.0893934  0.         0.        ], Predicted Values: tensor([0.0000, 0.1537, 0.8049, 0.0000, 0.0000, 0.0319, 0.0000, 0.0071, 0.0023,\n",
      "        0.0000, 0.0000], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 1., 0., 0., 1., 0., 1., 0., 1., 0.])\n",
      "tensor([[1., 0., 0., 1., 1., 0., 1., 0., 1., 0., 1.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1), Probabilities: [0.         0.30553782 0.30553782 0.         0.         0.0681747\n",
      " 0.         0.01521183 0.         0.30553782 0.        ], Predicted Values: tensor([0.0000, 0.1538, 0.8058, 0.0000, 0.0000, 0.0319, 0.0000, 0.0071, 0.0000,\n",
      "        0.0014, 0.0000], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 1., 0., 0., 1., 0., 1., 0., 0., 1.])\n",
      "tensor([[1., 0., 0., 1., 1., 0., 1., 0., 1., 1., 0.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0), Probabilities: [0.         0.30553782 0.30553782 0.         0.         0.0681747\n",
      " 0.         0.01521183 0.         0.         0.30553782], Predicted Values: tensor([    0.0000,     0.1539,     0.8067,     0.0000,     0.0000,     0.0319,\n",
      "            0.0000,     0.0071,     0.0000,     0.0000,     0.0004],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 1., 0., 0., 1., 0., 0., 1., 1., 0.])\n",
      "tensor([[1., 0., 0., 1., 1., 0., 1., 1., 0., 0., 1.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1), Probabilities: [0.         0.30553782 0.30553782 0.         0.         0.0681747\n",
      " 0.         0.         0.30553782 0.01521183 0.        ], Predicted Values: tensor([0.0000, 0.1517, 0.7942, 0.0000, 0.0000, 0.0315, 0.0000, 0.0000, 0.0212,\n",
      "        0.0013, 0.0000], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 1., 0., 0., 1., 0., 0., 1., 0., 1.])\n",
      "tensor([[1., 0., 0., 1., 1., 0., 1., 1., 0., 1., 0.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0), Probabilities: [0.         0.23679119 0.23679119 0.         0.         0.05283526\n",
      " 0.         0.         0.23679119 0.         0.23679119], Predicted Values: tensor([    0.0000,     0.1518,     0.7952,     0.0000,     0.0000,     0.0315,\n",
      "            0.0000,     0.0000,     0.0213,     0.0000,     0.0002],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 1., 0., 0., 1., 0., 0., 0., 1., 1.])\n",
      "tensor([[1., 0., 0., 1., 1., 0., 1., 1., 1., 0., 0.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0), Probabilities: [0.         0.30553782 0.30553782 0.         0.         0.0681747\n",
      " 0.         0.         0.         0.30553782 0.01521183], Predicted Values: tensor([    0.0000,     0.1548,     0.8114,     0.0000,     0.0000,     0.0321,\n",
      "            0.0000,     0.0000,     0.0000,     0.0014,     0.0002],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 1., 0., 0., 0., 1., 1., 1., 0., 0.])\n",
      "tensor([[1., 0., 0., 1., 1., 1., 0., 0., 0., 1., 1.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1), Probabilities: [0.         0.24692656 0.24692656 0.         0.         0.\n",
      " 0.24692656 0.24692656 0.01229375 0.         0.        ], Predicted Values: tensor([0.0000, 0.1571, 0.8249, 0.0000, 0.0000, 0.0000, 0.0086, 0.0073, 0.0021,\n",
      "        0.0000, 0.0000], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 1., 0., 0., 0., 1., 1., 0., 1., 0.])\n",
      "tensor([[1., 0., 0., 1., 1., 1., 0., 0., 1., 0., 1.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1), Probabilities: [0.  0.2 0.2 0.  0.  0.  0.2 0.2 0.  0.2 0. ], Predicted Values: tensor([0.0000, 0.1573, 0.8259, 0.0000, 0.0000, 0.0000, 0.0086, 0.0073, 0.0000,\n",
      "        0.0009, 0.0000], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 1., 0., 0., 0., 1., 1., 0., 0., 1.])\n",
      "tensor([[1., 0., 0., 1., 1., 1., 0., 0., 1., 1., 0.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0), Probabilities: [0.  0.2 0.2 0.  0.  0.  0.2 0.2 0.  0.  0.2], Predicted Values: tensor([    0.0000,     0.1573,     0.8266,     0.0000,     0.0000,     0.0000,\n",
      "            0.0086,     0.0073,     0.0000,     0.0000,     0.0002],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 1., 0., 0., 0., 1., 0., 1., 1., 0.])\n",
      "tensor([[1., 0., 0., 1., 1., 1., 0., 1., 0., 0., 1.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1), Probabilities: [0.         0.30553782 0.30553782 0.         0.         0.\n",
      " 0.30553782 0.         0.0681747  0.01521183 0.        ], Predicted Values: tensor([0.0000, 0.1566, 0.8222, 0.0000, 0.0000, 0.0000, 0.0009, 0.0000, 0.0193,\n",
      "        0.0009, 0.0000], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 1., 0., 0., 0., 1., 0., 1., 0., 1.])\n",
      "tensor([[1., 0., 0., 1., 1., 1., 0., 1., 0., 1., 0.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0), Probabilities: [0.         0.23679119 0.23679119 0.         0.         0.\n",
      " 0.23679119 0.         0.05283526 0.         0.23679119], Predicted Values: tensor([    0.0000,     0.1567,     0.8229,     0.0000,     0.0000,     0.0000,\n",
      "            0.0009,     0.0000,     0.0194,     0.0000,     0.0001],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 1., 0., 0., 0., 1., 0., 0., 1., 1.])\n",
      "tensor([[1., 0., 0., 1., 1., 1., 0., 1., 1., 0., 0.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0), Probabilities: [0.         0.24692656 0.24692656 0.         0.         0.\n",
      " 0.24692656 0.         0.         0.24692656 0.01229375], Predicted Values: tensor([    0.0000,     0.1596,     0.8384,     0.0000,     0.0000,     0.0000,\n",
      "            0.0009,     0.0000,     0.0000,     0.0010,     0.0001],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 1., 0., 0., 0., 0., 1., 1., 1., 0.])\n",
      "tensor([[1., 0., 0., 1., 1., 1., 1., 0., 0., 0., 1.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1), Probabilities: [0.         0.30553782 0.30553782 0.         0.         0.\n",
      " 0.         0.30553782 0.0681747  0.01521183 0.        ], Predicted Values: tensor([0.0000, 0.1583, 0.8309, 0.0000, 0.0000, 0.0000, 0.0000, 0.0074, 0.0024,\n",
      "        0.0009, 0.0000], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 1., 0., 0., 0., 0., 1., 1., 0., 1.])\n",
      "tensor([[1., 0., 0., 1., 1., 1., 1., 0., 0., 1., 0.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0), Probabilities: [0.         0.23679119 0.23679119 0.         0.         0.\n",
      " 0.         0.23679119 0.05283526 0.         0.23679119], Predicted Values: tensor([    0.0000,     0.1583,     0.8316,     0.0000,     0.0000,     0.0000,\n",
      "            0.0000,     0.0074,     0.0024,     0.0000,     0.0002],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1.])\n",
      "tensor([[1., 0., 0., 1., 1., 1., 1., 0., 1., 0., 0.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0), Probabilities: [0.         0.24692656 0.24692656 0.         0.         0.\n",
      " 0.         0.24692656 0.         0.24692656 0.01229375], Predicted Values: tensor([    0.0000,     0.1586,     0.8329,     0.0000,     0.0000,     0.0000,\n",
      "            0.0000,     0.0074,     0.0000,     0.0009,     0.0002],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 1., 0., 0., 0., 0., 0., 1., 1., 1.])\n",
      "tensor([[1., 0., 0., 1., 1., 1., 1., 1., 0., 0., 0.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0), Probabilities: [0.         0.32262497 0.32262497 0.         0.         0.\n",
      " 0.         0.         0.32262497 0.01606255 0.01606255], Predicted Values: tensor([    0.0000,     0.1563,     0.8207,     0.0000,     0.0000,     0.0000,\n",
      "            0.0000,     0.0000,     0.0219,     0.0009,     0.0001],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 0., 1., 1., 1., 1., 0., 0., 0., 0.])\n",
      "tensor([[1., 0., 1., 0., 0., 0., 0., 1., 1., 1., 1.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1), Probabilities: [0.         0.40063342 0.         0.40063342 0.0893934  0.0893934\n",
      " 0.01994636 0.         0.         0.         0.        ], Predicted Values: tensor([    0.0000,     0.4029,     0.0000,     0.5773,     0.0095,     0.0098,\n",
      "            0.0005,     0.0000,     0.0000,     0.0000,     0.0000],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 0., 1., 1., 1., 0., 1., 0., 0., 0.])\n",
      "tensor([[1., 0., 1., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1), Probabilities: [0.         0.40063342 0.         0.40063342 0.0893934  0.0893934\n",
      " 0.         0.01994636 0.         0.         0.        ], Predicted Values: tensor([0.0000, 0.4021, 0.0000, 0.5753, 0.0095, 0.0098, 0.0000, 0.0033, 0.0000,\n",
      "        0.0000, 0.0000], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 0., 1., 1., 1., 0., 0., 1., 0., 0.])\n",
      "tensor([[1., 0., 1., 0., 0., 0., 1., 1., 0., 1., 1.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1), Probabilities: [0.         0.29016961 0.         0.29016961 0.06474559 0.06474559\n",
      " 0.         0.         0.29016961 0.         0.        ], Predicted Values: tensor([0.0000, 0.3989, 0.0000, 0.5710, 0.0095, 0.0097, 0.0000, 0.0000, 0.0109,\n",
      "        0.0000, 0.0000], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 0., 1., 1., 1., 0., 0., 0., 1., 0.])\n",
      "tensor([[1., 0., 1., 0., 0., 0., 1., 1., 1., 0., 1.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1), Probabilities: [0.         0.29016961 0.         0.29016961 0.06474559 0.06474559\n",
      " 0.         0.         0.         0.29016961 0.        ], Predicted Values: tensor([0.0000, 0.4027, 0.0000, 0.5758, 0.0095, 0.0098, 0.0000, 0.0000, 0.0000,\n",
      "        0.0022, 0.0000], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 0., 1., 1., 1., 0., 0., 0., 0., 1.])\n",
      "tensor([[1., 0., 1., 0., 0., 0., 1., 1., 1., 1., 0.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0), Probabilities: [0.         0.29016961 0.         0.29016961 0.06474559 0.06474559\n",
      " 0.         0.         0.         0.         0.29016961], Predicted Values: tensor([0.0000, 0.4030, 0.0000, 0.5769, 0.0096, 0.0098, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0008], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 0., 1., 1., 0., 1., 1., 0., 0., 0.])\n",
      "tensor([[1., 0., 1., 0., 0., 1., 0., 0., 1., 1., 1.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1), Probabilities: [0.         0.30553782 0.         0.30553782 0.0681747  0.\n",
      " 0.01521183 0.30553782 0.         0.         0.        ], Predicted Values: tensor([0.0000, 0.4022, 0.0000, 0.5770, 0.0095, 0.0000, 0.0080, 0.0033, 0.0000,\n",
      "        0.0000, 0.0000], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 0., 1., 1., 0., 1., 0., 1., 0., 0.])\n",
      "tensor([[1., 0., 1., 0., 0., 1., 0., 1., 0., 1., 1.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1), Probabilities: [0.         0.40063342 0.         0.40063342 0.0893934  0.\n",
      " 0.01994636 0.         0.0893934  0.         0.        ], Predicted Values: tensor([0.0000, 0.4024, 0.0000, 0.5776, 0.0095, 0.0000, 0.0008, 0.0000, 0.0097,\n",
      "        0.0000, 0.0000], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 0., 1., 1., 0., 1., 0., 0., 1., 0.])\n",
      "tensor([[1., 0., 1., 0., 0., 1., 0., 1., 1., 0., 1.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1), Probabilities: [0.         0.30553782 0.         0.30553782 0.0681747  0.\n",
      " 0.01521183 0.         0.         0.30553782 0.        ], Predicted Values: tensor([0.0000, 0.4060, 0.0000, 0.5821, 0.0096, 0.0000, 0.0008, 0.0000, 0.0000,\n",
      "        0.0015, 0.0000], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 0., 1., 1., 0., 1., 0., 0., 0., 1.])\n",
      "tensor([[1., 0., 1., 0., 0., 1., 0., 1., 1., 1., 0.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0), Probabilities: [0.         0.30553782 0.         0.30553782 0.0681747  0.\n",
      " 0.01521183 0.         0.         0.         0.30553782], Predicted Values: tensor([    0.0000,     0.4062,     0.0000,     0.5830,     0.0096,     0.0000,\n",
      "            0.0008,     0.0000,     0.0000,     0.0000,     0.0004],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 0., 1., 1., 0., 0., 1., 1., 0., 0.])\n",
      "tensor([[1., 0., 1., 0., 0., 1., 1., 0., 0., 1., 1.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1), Probabilities: [0.         0.29016961 0.         0.29016961 0.06474559 0.\n",
      " 0.         0.29016961 0.06474559 0.         0.        ], Predicted Values: tensor([0.0000, 0.4051, 0.0000, 0.5807, 0.0096, 0.0000, 0.0000, 0.0033, 0.0012,\n",
      "        0.0000, 0.0000], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 0., 1., 1., 0., 0., 1., 0., 1., 0.])\n",
      "tensor([[1., 0., 1., 0., 0., 1., 1., 0., 1., 0., 1.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1), Probabilities: [0.         0.23679119 0.         0.23679119 0.05283526 0.\n",
      " 0.         0.23679119 0.         0.23679119 0.        ], Predicted Values: tensor([0.0000, 0.4053, 0.0000, 0.5803, 0.0096, 0.0000, 0.0000, 0.0033, 0.0000,\n",
      "        0.0015, 0.0000], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 0., 1., 1., 0., 0., 1., 0., 0., 1.])\n",
      "tensor([[1., 0., 1., 0., 0., 1., 1., 0., 1., 1., 0.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0), Probabilities: [0.         0.23679119 0.         0.23679119 0.05283526 0.\n",
      " 0.         0.23679119 0.         0.         0.23679119], Predicted Values: tensor([    0.0000,     0.4054,     0.0000,     0.5811,     0.0096,     0.0000,\n",
      "            0.0000,     0.0033,     0.0000,     0.0000,     0.0006],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 0., 1., 1., 0., 0., 0., 1., 1., 0.])\n",
      "tensor([[1., 0., 1., 0., 0., 1., 1., 1., 0., 0., 1.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1), Probabilities: [0.         0.30553782 0.         0.30553782 0.0681747  0.\n",
      " 0.         0.         0.30553782 0.01521183 0.        ], Predicted Values: tensor([0.0000, 0.4020, 0.0000, 0.5760, 0.0095, 0.0000, 0.0000, 0.0000, 0.0110,\n",
      "        0.0015, 0.0000], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 0., 1., 1., 0., 0., 0., 1., 0., 1.])\n",
      "tensor([[1., 0., 1., 0., 0., 1., 1., 1., 0., 1., 0.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0), Probabilities: [0.         0.23679119 0.         0.23679119 0.05283526 0.\n",
      " 0.         0.         0.23679119 0.         0.23679119], Predicted Values: tensor([    0.0000,     0.4022,     0.0000,     0.5768,     0.0095,     0.0000,\n",
      "            0.0000,     0.0000,     0.0110,     0.0000,     0.0004],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 0., 1., 1., 0., 0., 0., 0., 1., 1.])\n",
      "tensor([[1., 0., 1., 0., 0., 1., 1., 1., 1., 0., 0.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0), Probabilities: [0.         0.30553782 0.         0.30553782 0.0681747  0.\n",
      " 0.         0.         0.         0.30553782 0.01521183], Predicted Values: tensor([    0.0000,     0.4063,     0.0000,     0.5822,     0.0096,     0.0000,\n",
      "            0.0000,     0.0000,     0.0000,     0.0015,     0.0004],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 0., 1., 0., 1., 1., 1., 0., 0., 0.])\n",
      "tensor([[1., 0., 1., 0., 1., 0., 0., 0., 1., 1., 1.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1), Probabilities: [0.         0.30553782 0.         0.30553782 0.         0.0681747\n",
      " 0.30553782 0.01521183 0.         0.         0.        ], Predicted Values: tensor([0.0000, 0.4025, 0.0000, 0.5761, 0.0000, 0.0097, 0.0049, 0.0068, 0.0000,\n",
      "        0.0000, 0.0000], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 0., 1., 0., 1., 1., 0., 1., 0., 0.])\n",
      "tensor([[1., 0., 1., 0., 1., 0., 0., 1., 0., 1., 1.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1), Probabilities: [0.         0.29016961 0.         0.29016961 0.         0.06474559\n",
      " 0.29016961 0.         0.06474559 0.         0.        ], Predicted Values: tensor([    0.0000,     0.4029,     0.0000,     0.5771,     0.0000,     0.0098,\n",
      "            0.0005,     0.0000,     0.0098,     0.0000,     0.0000],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 0., 1., 0., 1., 1., 0., 0., 1., 0.])\n",
      "tensor([[1., 0., 1., 0., 1., 0., 0., 1., 1., 0., 1.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1), Probabilities: [0.         0.23679119 0.         0.23679119 0.         0.05283526\n",
      " 0.23679119 0.         0.         0.23679119 0.        ], Predicted Values: tensor([    0.0000,     0.4062,     0.0000,     0.5812,     0.0000,     0.0098,\n",
      "            0.0005,     0.0000,     0.0000,     0.0022,     0.0000],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 0., 1., 0., 1., 1., 0., 0., 0., 1.])\n",
      "tensor([[1., 0., 1., 0., 1., 0., 0., 1., 1., 1., 0.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0), Probabilities: [0.         0.23679119 0.         0.23679119 0.         0.05283526\n",
      " 0.23679119 0.         0.         0.         0.23679119], Predicted Values: tensor([    0.0000,     0.4067,     0.0000,     0.5825,     0.0000,     0.0098,\n",
      "            0.0005,     0.0000,     0.0000,     0.0000,     0.0004],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 0., 1., 0., 1., 0., 1., 1., 0., 0.])\n",
      "tensor([[1., 0., 1., 0., 1., 0., 1., 0., 0., 1., 1.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1), Probabilities: [0.         0.40063342 0.         0.40063342 0.         0.0893934\n",
      " 0.         0.01994636 0.0893934  0.         0.        ], Predicted Values: tensor([0.0000, 0.4041, 0.0000, 0.5780, 0.0000, 0.0098, 0.0000, 0.0069, 0.0012,\n",
      "        0.0000, 0.0000], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0.])\n",
      "tensor([[1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1), Probabilities: [0.         0.30553782 0.         0.30553782 0.         0.0681747\n",
      " 0.         0.01521183 0.         0.30553782 0.        ], Predicted Values: tensor([0.0000, 0.4040, 0.0000, 0.5772, 0.0000, 0.0098, 0.0000, 0.0068, 0.0000,\n",
      "        0.0022, 0.0000], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 0., 1., 0., 1., 0., 1., 0., 0., 1.])\n",
      "tensor([[1., 0., 1., 0., 1., 0., 1., 0., 1., 1., 0.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0), Probabilities: [0.         0.30553782 0.         0.30553782 0.         0.0681747\n",
      " 0.         0.01521183 0.         0.         0.30553782], Predicted Values: tensor([0.0000, 0.4044, 0.0000, 0.5784, 0.0000, 0.0098, 0.0000, 0.0069, 0.0000,\n",
      "        0.0000, 0.0006], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 0., 1., 0., 1., 0., 0., 1., 1., 0.])\n",
      "tensor([[1., 0., 1., 0., 1., 0., 1., 1., 0., 0., 1.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1), Probabilities: [0.         0.30553782 0.         0.30553782 0.         0.0681747\n",
      " 0.         0.         0.30553782 0.01521183 0.        ], Predicted Values: tensor([0.0000, 0.4021, 0.0000, 0.5749, 0.0000, 0.0097, 0.0000, 0.0000, 0.0110,\n",
      "        0.0022, 0.0000], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 0., 1., 0., 1., 0., 0., 1., 0., 1.])\n",
      "tensor([[1., 0., 1., 0., 1., 0., 1., 1., 0., 1., 0.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0), Probabilities: [0.         0.23679119 0.         0.23679119 0.         0.05283526\n",
      " 0.         0.         0.23679119 0.         0.23679119], Predicted Values: tensor([    0.0000,     0.4026,     0.0000,     0.5762,     0.0000,     0.0098,\n",
      "            0.0000,     0.0000,     0.0111,     0.0000,     0.0004],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 0., 1., 0., 1., 0., 0., 0., 1., 1.])\n",
      "tensor([[1., 0., 1., 0., 1., 0., 1., 1., 1., 0., 0.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0), Probabilities: [0.         0.30553782 0.         0.30553782 0.         0.0681747\n",
      " 0.         0.         0.         0.30553782 0.01521183], Predicted Values: tensor([    0.0000,     0.4065,     0.0000,     0.5811,     0.0000,     0.0098,\n",
      "            0.0000,     0.0000,     0.0000,     0.0022,     0.0004],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 0., 1., 0., 0., 1., 1., 1., 0., 0.])\n",
      "tensor([[1., 0., 1., 0., 1., 1., 0., 0., 0., 1., 1.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1), Probabilities: [0.         0.24692656 0.         0.24692656 0.         0.\n",
      " 0.24692656 0.24692656 0.01229375 0.         0.        ], Predicted Values: tensor([0.0000, 0.4043, 0.0000, 0.5798, 0.0000, 0.0000, 0.0080, 0.0069, 0.0011,\n",
      "        0.0000, 0.0000], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 0., 1., 0., 0., 1., 1., 0., 1., 0.])\n",
      "tensor([[1., 0., 1., 0., 1., 1., 0., 0., 1., 0., 1.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1), Probabilities: [0.  0.2 0.  0.2 0.  0.  0.2 0.2 0.  0.2 0. ], Predicted Values: tensor([0.0000, 0.4044, 0.0000, 0.5793, 0.0000, 0.0000, 0.0080, 0.0069, 0.0000,\n",
      "        0.0015, 0.0000], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 0., 1., 0., 0., 1., 1., 0., 0., 1.])\n",
      "tensor([[1., 0., 1., 0., 1., 1., 0., 0., 1., 1., 0.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0), Probabilities: [0.  0.2 0.  0.2 0.  0.  0.2 0.2 0.  0.  0.2], Predicted Values: tensor([    0.0000,     0.4046,     0.0000,     0.5802,     0.0000,     0.0000,\n",
      "            0.0080,     0.0069,     0.0000,     0.0000,     0.0003],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 0., 1., 0., 0., 1., 0., 1., 1., 0.])\n",
      "tensor([[1., 0., 1., 0., 1., 1., 0., 1., 0., 0., 1.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1), Probabilities: [0.         0.30553782 0.         0.30553782 0.         0.\n",
      " 0.30553782 0.         0.0681747  0.01521183 0.        ], Predicted Values: tensor([0.0000, 0.4059, 0.0000, 0.5819, 0.0000, 0.0000, 0.0008, 0.0000, 0.0098,\n",
      "        0.0015, 0.0000], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 0., 1., 0., 0., 1., 0., 1., 0., 1.])\n",
      "tensor([[1., 0., 1., 0., 1., 1., 0., 1., 0., 1., 0.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0), Probabilities: [0.         0.23679119 0.         0.23679119 0.         0.\n",
      " 0.23679119 0.         0.05283526 0.         0.23679119], Predicted Values: tensor([    0.0000,     0.4062,     0.0000,     0.5829,     0.0000,     0.0000,\n",
      "            0.0008,     0.0000,     0.0099,     0.0000,     0.0002],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 0., 1., 0., 0., 1., 0., 0., 1., 1.])\n",
      "tensor([[1., 0., 1., 0., 1., 1., 0., 1., 1., 0., 0.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0), Probabilities: [0.         0.24692656 0.         0.24692656 0.         0.\n",
      " 0.24692656 0.         0.         0.24692656 0.01229375], Predicted Values: tensor([    0.0000,     0.4099,     0.0000,     0.5875,     0.0000,     0.0000,\n",
      "            0.0009,     0.0000,     0.0000,     0.0015,     0.0002],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 0., 1., 0., 0., 0., 1., 1., 1., 0.])\n",
      "tensor([[1., 0., 1., 0., 1., 1., 1., 0., 0., 0., 1.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1), Probabilities: [0.         0.30553782 0.         0.30553782 0.         0.\n",
      " 0.         0.30553782 0.0681747  0.01521183 0.        ], Predicted Values: tensor([0.0000, 0.4073, 0.0000, 0.5830, 0.0000, 0.0000, 0.0000, 0.0070, 0.0012,\n",
      "        0.0015, 0.0000], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 0., 1., 0., 0., 0., 1., 1., 0., 1.])\n",
      "tensor([[1., 0., 1., 0., 1., 1., 1., 0., 0., 1., 0.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0), Probabilities: [0.         0.23679119 0.         0.23679119 0.         0.\n",
      " 0.         0.23679119 0.05283526 0.         0.23679119], Predicted Values: tensor([    0.0000,     0.4075,     0.0000,     0.5840,     0.0000,     0.0000,\n",
      "            0.0000,     0.0070,     0.0012,     0.0000,     0.0003],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 0., 1., 0., 0., 0., 1., 0., 1., 1.])\n",
      "tensor([[1., 0., 1., 0., 1., 1., 1., 0., 1., 0., 0.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0), Probabilities: [0.         0.24692656 0.         0.24692656 0.         0.\n",
      " 0.         0.24692656 0.         0.24692656 0.01229375], Predicted Values: tensor([    0.0000,     0.4077,     0.0000,     0.5836,     0.0000,     0.0000,\n",
      "            0.0000,     0.0070,     0.0000,     0.0015,     0.0003],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 0., 1., 0., 0., 0., 0., 1., 1., 1.])\n",
      "tensor([[1., 0., 1., 0., 1., 1., 1., 1., 0., 0., 0.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0), Probabilities: [0.         0.32262497 0.         0.32262497 0.         0.\n",
      " 0.         0.         0.32262497 0.01606255 0.01606255], Predicted Values: tensor([    0.0000,     0.4059,     0.0000,     0.5813,     0.0000,     0.0000,\n",
      "            0.0000,     0.0000,     0.0112,     0.0015,     0.0002],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 0., 0., 1., 1., 1., 1., 0., 0., 0.])\n",
      "tensor([[1., 0., 1., 1., 0., 0., 0., 0., 1., 1., 1.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1), Probabilities: [0.         0.43053263 0.         0.         0.09606482 0.43053263\n",
      " 0.02143496 0.02143496 0.         0.         0.        ], Predicted Values: tensor([0.0000, 0.9031, 0.0000, 0.0000, 0.0180, 0.0634, 0.0093, 0.0062, 0.0000,\n",
      "        0.0000, 0.0000], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 0., 0., 1., 1., 1., 0., 1., 0., 0.])\n",
      "tensor([[1., 0., 1., 1., 0., 0., 0., 1., 0., 1., 1.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1), Probabilities: [0.         0.40063342 0.         0.         0.0893934  0.40063342\n",
      " 0.01994636 0.         0.0893934  0.         0.        ], Predicted Values: tensor([0.0000, 0.9062, 0.0000, 0.0000, 0.0181, 0.0636, 0.0010, 0.0000, 0.0110,\n",
      "        0.0000, 0.0000], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 0., 0., 1., 1., 1., 0., 0., 1., 0.])\n",
      "tensor([[1., 0., 1., 1., 0., 0., 0., 1., 1., 0., 1.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1), Probabilities: [0.         0.30553782 0.         0.         0.0681747  0.30553782\n",
      " 0.01521183 0.         0.         0.30553782 0.        ], Predicted Values: tensor([0.0000, 0.9155, 0.0000, 0.0000, 0.0183, 0.0643, 0.0010, 0.0000, 0.0000,\n",
      "        0.0009, 0.0000], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 0., 0., 1., 1., 1., 0., 0., 0., 1.])\n",
      "tensor([[1., 0., 1., 1., 0., 0., 0., 1., 1., 1., 0.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0), Probabilities: [0.         0.30553782 0.         0.         0.0681747  0.30553782\n",
      " 0.01521183 0.         0.         0.         0.30553782], Predicted Values: tensor([    0.0000,     0.9161,     0.0000,     0.0000,     0.0183,     0.0643,\n",
      "            0.0010,     0.0000,     0.0000,     0.0000,     0.0003],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 0., 0., 1., 1., 0., 1., 1., 0., 0.])\n",
      "tensor([[1., 0., 1., 1., 0., 0., 1., 0., 0., 1., 1.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1), Probabilities: [0.         0.40063342 0.         0.         0.0893934  0.40063342\n",
      " 0.         0.01994636 0.0893934  0.         0.        ], Predicted Values: tensor([0.0000, 0.9102, 0.0000, 0.0000, 0.0182, 0.0639, 0.0000, 0.0063, 0.0014,\n",
      "        0.0000, 0.0000], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 0., 0., 1., 1., 0., 1., 0., 1., 0.])\n",
      "tensor([[1., 0., 1., 1., 0., 0., 1., 0., 1., 0., 1.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1), Probabilities: [0.         0.30553782 0.         0.         0.0681747  0.30553782\n",
      " 0.         0.01521183 0.         0.30553782 0.        ], Predicted Values: tensor([0.0000, 0.9107, 0.0000, 0.0000, 0.0182, 0.0639, 0.0000, 0.0063, 0.0000,\n",
      "        0.0009, 0.0000], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 0., 0., 1., 1., 0., 1., 0., 0., 1.])\n",
      "tensor([[1., 0., 1., 1., 0., 0., 1., 0., 1., 1., 0.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0), Probabilities: [0.         0.30553782 0.         0.         0.0681747  0.30553782\n",
      " 0.         0.01521183 0.         0.         0.30553782], Predicted Values: tensor([    0.0000,     0.9111,     0.0000,     0.0000,     0.0183,     0.0639,\n",
      "            0.0000,     0.0063,     0.0000,     0.0000,     0.0004],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 0., 0., 1., 1., 0., 0., 1., 1., 0.])\n",
      "tensor([[1., 0., 1., 1., 0., 0., 1., 1., 0., 0., 1.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1), Probabilities: [0.         0.30553782 0.         0.         0.0681747  0.30553782\n",
      " 0.         0.         0.30553782 0.01521183 0.        ], Predicted Values: tensor([0.0000, 0.9049, 0.0000, 0.0000, 0.0181, 0.0636, 0.0000, 0.0000, 0.0125,\n",
      "        0.0009, 0.0000], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 0., 0., 1., 1., 0., 0., 1., 0., 1.])\n",
      "tensor([[1., 0., 1., 1., 0., 0., 1., 1., 0., 1., 0.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0), Probabilities: [0.         0.23679119 0.         0.         0.05283526 0.23679119\n",
      " 0.         0.         0.23679119 0.         0.23679119], Predicted Values: tensor([    0.0000,     0.9055,     0.0000,     0.0000,     0.0182,     0.0636,\n",
      "            0.0000,     0.0000,     0.0125,     0.0000,     0.0003],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 0., 0., 1., 1., 0., 0., 0., 1., 1.])\n",
      "tensor([[1., 0., 1., 1., 0., 0., 1., 1., 1., 0., 0.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0), Probabilities: [0.         0.30553782 0.         0.         0.0681747  0.30553782\n",
      " 0.         0.         0.         0.30553782 0.01521183], Predicted Values: tensor([    0.0000,     0.9161,     0.0000,     0.0000,     0.0184,     0.0643,\n",
      "            0.0000,     0.0000,     0.0000,     0.0009,     0.0003],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 0., 0., 1., 0., 1., 1., 1., 0., 0.])\n",
      "tensor([[1., 0., 1., 1., 0., 1., 0., 0., 0., 1., 1.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1), Probabilities: [0.         0.43053263 0.         0.         0.09606482 0.\n",
      " 0.02143496 0.43053263 0.02143496 0.         0.        ], Predicted Values: tensor([0.0000, 0.9569, 0.0000, 0.0000, 0.0191, 0.0000, 0.0162, 0.0066, 0.0013,\n",
      "        0.0000, 0.0000], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 0., 0., 1., 0., 1., 1., 0., 1., 0.])\n",
      "tensor([[1., 0., 1., 1., 0., 1., 0., 0., 1., 0., 1.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1), Probabilities: [0.         0.30553782 0.         0.         0.0681747  0.\n",
      " 0.01521183 0.30553782 0.         0.30553782 0.        ], Predicted Values: tensor([    0.0000,     0.9575,     0.0000,     0.0000,     0.0191,     0.0000,\n",
      "            0.0161,     0.0066,     0.0000,     0.0007,     0.0000],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 0., 0., 1., 0., 1., 1., 0., 0., 1.])\n",
      "tensor([[1., 0., 1., 1., 0., 1., 0., 0., 1., 1., 0.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0), Probabilities: [0.         0.30553782 0.         0.         0.0681747  0.\n",
      " 0.01521183 0.30553782 0.         0.         0.30553782], Predicted Values: tensor([    0.0000,     0.9579,     0.0000,     0.0000,     0.0192,     0.0000,\n",
      "            0.0161,     0.0066,     0.0000,     0.0000,     0.0002],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 0., 0., 1., 0., 1., 0., 1., 1., 0.])\n",
      "tensor([[1., 0., 1., 1., 0., 1., 0., 1., 0., 0., 1.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1), Probabilities: [0.         0.6468998  0.         0.         0.14434286 0.\n",
      " 0.03220724 0.         0.14434286 0.03220724 0.        ], Predicted Values: tensor([    0.0000,     0.9666,     0.0000,     0.0000,     0.0193,     0.0000,\n",
      "            0.0017,     0.0000,     0.0117,     0.0007,     0.0000],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 0., 0., 1., 0., 1., 0., 1., 0., 1.])\n",
      "tensor([[1., 0., 1., 1., 0., 1., 0., 1., 0., 1., 0.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0), Probabilities: [0.         0.40063342 0.         0.         0.0893934  0.\n",
      " 0.01994636 0.         0.0893934  0.         0.40063342], Predicted Values: tensor([    0.0000,     0.9670,     0.0000,     0.0000,     0.0194,     0.0000,\n",
      "            0.0017,     0.0000,     0.0118,     0.0000,     0.0002],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 0., 0., 1., 0., 1., 0., 0., 1., 1.])\n",
      "tensor([[1., 0., 1., 1., 0., 1., 0., 1., 1., 0., 0.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0), Probabilities: [0.         0.43053263 0.         0.         0.09606482 0.\n",
      " 0.02143496 0.         0.         0.43053263 0.02143496], Predicted Values: tensor([    0.0000,     0.9779,     0.0000,     0.0000,     0.0196,     0.0000,\n",
      "            0.0017,     0.0000,     0.0000,     0.0007,     0.0002],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 0., 0., 1., 0., 0., 1., 1., 1., 0.])\n",
      "tensor([[1., 0., 1., 1., 0., 1., 1., 0., 0., 0., 1.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1), Probabilities: [0.         0.40063342 0.         0.         0.0893934  0.\n",
      " 0.         0.40063342 0.0893934  0.01994636 0.        ], Predicted Values: tensor([    0.0000,     0.9717,     0.0000,     0.0000,     0.0194,     0.0000,\n",
      "            0.0000,     0.0067,     0.0015,     0.0007,     0.0000],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 0., 0., 1., 0., 0., 1., 1., 0., 1.])\n",
      "tensor([[1., 0., 1., 1., 0., 1., 1., 0., 0., 1., 0.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0), Probabilities: [0.         0.29016961 0.         0.         0.06474559 0.\n",
      " 0.         0.29016961 0.06474559 0.         0.29016961], Predicted Values: tensor([    0.0000,     0.9721,     0.0000,     0.0000,     0.0195,     0.0000,\n",
      "            0.0000,     0.0067,     0.0015,     0.0000,     0.0002],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 0., 0., 1., 0., 0., 1., 0., 1., 1.])\n",
      "tensor([[1., 0., 1., 1., 0., 1., 1., 0., 1., 0., 0.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0), Probabilities: [0.         0.30553782 0.         0.         0.0681747  0.\n",
      " 0.         0.30553782 0.         0.30553782 0.01521183], Predicted Values: tensor([    0.0000,     0.9729,     0.0000,     0.0000,     0.0195,     0.0000,\n",
      "            0.0000,     0.0067,     0.0000,     0.0007,     0.0002],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 0., 0., 1., 0., 0., 0., 1., 1., 1.])\n",
      "tensor([[1., 0., 1., 1., 0., 1., 1., 1., 0., 0., 0.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0), Probabilities: [0.         0.43053263 0.         0.         0.09606482 0.\n",
      " 0.         0.         0.43053263 0.02143496 0.02143496], Predicted Values: tensor([    0.0000,     0.9665,     0.0000,     0.0000,     0.0194,     0.0000,\n",
      "            0.0000,     0.0000,     0.0133,     0.0007,     0.0001],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 0., 0., 0., 1., 1., 1., 1., 0., 0.])\n",
      "tensor([[1., 0., 1., 1., 1., 0., 0., 0., 0., 1., 1.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1), Probabilities: [0.         0.32262497 0.         0.         0.         0.32262497\n",
      " 0.32262497 0.01606255 0.01606255 0.         0.        ], Predicted Values: tensor([0.0000, 0.9125, 0.0000, 0.0000, 0.0000, 0.0639, 0.0094, 0.0130, 0.0012,\n",
      "        0.0000, 0.0000], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 0., 0., 0., 1., 1., 1., 0., 1., 0.])\n",
      "tensor([[1., 0., 1., 1., 1., 0., 0., 0., 1., 0., 1.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1), Probabilities: [0.         0.24692656 0.         0.         0.         0.24692656\n",
      " 0.24692656 0.01229375 0.         0.24692656 0.        ], Predicted Values: tensor([0.0000, 0.9128, 0.0000, 0.0000, 0.0000, 0.0639, 0.0094, 0.0129, 0.0000,\n",
      "        0.0009, 0.0000], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 0., 0., 0., 1., 1., 1., 0., 0., 1.])\n",
      "tensor([[1., 0., 1., 1., 1., 0., 0., 0., 1., 1., 0.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0), Probabilities: [0.         0.24692656 0.         0.         0.         0.24692656\n",
      " 0.24692656 0.01229375 0.         0.         0.24692656], Predicted Values: tensor([    0.0000,     0.9134,     0.0000,     0.0000,     0.0000,     0.0639,\n",
      "            0.0094,     0.0130,     0.0000,     0.0000,     0.0003],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 0., 0., 0., 1., 1., 0., 1., 1., 0.])\n",
      "tensor([[1., 0., 1., 1., 1., 0., 0., 1., 0., 0., 1.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1), Probabilities: [0.         0.30553782 0.         0.         0.         0.30553782\n",
      " 0.30553782 0.         0.0681747  0.01521183 0.        ], Predicted Values: tensor([0.0000, 0.9222, 0.0000, 0.0000, 0.0000, 0.0646, 0.0010, 0.0000, 0.0112,\n",
      "        0.0009, 0.0000], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 0., 0., 0., 1., 1., 0., 1., 0., 1.])\n",
      "tensor([[1., 0., 1., 1., 1., 0., 0., 1., 0., 1., 0.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0), Probabilities: [0.         0.23679119 0.         0.         0.         0.23679119\n",
      " 0.23679119 0.         0.05283526 0.         0.23679119], Predicted Values: tensor([    0.0000,     0.9229,     0.0000,     0.0000,     0.0000,     0.0646,\n",
      "            0.0010,     0.0000,     0.0113,     0.0000,     0.0002],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 0., 0., 0., 1., 1., 0., 0., 1., 1.])\n",
      "tensor([[1., 0., 1., 1., 1., 0., 0., 1., 1., 0., 0.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0), Probabilities: [0.         0.24692656 0.         0.         0.         0.24692656\n",
      " 0.24692656 0.         0.         0.24692656 0.01229375], Predicted Values: tensor([    0.0000,     0.9326,     0.0000,     0.0000,     0.0000,     0.0653,\n",
      "            0.0010,     0.0000,     0.0000,     0.0009,     0.0002],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 0., 0., 0., 1., 0., 1., 1., 1., 0.])\n",
      "tensor([[1., 0., 1., 1., 1., 0., 1., 0., 0., 0., 1.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1), Probabilities: [0.         0.43053263 0.         0.         0.         0.43053263\n",
      " 0.         0.02143496 0.09606482 0.02143496 0.        ], Predicted Values: tensor([0.0000, 0.9201, 0.0000, 0.0000, 0.0000, 0.0645, 0.0000, 0.0131, 0.0014,\n",
      "        0.0009, 0.0000], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 0., 0., 0., 1., 0., 1., 1., 0., 1.])\n",
      "tensor([[1., 0., 1., 1., 1., 0., 1., 0., 0., 1., 0.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0), Probabilities: [0.         0.30553782 0.         0.         0.         0.30553782\n",
      " 0.         0.01521183 0.0681747  0.         0.30553782], Predicted Values: tensor([    0.0000,     0.9207,     0.0000,     0.0000,     0.0000,     0.0645,\n",
      "            0.0000,     0.0132,     0.0014,     0.0000,     0.0002],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 0., 0., 0., 1., 0., 1., 0., 1., 1.])\n",
      "tensor([[1., 0., 1., 1., 1., 0., 1., 0., 1., 0., 0.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0), Probabilities: [0.         0.32262497 0.         0.         0.         0.32262497\n",
      " 0.         0.01606255 0.         0.32262497 0.01606255], Predicted Values: tensor([    0.0000,     0.9212,     0.0000,     0.0000,     0.0000,     0.0645,\n",
      "            0.0000,     0.0132,     0.0000,     0.0009,     0.0002],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 0., 0., 0., 1., 0., 0., 1., 1., 1.])\n",
      "tensor([[1., 0., 1., 1., 1., 0., 1., 1., 0., 0., 0.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0), Probabilities: [0.         0.32262497 0.         0.         0.         0.32262497\n",
      " 0.         0.         0.32262497 0.01606255 0.01606255], Predicted Values: tensor([    0.0000,     0.9216,     0.0000,     0.0000,     0.0000,     0.0646,\n",
      "            0.0000,     0.0000,     0.0127,     0.0009,     0.0002],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 0., 0., 0., 0., 1., 1., 1., 1., 0.])\n",
      "tensor([[1., 0., 1., 1., 1., 1., 0., 0., 0., 0., 1.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1), Probabilities: [0.         0.32262497 0.         0.         0.         0.\n",
      " 0.32262497 0.32262497 0.01606255 0.01606255 0.        ], Predicted Values: tensor([    0.0000,     0.9679,     0.0000,     0.0000,     0.0000,     0.0000,\n",
      "            0.0163,     0.0138,     0.0013,     0.0007,     0.0000],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 0., 0., 0., 0., 1., 1., 1., 0., 1.])\n",
      "tensor([[1., 0., 1., 1., 1., 1., 0., 0., 0., 1., 0.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0), Probabilities: [0.         0.24692656 0.         0.         0.         0.\n",
      " 0.24692656 0.24692656 0.01229375 0.         0.24692656], Predicted Values: tensor([    0.0000,     0.9684,     0.0000,     0.0000,     0.0000,     0.0000,\n",
      "            0.0163,     0.0139,     0.0013,     0.0000,     0.0001],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 0., 0., 0., 0., 1., 1., 0., 1., 1.])\n",
      "tensor([[1., 0., 1., 1., 1., 1., 0., 0., 1., 0., 0.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0), Probabilities: [0.         0.24692656 0.         0.         0.         0.\n",
      " 0.24692656 0.24692656 0.         0.24692656 0.01229375], Predicted Values: tensor([    0.0000,     0.9691,     0.0000,     0.0000,     0.0000,     0.0000,\n",
      "            0.0163,     0.0138,     0.0000,     0.0007,     0.0001],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.])\n",
      "tensor([[1., 0., 1., 1., 1., 1., 0., 1., 0., 0., 0.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0), Probabilities: [0.         0.43053263 0.         0.         0.         0.\n",
      " 0.43053263 0.         0.09606482 0.02143496 0.02143496], Predicted Values: tensor([    0.0000,     0.9855,     0.0000,     0.0000,     0.0000,     0.0000,\n",
      "            0.0017,     0.0000,     0.0120,     0.0007,     0.0001],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 0., 0., 0., 0., 0., 1., 1., 1., 1.])\n",
      "tensor([[1., 0., 1., 1., 1., 1., 1., 0., 0., 0., 0.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0), Probabilities: [0.         0.43053263 0.         0.         0.         0.\n",
      " 0.         0.43053263 0.09606482 0.02143496 0.02143496], Predicted Values: tensor([    0.0000,     0.9836,     0.0000,     0.0000,     0.0000,     0.0000,\n",
      "            0.0000,     0.0142,     0.0015,     0.0007,     0.0001],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 1., 1., 1., 1., 1., 0., 0., 0., 0.])\n",
      "tensor([[1., 1., 0., 0., 0., 0., 0., 1., 1., 1., 1.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1), Probabilities: [0.         0.         0.43053263 0.43053263 0.09606482 0.02143496\n",
      " 0.02143496 0.         0.         0.         0.        ], Predicted Values: tensor([    0.0000,     0.0000,     0.4639,     0.5138,     0.0081,     0.0137,\n",
      "            0.0004,     0.0000,     0.0000,     0.0000,     0.0000],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 1., 1., 1., 1., 0., 1., 0., 0., 0.])\n",
      "tensor([[1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1), Probabilities: [0.         0.         0.43053263 0.43053263 0.09606482 0.02143496\n",
      " 0.         0.02143496 0.         0.         0.        ], Predicted Values: tensor([0.0000, 0.0000, 0.4631, 0.5123, 0.0081, 0.0137, 0.0000, 0.0028, 0.0000,\n",
      "        0.0000, 0.0000], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 1., 1., 1., 1., 0., 0., 1., 0., 0.])\n",
      "tensor([[1., 1., 0., 0., 0., 0., 1., 1., 0., 1., 1.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1), Probabilities: [0.         0.         0.30553782 0.30553782 0.0681747  0.01521183\n",
      " 0.         0.         0.30553782 0.         0.        ], Predicted Values: tensor([0.0000, 0.0000, 0.4538, 0.5025, 0.0079, 0.0134, 0.0000, 0.0000, 0.0223,\n",
      "        0.0000, 0.0000], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 1., 1., 1., 1., 0., 0., 0., 1., 0.])\n",
      "tensor([[1., 1., 0., 0., 0., 0., 1., 1., 1., 0., 1.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1), Probabilities: [0.         0.         0.30553782 0.30553782 0.0681747  0.01521183\n",
      " 0.         0.         0.         0.30553782 0.        ], Predicted Values: tensor([0.0000, 0.0000, 0.4636, 0.5129, 0.0081, 0.0137, 0.0000, 0.0000, 0.0000,\n",
      "        0.0017, 0.0000], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 1., 1., 1., 1., 0., 0., 0., 0., 1.])\n",
      "tensor([[1., 1., 0., 0., 0., 0., 1., 1., 1., 1., 0.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0), Probabilities: [0.         0.         0.30553782 0.30553782 0.0681747  0.01521183\n",
      " 0.         0.         0.         0.         0.30553782], Predicted Values: tensor([0.0000, 0.0000, 0.4640, 0.5134, 0.0081, 0.0137, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0008], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 1., 1., 1., 0., 1., 1., 0., 0., 0.])\n",
      "tensor([[1., 1., 0., 0., 0., 1., 0., 0., 1., 1., 1.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1), Probabilities: [0.         0.         0.30553782 0.30553782 0.0681747  0.\n",
      " 0.01521183 0.30553782 0.         0.         0.        ], Predicted Values: tensor([0.0000, 0.0000, 0.4663, 0.5159, 0.0081, 0.0000, 0.0068, 0.0028, 0.0000,\n",
      "        0.0000, 0.0000], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 1., 1., 1., 0., 1., 0., 1., 0., 0.])\n",
      "tensor([[1., 1., 0., 0., 0., 1., 0., 1., 0., 1., 1.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1), Probabilities: [0.         0.         0.40063342 0.40063342 0.0893934  0.\n",
      " 0.01994636 0.         0.0893934  0.         0.        ], Predicted Values: tensor([0.0000, 0.0000, 0.4609, 0.5105, 0.0080, 0.0000, 0.0007, 0.0000, 0.0199,\n",
      "        0.0000, 0.0000], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 1., 1., 1., 0., 1., 0., 0., 1., 0.])\n",
      "tensor([[1., 1., 0., 0., 0., 1., 0., 1., 1., 0., 1.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1), Probabilities: [0.         0.         0.30553782 0.30553782 0.0681747  0.\n",
      " 0.01521183 0.         0.         0.30553782 0.        ], Predicted Values: tensor([0.0000, 0.0000, 0.4700, 0.5200, 0.0082, 0.0000, 0.0007, 0.0000, 0.0000,\n",
      "        0.0012, 0.0000], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 1., 1., 1., 0., 1., 0., 0., 0., 1.])\n",
      "tensor([[1., 1., 0., 0., 0., 1., 0., 1., 1., 1., 0.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0), Probabilities: [0.         0.         0.30553782 0.30553782 0.0681747  0.\n",
      " 0.01521183 0.         0.         0.         0.30553782], Predicted Values: tensor([    0.0000,     0.0000,     0.4703,     0.5204,     0.0082,     0.0000,\n",
      "            0.0007,     0.0000,     0.0000,     0.0000,     0.0004],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 1., 1., 1., 0., 0., 1., 1., 0., 0.])\n",
      "tensor([[1., 1., 0., 0., 0., 1., 1., 0., 0., 1., 1.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1), Probabilities: [0.         0.         0.29016961 0.29016961 0.06474559 0.\n",
      " 0.         0.29016961 0.06474559 0.         0.        ], Predicted Values: tensor([0.0000, 0.0000, 0.4684, 0.5181, 0.0082, 0.0000, 0.0000, 0.0028, 0.0025,\n",
      "        0.0000, 0.0000], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 1., 1., 1., 0., 0., 1., 0., 1., 0.])\n",
      "tensor([[1., 1., 0., 0., 0., 1., 1., 0., 1., 0., 1.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1), Probabilities: [0.         0.         0.23679119 0.23679119 0.05283526 0.\n",
      " 0.         0.23679119 0.         0.23679119 0.        ], Predicted Values: tensor([0.0000, 0.0000, 0.4693, 0.5186, 0.0082, 0.0000, 0.0000, 0.0028, 0.0000,\n",
      "        0.0012, 0.0000], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 1., 1., 1., 0., 0., 1., 0., 0., 1.])\n",
      "tensor([[1., 1., 0., 0., 0., 1., 1., 0., 1., 1., 0.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0), Probabilities: [0.         0.         0.23679119 0.23679119 0.05283526 0.\n",
      " 0.         0.23679119 0.         0.         0.23679119], Predicted Values: tensor([0.0000, 0.0000, 0.4695, 0.5189, 0.0082, 0.0000, 0.0000, 0.0028, 0.0000,\n",
      "        0.0000, 0.0006], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 1., 1., 1., 0., 0., 0., 1., 1., 0.])\n",
      "tensor([[1., 1., 0., 0., 0., 1., 1., 1., 0., 0., 1.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1), Probabilities: [0.         0.         0.30553782 0.30553782 0.0681747  0.\n",
      " 0.         0.         0.30553782 0.01521183 0.        ], Predicted Values: tensor([0.0000, 0.0000, 0.4597, 0.5086, 0.0080, 0.0000, 0.0000, 0.0000, 0.0225,\n",
      "        0.0011, 0.0000], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 1., 1., 1., 0., 0., 0., 1., 0., 1.])\n",
      "tensor([[1., 1., 0., 0., 0., 1., 1., 1., 0., 1., 0.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0), Probabilities: [0.         0.         0.23679119 0.23679119 0.05283526 0.\n",
      " 0.         0.         0.23679119 0.         0.23679119], Predicted Values: tensor([    0.0000,     0.0000,     0.4600,     0.5090,     0.0080,     0.0000,\n",
      "            0.0000,     0.0000,     0.0226,     0.0000,     0.0004],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 1., 1., 1., 0., 0., 0., 0., 1., 1.])\n",
      "tensor([[1., 1., 0., 0., 0., 1., 1., 1., 1., 0., 0.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0), Probabilities: [0.         0.         0.30553782 0.30553782 0.0681747  0.\n",
      " 0.         0.         0.         0.30553782 0.01521183], Predicted Values: tensor([    0.0000,     0.0000,     0.4704,     0.5199,     0.0082,     0.0000,\n",
      "            0.0000,     0.0000,     0.0000,     0.0012,     0.0004],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 1., 1., 0., 1., 1., 1., 0., 0., 0.])\n",
      "tensor([[1., 1., 0., 0., 1., 0., 0., 0., 1., 1., 1.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1), Probabilities: [0.         0.         0.32262497 0.32262497 0.         0.01606255\n",
      " 0.32262497 0.01606255 0.         0.         0.        ], Predicted Values: tensor([0.0000, 0.0000, 0.4633, 0.5131, 0.0000, 0.0137, 0.0042, 0.0058, 0.0000,\n",
      "        0.0000, 0.0000], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 1., 1., 0., 1., 1., 0., 1., 0., 0.])\n",
      "tensor([[1., 1., 0., 0., 1., 0., 0., 1., 0., 1., 1.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1), Probabilities: [0.         0.         0.30553782 0.30553782 0.         0.01521183\n",
      " 0.30553782 0.         0.0681747  0.         0.        ], Predicted Values: tensor([    0.0000,     0.0000,     0.4582,     0.5079,     0.0000,     0.0135,\n",
      "            0.0004,     0.0000,     0.0199,     0.0000,     0.0000],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 1., 1., 0., 1., 1., 0., 0., 1., 0.])\n",
      "tensor([[1., 1., 0., 0., 1., 0., 0., 1., 1., 0., 1.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1), Probabilities: [0.         0.         0.24692656 0.24692656 0.         0.01229375\n",
      " 0.24692656 0.         0.         0.24692656 0.        ], Predicted Values: tensor([    0.0000,     0.0000,     0.4670,     0.5171,     0.0000,     0.0138,\n",
      "            0.0004,     0.0000,     0.0000,     0.0017,     0.0000],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 1., 1., 0., 1., 1., 0., 0., 0., 1.])\n",
      "tensor([[1., 1., 0., 0., 1., 0., 0., 1., 1., 1., 0.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0), Probabilities: [0.         0.         0.24692656 0.24692656 0.         0.01229375\n",
      " 0.24692656 0.         0.         0.         0.24692656], Predicted Values: tensor([    0.0000,     0.0000,     0.4675,     0.5178,     0.0000,     0.0138,\n",
      "            0.0004,     0.0000,     0.0000,     0.0000,     0.0005],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 1., 1., 0., 1., 0., 1., 1., 0., 0.])\n",
      "tensor([[1., 1., 0., 0., 1., 0., 1., 0., 0., 1., 1.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1), Probabilities: [0.         0.         0.43053263 0.43053263 0.         0.02143496\n",
      " 0.         0.02143496 0.09606482 0.         0.        ], Predicted Values: tensor([0.0000, 0.0000, 0.4641, 0.5138, 0.0000, 0.0137, 0.0000, 0.0058, 0.0025,\n",
      "        0.0000, 0.0000], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 1., 1., 0., 1., 0., 1., 0., 1., 0.])\n",
      "tensor([[1., 1., 0., 0., 1., 0., 1., 0., 1., 0., 1.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1), Probabilities: [0.         0.         0.32262497 0.32262497 0.         0.01606255\n",
      " 0.         0.01606255 0.         0.32262497 0.        ], Predicted Values: tensor([0.0000, 0.0000, 0.4647, 0.5140, 0.0000, 0.0137, 0.0000, 0.0058, 0.0000,\n",
      "        0.0017, 0.0000], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 1., 1., 0., 1., 0., 1., 0., 0., 1.])\n",
      "tensor([[1., 1., 0., 0., 1., 0., 1., 0., 1., 1., 0.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0), Probabilities: [0.         0.         0.32262497 0.32262497 0.         0.01606255\n",
      " 0.         0.01606255 0.         0.         0.32262497], Predicted Values: tensor([0.0000, 0.0000, 0.4652, 0.5146, 0.0000, 0.0137, 0.0000, 0.0058, 0.0000,\n",
      "        0.0000, 0.0007], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 1., 1., 0., 1., 0., 0., 1., 1., 0.])\n",
      "tensor([[1., 1., 0., 0., 1., 0., 1., 1., 0., 0., 1.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1), Probabilities: [0.         0.         0.32262497 0.32262497 0.         0.01606255\n",
      " 0.         0.         0.32262497 0.01606255 0.        ], Predicted Values: tensor([0.0000, 0.0000, 0.4567, 0.5056, 0.0000, 0.0135, 0.0000, 0.0000, 0.0225,\n",
      "        0.0017, 0.0000], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 1., 1., 0., 1., 0., 0., 1., 0., 1.])\n",
      "tensor([[1., 1., 0., 0., 1., 0., 1., 1., 0., 1., 0.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0), Probabilities: [0.         0.         0.24692656 0.24692656 0.         0.01229375\n",
      " 0.         0.         0.24692656 0.         0.24692656], Predicted Values: tensor([    0.0000,     0.0000,     0.4572,     0.5063,     0.0000,     0.0135,\n",
      "            0.0000,     0.0000,     0.0226,     0.0000,     0.0004],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 1., 1., 0., 1., 0., 0., 0., 1., 1.])\n",
      "tensor([[1., 1., 0., 0., 1., 0., 1., 1., 1., 0., 0.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0), Probabilities: [0.         0.         0.32262497 0.32262497 0.         0.01606255\n",
      " 0.         0.         0.         0.32262497 0.01606255], Predicted Values: tensor([    0.0000,     0.0000,     0.4672,     0.5168,     0.0000,     0.0138,\n",
      "            0.0000,     0.0000,     0.0000,     0.0017,     0.0004],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 1., 1., 0., 0., 1., 1., 1., 0., 0.])\n",
      "tensor([[1., 1., 0., 0., 1., 1., 0., 0., 0., 1., 1.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1), Probabilities: [0.         0.         0.24692656 0.24692656 0.         0.\n",
      " 0.24692656 0.24692656 0.01229375 0.         0.        ], Predicted Values: tensor([0.0000, 0.0000, 0.4675, 0.5176, 0.0000, 0.0000, 0.0069, 0.0058, 0.0022,\n",
      "        0.0000, 0.0000], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 1., 1., 0., 0., 1., 1., 0., 1., 0.])\n",
      "tensor([[1., 1., 0., 0., 1., 1., 0., 0., 1., 0., 1.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1), Probabilities: [0.  0.  0.2 0.2 0.  0.  0.2 0.2 0.  0.2 0. ], Predicted Values: tensor([0.0000, 0.0000, 0.4682, 0.5179, 0.0000, 0.0000, 0.0069, 0.0058, 0.0000,\n",
      "        0.0012, 0.0000], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 1., 1., 0., 0., 1., 1., 0., 0., 1.])\n",
      "tensor([[1., 1., 0., 0., 1., 1., 0., 0., 1., 1., 0.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0), Probabilities: [0.  0.  0.2 0.2 0.  0.  0.2 0.2 0.  0.  0.2], Predicted Values: tensor([    0.0000,     0.0000,     0.4686,     0.5184,     0.0000,     0.0000,\n",
      "            0.0069,     0.0059,     0.0000,     0.0000,     0.0003],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 1., 1., 0., 0., 1., 0., 1., 1., 0.])\n",
      "tensor([[1., 1., 0., 0., 1., 1., 0., 1., 0., 0., 1.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1), Probabilities: [0.         0.         0.30553782 0.30553782 0.         0.\n",
      " 0.30553782 0.         0.0681747  0.01521183 0.        ], Predicted Values: tensor([0.0000, 0.0000, 0.4641, 0.5139, 0.0000, 0.0000, 0.0007, 0.0000, 0.0201,\n",
      "        0.0012, 0.0000], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 1., 1., 0., 0., 1., 0., 1., 0., 1.])\n",
      "tensor([[1., 1., 0., 0., 1., 1., 0., 1., 0., 1., 0.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0), Probabilities: [0.         0.         0.23679119 0.23679119 0.         0.\n",
      " 0.23679119 0.         0.05283526 0.         0.23679119], Predicted Values: tensor([    0.0000,     0.0000,     0.4645,     0.5144,     0.0000,     0.0000,\n",
      "            0.0007,     0.0000,     0.0202,     0.0000,     0.0002],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 1., 1., 0., 0., 1., 0., 0., 1., 1.])\n",
      "tensor([[1., 1., 0., 0., 1., 1., 0., 1., 1., 0., 0.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0), Probabilities: [0.         0.         0.24692656 0.24692656 0.         0.\n",
      " 0.24692656 0.         0.         0.24692656 0.01229375], Predicted Values: tensor([    0.0000,     0.0000,     0.4738,     0.5241,     0.0000,     0.0000,\n",
      "            0.0007,     0.0000,     0.0000,     0.0012,     0.0002],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 1., 1., 0., 0., 0., 1., 1., 1., 0.])\n",
      "tensor([[1., 1., 0., 0., 1., 1., 1., 0., 0., 0., 1.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1), Probabilities: [0.         0.         0.30553782 0.30553782 0.         0.\n",
      " 0.         0.30553782 0.0681747  0.01521183 0.        ], Predicted Values: tensor([0.0000, 0.0000, 0.4703, 0.5201, 0.0000, 0.0000, 0.0000, 0.0059, 0.0025,\n",
      "        0.0012, 0.0000], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 1., 1., 0., 0., 0., 1., 1., 0., 1.])\n",
      "tensor([[1., 1., 0., 0., 1., 1., 1., 0., 0., 1., 0.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0), Probabilities: [0.         0.         0.23679119 0.23679119 0.         0.\n",
      " 0.         0.23679119 0.05283526 0.         0.23679119], Predicted Values: tensor([    0.0000,     0.0000,     0.4707,     0.5206,     0.0000,     0.0000,\n",
      "            0.0000,     0.0059,     0.0025,     0.0000,     0.0003],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 1., 1., 0., 0., 0., 1., 0., 1., 1.])\n",
      "tensor([[1., 1., 0., 0., 1., 1., 1., 0., 1., 0., 0.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0), Probabilities: [0.         0.         0.24692656 0.24692656 0.         0.\n",
      " 0.         0.24692656 0.         0.24692656 0.01229375], Predicted Values: tensor([    0.0000,     0.0000,     0.4716,     0.5210,     0.0000,     0.0000,\n",
      "            0.0000,     0.0059,     0.0000,     0.0012,     0.0003],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 1., 1., 0., 0., 0., 0., 1., 1., 1.])\n",
      "tensor([[1., 1., 0., 0., 1., 1., 1., 1., 0., 0., 0.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0), Probabilities: [0.         0.         0.32262497 0.32262497 0.         0.\n",
      " 0.         0.         0.32262497 0.01606255 0.01606255], Predicted Values: tensor([    0.0000,     0.0000,     0.4634,     0.5125,     0.0000,     0.0000,\n",
      "            0.0000,     0.0000,     0.0228,     0.0012,     0.0002],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 1., 0., 1., 1., 1., 1., 0., 0., 0.])\n",
      "tensor([[1., 1., 0., 1., 0., 0., 0., 0., 1., 1., 1.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1), Probabilities: [0.         0.         0.6468998  0.         0.14434286 0.14434286\n",
      " 0.03220724 0.03220724 0.         0.         0.        ], Predicted Values: tensor([0.0000, 0.0000, 0.9470, 0.0000, 0.0069, 0.0401, 0.0036, 0.0024, 0.0000,\n",
      "        0.0000, 0.0000], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 1., 0., 1., 1., 1., 0., 1., 0., 0.])\n",
      "tensor([[1., 1., 0., 1., 0., 0., 0., 1., 0., 1., 1.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1), Probabilities: [0.         0.         0.58167349 0.         0.1297889  0.1297889\n",
      " 0.02895982 0.         0.1297889  0.         0.        ], Predicted Values: tensor([    0.0000,     0.0000,     0.9426,     0.0000,     0.0069,     0.0400,\n",
      "            0.0004,     0.0000,     0.0102,     0.0000,     0.0000],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 1., 0., 1., 1., 1., 0., 0., 1., 0.])\n",
      "tensor([[1., 1., 0., 1., 0., 0., 0., 1., 1., 0., 1.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1), Probabilities: [0.         0.         0.40063342 0.         0.0893934  0.0893934\n",
      " 0.01994636 0.         0.         0.40063342 0.        ], Predicted Values: tensor([    0.0000,     0.0000,     0.9520,     0.0000,     0.0070,     0.0404,\n",
      "            0.0004,     0.0000,     0.0000,     0.0003,     0.0000],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 1., 0., 1., 1., 1., 0., 0., 0., 1.])\n",
      "tensor([[1., 1., 0., 1., 0., 0., 0., 1., 1., 1., 0.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0), Probabilities: [0.         0.         0.40063342 0.         0.0893934  0.0893934\n",
      " 0.01994636 0.         0.         0.         0.40063342], Predicted Values: tensor([    0.0000,     0.0000,     0.9522,     0.0000,     0.0070,     0.0403,\n",
      "            0.0004,     0.0000,     0.0000,     0.0000,     0.0001],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 1., 0., 1., 1., 0., 1., 1., 0., 0.])\n",
      "tensor([[1., 1., 0., 1., 0., 0., 1., 0., 0., 1., 1.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1), Probabilities: [0.         0.         0.58167349 0.         0.1297889  0.1297889\n",
      " 0.         0.02895982 0.1297889  0.         0.        ], Predicted Values: tensor([0.0000, 0.0000, 0.9491, 0.0000, 0.0070, 0.0403, 0.0000, 0.0024, 0.0013,\n",
      "        0.0000, 0.0000], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 1., 0., 1., 1., 0., 1., 0., 1., 0.])\n",
      "tensor([[1., 1., 0., 1., 0., 0., 1., 0., 1., 0., 1.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1), Probabilities: [0.         0.         0.40063342 0.         0.0893934  0.0893934\n",
      " 0.         0.01994636 0.         0.40063342 0.        ], Predicted Values: tensor([    0.0000,     0.0000,     0.9500,     0.0000,     0.0069,     0.0403,\n",
      "            0.0000,     0.0024,     0.0000,     0.0003,     0.0000],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 1., 0., 1., 1., 0., 1., 0., 0., 1.])\n",
      "tensor([[1., 1., 0., 1., 0., 0., 1., 0., 1., 1., 0.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0), Probabilities: [0.         0.         0.40063342 0.         0.0893934  0.0893934\n",
      " 0.         0.01994636 0.         0.         0.40063342], Predicted Values: tensor([    0.0000,     0.0000,     0.9502,     0.0000,     0.0070,     0.0402,\n",
      "            0.0000,     0.0024,     0.0000,     0.0000,     0.0002],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 1., 0., 1., 1., 0., 0., 1., 1., 0.])\n",
      "tensor([[1., 1., 0., 1., 0., 0., 1., 1., 0., 0., 1.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1), Probabilities: [0.         0.         0.40063342 0.         0.0893934  0.0893934\n",
      " 0.         0.         0.40063342 0.01994636 0.        ], Predicted Values: tensor([    0.0000,     0.0000,     0.9413,     0.0000,     0.0069,     0.0400,\n",
      "            0.0000,     0.0000,     0.0115,     0.0003,     0.0000],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 1., 0., 1., 1., 0., 0., 1., 0., 1.])\n",
      "tensor([[1., 1., 0., 1., 0., 0., 1., 1., 0., 1., 0.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0), Probabilities: [0.         0.         0.29016961 0.         0.06474559 0.06474559\n",
      " 0.         0.         0.29016961 0.         0.29016961], Predicted Values: tensor([    0.0000,     0.0000,     0.9415,     0.0000,     0.0069,     0.0399,\n",
      "            0.0000,     0.0000,     0.0115,     0.0000,     0.0001],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 1., 0., 1., 1., 0., 0., 0., 1., 1.])\n",
      "tensor([[1., 1., 0., 1., 0., 0., 1., 1., 1., 0., 0.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0), Probabilities: [0.         0.         0.40063342 0.         0.0893934  0.0893934\n",
      " 0.         0.         0.         0.40063342 0.01994636], Predicted Values: tensor([    0.0000,     0.0000,     0.9522,     0.0000,     0.0070,     0.0404,\n",
      "            0.0000,     0.0000,     0.0000,     0.0003,     0.0001],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 1., 0., 1., 0., 1., 1., 1., 0., 0.])\n",
      "tensor([[1., 1., 0., 1., 0., 1., 0., 0., 0., 1., 1.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1), Probabilities: [0.         0.         0.43053263 0.         0.09606482 0.\n",
      " 0.02143496 0.43053263 0.02143496 0.         0.        ], Predicted Values: tensor([0.0000, 0.0000, 0.9832, 0.0000, 0.0072, 0.0000, 0.0061, 0.0025, 0.0012,\n",
      "        0.0000, 0.0000], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 1., 0., 1., 0., 1., 1., 0., 1., 0.])\n",
      "tensor([[1., 1., 0., 1., 0., 1., 0., 0., 1., 0., 1.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1), Probabilities: [0.         0.         0.30553782 0.         0.0681747  0.\n",
      " 0.01521183 0.30553782 0.         0.30553782 0.        ], Predicted Values: tensor([    0.0000,     0.0000,     0.9841,     0.0000,     0.0072,     0.0000,\n",
      "            0.0061,     0.0025,     0.0000,     0.0002,     0.0000],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 1., 0., 1., 0., 1., 1., 0., 0., 1.])\n",
      "tensor([[1., 1., 0., 1., 0., 1., 0., 0., 1., 1., 0.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0), Probabilities: [0.         0.         0.30553782 0.         0.0681747  0.\n",
      " 0.01521183 0.30553782 0.         0.         0.30553782], Predicted Values: tensor([    0.0000,     0.0000,     0.9842,     0.0000,     0.0072,     0.0000,\n",
      "            0.0060,     0.0025,     0.0000,     0.0000,     0.0001],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 1., 0., 1., 0., 1., 0., 1., 1., 0.])\n",
      "tensor([[1., 1., 0., 1., 0., 1., 0., 1., 0., 0., 1.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1), Probabilities: [0.         0.         0.6468998  0.         0.14434286 0.\n",
      " 0.03220724 0.         0.14434286 0.03220724 0.        ], Predicted Values: tensor([    0.0000,     0.0000,     0.9814,     0.0000,     0.0072,     0.0000,\n",
      "            0.0006,     0.0000,     0.0105,     0.0002,     0.0000],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1.])\n",
      "tensor([[1., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0), Probabilities: [0.         0.         0.40063342 0.         0.0893934  0.\n",
      " 0.01994636 0.         0.0893934  0.         0.40063342], Predicted Values: tensor([    0.0000,     0.0000,     0.9816,     0.0000,     0.0072,     0.0000,\n",
      "            0.0006,     0.0000,     0.0106,     0.0000,     0.0001],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 1., 0., 1., 0., 1., 0., 0., 1., 1.])\n",
      "tensor([[1., 1., 0., 1., 0., 1., 0., 1., 1., 0., 0.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0), Probabilities: [0.         0.         0.43053263 0.         0.09606482 0.\n",
      " 0.02143496 0.         0.         0.43053263 0.02143496], Predicted Values: tensor([    0.0000,     0.0000,     0.9918,     0.0000,     0.0072,     0.0000,\n",
      "            0.0006,     0.0000,     0.0000,     0.0002,     0.0001],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 1., 0., 1., 0., 0., 1., 1., 1., 0.])\n",
      "tensor([[1., 1., 0., 1., 0., 1., 1., 0., 0., 0., 1.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1), Probabilities: [0.         0.         0.40063342 0.         0.0893934  0.\n",
      " 0.         0.40063342 0.0893934  0.01994636 0.        ], Predicted Values: tensor([    0.0000,     0.0000,     0.9887,     0.0000,     0.0072,     0.0000,\n",
      "            0.0000,     0.0025,     0.0013,     0.0002,     0.0000],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 1., 0., 1., 0., 0., 1., 1., 0., 1.])\n",
      "tensor([[1., 1., 0., 1., 0., 1., 1., 0., 0., 1., 0.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0), Probabilities: [0.         0.         0.29016961 0.         0.06474559 0.\n",
      " 0.         0.29016961 0.06474559 0.         0.29016961], Predicted Values: tensor([    0.0000,     0.0000,     0.9889,     0.0000,     0.0072,     0.0000,\n",
      "            0.0000,     0.0025,     0.0013,     0.0000,     0.0001],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 1., 0., 1., 0., 0., 1., 0., 1., 1.])\n",
      "tensor([[1., 1., 0., 1., 0., 1., 1., 0., 1., 0., 0.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0), Probabilities: [0.         0.         0.30553782 0.         0.0681747  0.\n",
      " 0.         0.30553782 0.         0.30553782 0.01521183], Predicted Values: tensor([    0.0000,     0.0000,     0.9899,     0.0000,     0.0072,     0.0000,\n",
      "            0.0000,     0.0025,     0.0000,     0.0002,     0.0001],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 1., 0., 1., 0., 0., 0., 1., 1., 1.])\n",
      "tensor([[1., 1., 0., 1., 0., 1., 1., 1., 0., 0., 0.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0), Probabilities: [0.         0.         0.43053263 0.         0.09606482 0.\n",
      " 0.         0.         0.43053263 0.02143496 0.02143496], Predicted Values: tensor([    0.0000,     0.0000,     0.9806,     0.0000,     0.0072,     0.0000,\n",
      "            0.0000,     0.0000,     0.0120,     0.0002,     0.0001],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 1., 0., 0., 1., 1., 1., 1., 0., 0.])\n",
      "tensor([[1., 1., 0., 1., 1., 0., 0., 0., 0., 1., 1.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1), Probabilities: [0.         0.         0.43053263 0.         0.         0.09606482\n",
      " 0.43053263 0.02143496 0.02143496 0.         0.        ], Predicted Values: tensor([0.0000, 0.0000, 0.9501, 0.0000, 0.0000, 0.0402, 0.0036, 0.0049, 0.0011,\n",
      "        0.0000, 0.0000], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 1., 0., 0., 1., 1., 1., 0., 1., 0.])\n",
      "tensor([[1., 1., 0., 1., 1., 0., 0., 0., 1., 0., 1.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1), Probabilities: [0.         0.         0.30553782 0.         0.         0.0681747\n",
      " 0.30553782 0.01521183 0.         0.30553782 0.        ], Predicted Values: tensor([    0.0000,     0.0000,     0.9509,     0.0000,     0.0000,     0.0402,\n",
      "            0.0036,     0.0049,     0.0000,     0.0003,     0.0000],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 1., 0., 0., 1., 1., 1., 0., 0., 1.])\n",
      "tensor([[1., 1., 0., 1., 1., 0., 0., 0., 1., 1., 0.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0), Probabilities: [0.         0.         0.30553782 0.         0.         0.0681747\n",
      " 0.30553782 0.01521183 0.         0.         0.30553782], Predicted Values: tensor([    0.0000,     0.0000,     0.9512,     0.0000,     0.0000,     0.0402,\n",
      "            0.0036,     0.0049,     0.0000,     0.0000,     0.0001],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 1., 0., 0., 1., 1., 0., 1., 1., 0.])\n",
      "tensor([[1., 1., 0., 1., 1., 0., 0., 1., 0., 0., 1.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1), Probabilities: [0.         0.         0.40063342 0.         0.         0.0893934\n",
      " 0.40063342 0.         0.0893934  0.01994636 0.        ], Predicted Values: tensor([    0.0000,     0.0000,     0.9488,     0.0000,     0.0000,     0.0402,\n",
      "            0.0004,     0.0000,     0.0103,     0.0003,     0.0000],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 1., 0., 0., 1., 1., 0., 1., 0., 1.])\n",
      "tensor([[1., 1., 0., 1., 1., 0., 0., 1., 0., 1., 0.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0), Probabilities: [0.         0.         0.29016961 0.         0.         0.06474559\n",
      " 0.29016961 0.         0.06474559 0.         0.29016961], Predicted Values: tensor([    0.0000,     0.0000,     0.9491,     0.0000,     0.0000,     0.0402,\n",
      "            0.0004,     0.0000,     0.0103,     0.0000,     0.0001],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 1., 0., 0., 1., 1., 0., 0., 1., 1.])\n",
      "tensor([[1., 1., 0., 1., 1., 0., 0., 1., 1., 0., 0.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0), Probabilities: [0.         0.         0.30553782 0.         0.         0.0681747\n",
      " 0.30553782 0.         0.         0.30553782 0.01521183], Predicted Values: tensor([    0.0000,     0.0000,     0.9587,     0.0000,     0.0000,     0.0406,\n",
      "            0.0004,     0.0000,     0.0000,     0.0003,     0.0001],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 1., 0., 0., 1., 0., 1., 1., 1., 0.])\n",
      "tensor([[1., 1., 0., 1., 1., 0., 1., 0., 0., 0., 1.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1), Probabilities: [0.         0.         0.6468998  0.         0.         0.14434286\n",
      " 0.         0.03220724 0.14434286 0.03220724 0.        ], Predicted Values: tensor([    0.0000,     0.0000,     0.9530,     0.0000,     0.0000,     0.0404,\n",
      "            0.0000,     0.0050,     0.0013,     0.0003,     0.0000],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 1., 0., 0., 1., 0., 1., 1., 0., 1.])\n",
      "tensor([[1., 1., 0., 1., 1., 0., 1., 0., 0., 1., 0.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0), Probabilities: [0.         0.         0.40063342 0.         0.         0.0893934\n",
      " 0.         0.01994636 0.0893934  0.         0.40063342], Predicted Values: tensor([    0.0000,     0.0000,     0.9533,     0.0000,     0.0000,     0.0403,\n",
      "            0.0000,     0.0050,     0.0013,     0.0000,     0.0001],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 1., 0., 0., 1., 0., 1., 0., 1., 1.])\n",
      "tensor([[1., 1., 0., 1., 1., 0., 1., 0., 1., 0., 0.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0), Probabilities: [0.         0.         0.43053263 0.         0.         0.09606482\n",
      " 0.         0.02143496 0.         0.43053263 0.02143496], Predicted Values: tensor([    0.0000,     0.0000,     0.9542,     0.0000,     0.0000,     0.0404,\n",
      "            0.0000,     0.0050,     0.0000,     0.0003,     0.0001],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 1., 0., 0., 1., 0., 0., 1., 1., 1.])\n",
      "tensor([[1., 1., 0., 1., 1., 0., 1., 1., 0., 0., 0.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0), Probabilities: [0.         0.         0.43053263 0.         0.         0.09606482\n",
      " 0.         0.         0.43053263 0.02143496 0.02143496], Predicted Values: tensor([    0.0000,     0.0000,     0.9478,     0.0000,     0.0000,     0.0401,\n",
      "            0.0000,     0.0000,     0.0116,     0.0003,     0.0001],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 1., 0., 0., 0., 1., 1., 1., 1., 0.])\n",
      "tensor([[1., 1., 0., 1., 1., 1., 0., 0., 0., 0., 1.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1), Probabilities: [0.         0.         0.32262497 0.         0.         0.\n",
      " 0.32262497 0.32262497 0.01606255 0.01606255 0.        ], Predicted Values: tensor([    0.0000,     0.0000,     0.9874,     0.0000,     0.0000,     0.0000,\n",
      "            0.0061,     0.0051,     0.0012,     0.0002,     0.0000],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 1., 0., 0., 0., 1., 1., 1., 0., 1.])\n",
      "tensor([[1., 1., 0., 1., 1., 1., 0., 0., 0., 1., 0.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0), Probabilities: [0.         0.         0.24692656 0.         0.         0.\n",
      " 0.24692656 0.24692656 0.01229375 0.         0.24692656], Predicted Values: tensor([    0.0000,     0.0000,     0.9876,     0.0000,     0.0000,     0.0000,\n",
      "            0.0061,     0.0052,     0.0012,     0.0000,     0.0001],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 1., 0., 0., 0., 1., 1., 0., 1., 1.])\n",
      "tensor([[1., 1., 0., 1., 1., 1., 0., 0., 1., 0., 0.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0), Probabilities: [0.         0.         0.24692656 0.         0.         0.\n",
      " 0.24692656 0.24692656 0.         0.24692656 0.01229375], Predicted Values: tensor([    0.0000,     0.0000,     0.9885,     0.0000,     0.0000,     0.0000,\n",
      "            0.0061,     0.0052,     0.0000,     0.0002,     0.0001],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 1., 0., 0., 0., 1., 0., 1., 1., 1.])\n",
      "tensor([[1., 1., 0., 1., 1., 1., 0., 1., 0., 0., 0.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0), Probabilities: [0.         0.         0.43053263 0.         0.         0.\n",
      " 0.43053263 0.         0.09606482 0.02143496 0.02143496], Predicted Values: tensor([    0.0000,     0.0000,     0.9884,     0.0000,     0.0000,     0.0000,\n",
      "            0.0006,     0.0000,     0.0107,     0.0002,     0.0000],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 1., 0., 0., 0., 0., 1., 1., 1., 1.])\n",
      "tensor([[1., 1., 0., 1., 1., 1., 1., 0., 0., 0., 0.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0), Probabilities: [0.         0.         0.43053263 0.         0.         0.\n",
      " 0.         0.43053263 0.09606482 0.02143496 0.02143496], Predicted Values: tensor([    0.0000,     0.0000,     0.9932,     0.0000,     0.0000,     0.0000,\n",
      "            0.0000,     0.0052,     0.0013,     0.0002,     0.0001],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 0., 1., 1., 1., 1., 1., 0., 0., 0.])\n",
      "tensor([[1., 1., 1., 0., 0., 0., 0., 0., 1., 1., 1.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1), Probabilities: [0.         0.         0.         0.43053263 0.43053263 0.09606482\n",
      " 0.02143496 0.02143496 0.         0.         0.        ], Predicted Values: tensor([0.0000, 0.0000, 0.0000, 0.9638, 0.0097, 0.0181, 0.0050, 0.0033, 0.0000,\n",
      "        0.0000, 0.0000], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 0., 1., 1., 1., 1., 0., 1., 0., 0.])\n",
      "tensor([[1., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1), Probabilities: [0.         0.         0.         0.40063342 0.40063342 0.0893934\n",
      " 0.01994636 0.         0.0893934  0.         0.        ], Predicted Values: tensor([    0.0000,     0.0000,     0.0000,     0.9639,     0.0098,     0.0181,\n",
      "            0.0005,     0.0000,     0.0077,     0.0000,     0.0000],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 0., 1., 1., 1., 1., 0., 0., 1., 0.])\n",
      "tensor([[1., 1., 1., 0., 0., 0., 0., 1., 1., 0., 1.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1), Probabilities: [0.         0.         0.         0.30553782 0.30553782 0.0681747\n",
      " 0.01521183 0.         0.         0.30553782 0.        ], Predicted Values: tensor([    0.0000,     0.0000,     0.0000,     0.9706,     0.0098,     0.0182,\n",
      "            0.0005,     0.0000,     0.0000,     0.0008,     0.0000],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 0., 1., 1., 1., 1., 0., 0., 0., 1.])\n",
      "tensor([[1., 1., 1., 0., 0., 0., 0., 1., 1., 1., 0.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0), Probabilities: [0.         0.         0.         0.30553782 0.30553782 0.0681747\n",
      " 0.01521183 0.         0.         0.         0.30553782], Predicted Values: tensor([    0.0000,     0.0000,     0.0000,     0.9711,     0.0098,     0.0182,\n",
      "            0.0005,     0.0000,     0.0000,     0.0000,     0.0003],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 0., 1., 1., 1., 0., 1., 1., 0., 0.])\n",
      "tensor([[1., 1., 1., 0., 0., 0., 1., 0., 0., 1., 1.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1), Probabilities: [0.         0.         0.         0.40063342 0.40063342 0.0893934\n",
      " 0.         0.01994636 0.0893934  0.         0.        ], Predicted Values: tensor([    0.0000,     0.0000,     0.0000,     0.9677,     0.0098,     0.0182,\n",
      "            0.0000,     0.0034,     0.0010,     0.0000,     0.0000],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 0., 1., 1., 1., 0., 1., 0., 1., 0.])\n",
      "tensor([[1., 1., 1., 0., 0., 0., 1., 0., 1., 0., 1.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1), Probabilities: [0.         0.         0.         0.30553782 0.30553782 0.0681747\n",
      " 0.         0.01521183 0.         0.30553782 0.        ], Predicted Values: tensor([    0.0000,     0.0000,     0.0000,     0.9678,     0.0098,     0.0182,\n",
      "            0.0000,     0.0034,     0.0000,     0.0008,     0.0000],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 0., 1., 1., 1., 0., 1., 0., 0., 1.])\n",
      "tensor([[1., 1., 1., 0., 0., 0., 1., 0., 1., 1., 0.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0), Probabilities: [0.         0.         0.         0.30553782 0.30553782 0.0681747\n",
      " 0.         0.01521183 0.         0.         0.30553782], Predicted Values: tensor([    0.0000,     0.0000,     0.0000,     0.9681,     0.0098,     0.0182,\n",
      "            0.0000,     0.0034,     0.0000,     0.0000,     0.0005],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 0., 1., 1., 1., 0., 0., 1., 1., 0.])\n",
      "tensor([[1., 1., 1., 0., 0., 0., 1., 1., 0., 0., 1.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1), Probabilities: [0.         0.         0.         0.30553782 0.30553782 0.0681747\n",
      " 0.         0.         0.30553782 0.01521183 0.        ], Predicted Values: tensor([    0.0000,     0.0000,     0.0000,     0.9626,     0.0098,     0.0181,\n",
      "            0.0000,     0.0000,     0.0088,     0.0008,     0.0000],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 0., 1., 1., 1., 0., 0., 1., 0., 1.])\n",
      "tensor([[1., 1., 1., 0., 0., 0., 1., 1., 0., 1., 0.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0), Probabilities: [0.         0.         0.         0.23679119 0.23679119 0.05283526\n",
      " 0.         0.         0.23679119 0.         0.23679119], Predicted Values: tensor([    0.0000,     0.0000,     0.0000,     0.9630,     0.0098,     0.0181,\n",
      "            0.0000,     0.0000,     0.0088,     0.0000,     0.0003],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 0., 1., 1., 1., 0., 0., 0., 1., 1.])\n",
      "tensor([[1., 1., 1., 0., 0., 0., 1., 1., 1., 0., 0.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0), Probabilities: [0.         0.         0.         0.30553782 0.30553782 0.0681747\n",
      " 0.         0.         0.         0.30553782 0.01521183], Predicted Values: tensor([    0.0000,     0.0000,     0.0000,     0.9708,     0.0099,     0.0183,\n",
      "            0.0000,     0.0000,     0.0000,     0.0008,     0.0003],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 0., 1., 1., 0., 1., 1., 1., 0., 0.])\n",
      "tensor([[1., 1., 1., 0., 0., 1., 0., 0., 0., 1., 1.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1), Probabilities: [0.         0.         0.         0.32262497 0.32262497 0.\n",
      " 0.01606255 0.32262497 0.01606255 0.         0.        ], Predicted Values: tensor([    0.0000,     0.0000,     0.0000,     0.9776,     0.0099,     0.0000,\n",
      "            0.0083,     0.0034,     0.0009,     0.0000,     0.0000],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 0., 1., 1., 0., 1., 1., 0., 1., 0.])\n",
      "tensor([[1., 1., 1., 0., 0., 1., 0., 0., 1., 0., 1.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1), Probabilities: [0.         0.         0.         0.24692656 0.24692656 0.\n",
      " 0.01229375 0.24692656 0.         0.24692656 0.        ], Predicted Values: tensor([    0.0000,     0.0000,     0.0000,     0.9779,     0.0099,     0.0000,\n",
      "            0.0083,     0.0034,     0.0000,     0.0005,     0.0000],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 0., 1., 1., 0., 1., 1., 0., 0., 1.])\n",
      "tensor([[1., 1., 1., 0., 0., 1., 0., 0., 1., 1., 0.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0), Probabilities: [0.         0.         0.         0.24692656 0.24692656 0.\n",
      " 0.01229375 0.24692656 0.         0.         0.24692656], Predicted Values: tensor([    0.0000,     0.0000,     0.0000,     0.9781,     0.0099,     0.0000,\n",
      "            0.0083,     0.0034,     0.0000,     0.0000,     0.0003],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 0., 1., 1., 0., 1., 0., 1., 1., 0.])\n",
      "tensor([[1., 1., 1., 0., 0., 1., 0., 1., 0., 0., 1.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1), Probabilities: [0.         0.         0.         0.43053263 0.43053263 0.\n",
      " 0.02143496 0.         0.09606482 0.02143496 0.        ], Predicted Values: tensor([    0.0000,     0.0000,     0.0000,     0.9808,     0.0099,     0.0000,\n",
      "            0.0009,     0.0000,     0.0079,     0.0005,     0.0000],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 0., 1., 1., 0., 1., 0., 1., 0., 1.])\n",
      "tensor([[1., 1., 1., 0., 0., 1., 0., 1., 0., 1., 0.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0), Probabilities: [0.         0.         0.         0.30553782 0.30553782 0.\n",
      " 0.01521183 0.         0.0681747  0.         0.30553782], Predicted Values: tensor([    0.0000,     0.0000,     0.0000,     0.9812,     0.0099,     0.0000,\n",
      "            0.0009,     0.0000,     0.0079,     0.0000,     0.0002],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 0., 1., 1., 0., 1., 0., 0., 1., 1.])\n",
      "tensor([[1., 1., 1., 0., 0., 1., 0., 1., 1., 0., 0.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0), Probabilities: [0.         0.         0.         0.32262497 0.32262497 0.\n",
      " 0.01606255 0.         0.         0.32262497 0.01606255], Predicted Values: tensor([    0.0000,     0.0000,     0.0000,     0.9884,     0.0100,     0.0000,\n",
      "            0.0009,     0.0000,     0.0000,     0.0005,     0.0002],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 0., 1., 1., 0., 0., 1., 1., 1., 0.])\n",
      "tensor([[1., 1., 1., 0., 0., 1., 1., 0., 0., 0., 1.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1), Probabilities: [0.         0.         0.         0.30553782 0.30553782 0.\n",
      " 0.         0.30553782 0.0681747  0.01521183 0.        ], Predicted Values: tensor([    0.0000,     0.0000,     0.0000,     0.9851,     0.0100,     0.0000,\n",
      "            0.0000,     0.0035,     0.0010,     0.0005,     0.0000],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 0., 1., 1., 0., 0., 1., 1., 0., 1.])\n",
      "tensor([[1., 1., 1., 0., 0., 1., 1., 0., 0., 1., 0.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0), Probabilities: [0.         0.         0.         0.23679119 0.23679119 0.\n",
      " 0.         0.23679119 0.05283526 0.         0.23679119], Predicted Values: tensor([    0.0000,     0.0000,     0.0000,     0.9853,     0.0100,     0.0000,\n",
      "            0.0000,     0.0035,     0.0010,     0.0000,     0.0002],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 0., 1., 1., 0., 0., 1., 0., 1., 1.])\n",
      "tensor([[1., 1., 1., 0., 0., 1., 1., 0., 1., 0., 0.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0), Probabilities: [0.         0.         0.         0.24692656 0.24692656 0.\n",
      " 0.         0.24692656 0.         0.24692656 0.01229375], Predicted Values: tensor([    0.0000,     0.0000,     0.0000,     0.9858,     0.0100,     0.0000,\n",
      "            0.0000,     0.0035,     0.0000,     0.0005,     0.0002],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 0., 1., 1., 0., 0., 0., 1., 1., 1.])\n",
      "tensor([[1., 1., 1., 0., 0., 1., 1., 1., 0., 0., 0.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0), Probabilities: [0.         0.         0.         0.32262497 0.32262497 0.\n",
      " 0.         0.         0.32262497 0.01606255 0.01606255], Predicted Values: tensor([    0.0000,     0.0000,     0.0000,     0.9804,     0.0099,     0.0000,\n",
      "            0.0000,     0.0000,     0.0089,     0.0005,     0.0001],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 0., 1., 0., 1., 1., 1., 1., 0., 0.])\n",
      "tensor([[1., 1., 1., 0., 1., 0., 0., 0., 0., 1., 1.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1), Probabilities: [0.         0.         0.         0.43053263 0.         0.09606482\n",
      " 0.43053263 0.02143496 0.02143496 0.         0.        ], Predicted Values: tensor([    0.0000,     0.0000,     0.0000,     0.9689,     0.0000,     0.0182,\n",
      "            0.0051,     0.0070,     0.0009,     0.0000,     0.0000],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 0., 1., 0., 1., 1., 1., 0., 1., 0.])\n",
      "tensor([[1., 1., 1., 0., 1., 0., 0., 0., 1., 0., 1.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1), Probabilities: [0.         0.         0.         0.30553782 0.         0.0681747\n",
      " 0.30553782 0.01521183 0.         0.30553782 0.        ], Predicted Values: tensor([    0.0000,     0.0000,     0.0000,     0.9690,     0.0000,     0.0182,\n",
      "            0.0051,     0.0070,     0.0000,     0.0008,     0.0000],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 0., 1., 0., 1., 1., 1., 0., 0., 1.])\n",
      "tensor([[1., 1., 1., 0., 1., 0., 0., 0., 1., 1., 0.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0), Probabilities: [0.         0.         0.         0.30553782 0.         0.0681747\n",
      " 0.30553782 0.01521183 0.         0.         0.30553782], Predicted Values: tensor([    0.0000,     0.0000,     0.0000,     0.9695,     0.0000,     0.0182,\n",
      "            0.0051,     0.0070,     0.0000,     0.0000,     0.0003],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 0., 1., 0., 1., 1., 0., 1., 1., 0.])\n",
      "tensor([[1., 1., 1., 0., 1., 0., 0., 1., 0., 0., 1.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1), Probabilities: [0.         0.         0.         0.40063342 0.         0.0893934\n",
      " 0.40063342 0.         0.0893934  0.01994636 0.        ], Predicted Values: tensor([    0.0000,     0.0000,     0.0000,     0.9726,     0.0000,     0.0183,\n",
      "            0.0005,     0.0000,     0.0078,     0.0008,     0.0000],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 0., 1., 0., 1., 1., 0., 1., 0., 1.])\n",
      "tensor([[1., 1., 1., 0., 1., 0., 0., 1., 0., 1., 0.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0), Probabilities: [0.         0.         0.         0.29016961 0.         0.06474559\n",
      " 0.29016961 0.         0.06474559 0.         0.29016961], Predicted Values: tensor([    0.0000,     0.0000,     0.0000,     0.9732,     0.0000,     0.0182,\n",
      "            0.0005,     0.0000,     0.0079,     0.0000,     0.0002],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 0., 1., 0., 1., 1., 0., 0., 1., 1.])\n",
      "tensor([[1., 1., 1., 0., 1., 0., 0., 1., 1., 0., 0.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0), Probabilities: [0.         0.         0.         0.30553782 0.         0.0681747\n",
      " 0.30553782 0.         0.         0.30553782 0.01521183], Predicted Values: tensor([    0.0000,     0.0000,     0.0000,     0.9801,     0.0000,     0.0184,\n",
      "            0.0005,     0.0000,     0.0000,     0.0008,     0.0002],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 0.])\n",
      "tensor([[1., 1., 1., 0., 1., 0., 1., 0., 0., 0., 1.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1), Probabilities: [0.         0.         0.         0.6468998  0.         0.14434286\n",
      " 0.         0.03220724 0.14434286 0.03220724 0.        ], Predicted Values: tensor([    0.0000,     0.0000,     0.0000,     0.9729,     0.0000,     0.0183,\n",
      "            0.0000,     0.0071,     0.0010,     0.0008,     0.0000],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 0., 1., 0., 1., 0., 1., 1., 0., 1.])\n",
      "tensor([[1., 1., 1., 0., 1., 0., 1., 0., 0., 1., 0.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0), Probabilities: [0.         0.         0.         0.40063342 0.         0.0893934\n",
      " 0.         0.01994636 0.0893934  0.         0.40063342], Predicted Values: tensor([    0.0000,     0.0000,     0.0000,     0.9734,     0.0000,     0.0183,\n",
      "            0.0000,     0.0071,     0.0010,     0.0000,     0.0003],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 0., 1., 0., 1., 0., 1., 0., 1., 1.])\n",
      "tensor([[1., 1., 1., 0., 1., 0., 1., 0., 1., 0., 0.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0), Probabilities: [0.         0.         0.         0.43053263 0.         0.09606482\n",
      " 0.         0.02143496 0.         0.43053263 0.02143496], Predicted Values: tensor([    0.0000,     0.0000,     0.0000,     0.9736,     0.0000,     0.0183,\n",
      "            0.0000,     0.0071,     0.0000,     0.0008,     0.0003],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 0., 1., 0., 1., 0., 0., 1., 1., 1.])\n",
      "tensor([[1., 1., 1., 0., 1., 0., 1., 1., 0., 0., 0.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0), Probabilities: [0.         0.         0.         0.43053263 0.         0.09606482\n",
      " 0.         0.         0.43053263 0.02143496 0.02143496], Predicted Values: tensor([    0.0000,     0.0000,     0.0000,     0.9719,     0.0000,     0.0183,\n",
      "            0.0000,     0.0000,     0.0089,     0.0008,     0.0002],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 0., 1., 0., 0., 1., 1., 1., 1., 0.])\n",
      "tensor([[1., 1., 1., 0., 1., 1., 0., 0., 0., 0., 1.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1), Probabilities: [0.         0.         0.         0.32262497 0.         0.\n",
      " 0.32262497 0.32262497 0.01606255 0.01606255 0.        ], Predicted Values: tensor([    0.0000,     0.0000,     0.0000,     0.9831,     0.0000,     0.0000,\n",
      "            0.0084,     0.0071,     0.0009,     0.0005,     0.0000],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 0., 1., 0., 0., 1., 1., 1., 0., 1.])\n",
      "tensor([[1., 1., 1., 0., 1., 1., 0., 0., 0., 1., 0.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0), Probabilities: [0.         0.         0.         0.24692656 0.         0.\n",
      " 0.24692656 0.24692656 0.01229375 0.         0.24692656], Predicted Values: tensor([    0.0000,     0.0000,     0.0000,     0.9835,     0.0000,     0.0000,\n",
      "            0.0084,     0.0071,     0.0009,     0.0000,     0.0001],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 0., 1., 0., 0., 1., 1., 0., 1., 1.])\n",
      "tensor([[1., 1., 1., 0., 1., 1., 0., 0., 1., 0., 0.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0), Probabilities: [0.         0.         0.         0.24692656 0.         0.\n",
      " 0.24692656 0.24692656 0.         0.24692656 0.01229375], Predicted Values: tensor([    0.0000,     0.0000,     0.0000,     0.9839,     0.0000,     0.0000,\n",
      "            0.0083,     0.0071,     0.0000,     0.0005,     0.0001],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 0., 1., 0., 0., 1., 0., 1., 1., 1.])\n",
      "tensor([[1., 1., 1., 0., 1., 1., 0., 1., 0., 0., 0.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0), Probabilities: [0.         0.         0.         0.43053263 0.         0.\n",
      " 0.43053263 0.         0.09606482 0.02143496 0.02143496], Predicted Values: tensor([    0.0000,     0.0000,     0.0000,     0.9905,     0.0000,     0.0000,\n",
      "            0.0009,     0.0000,     0.0080,     0.0005,     0.0001],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 0., 1., 0., 0., 0., 1., 1., 1., 1.])\n",
      "tensor([[1., 1., 1., 0., 1., 1., 1., 0., 0., 0., 0.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0), Probabilities: [0.         0.         0.         0.43053263 0.         0.\n",
      " 0.         0.43053263 0.09606482 0.02143496 0.02143496], Predicted Values: tensor([    0.0000,     0.0000,     0.0000,     0.9911,     0.0000,     0.0000,\n",
      "            0.0000,     0.0072,     0.0010,     0.0005,     0.0001],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 0., 0., 1., 1., 1., 1., 1., 0., 0.])\n",
      "tensor([[1., 1., 1., 1., 0., 0., 0., 0., 0., 1., 1.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1), Probabilities: [0.         0.         0.         0.         0.46525451 0.46525451\n",
      " 0.02316366 0.02316366 0.02316366 0.         0.        ], Predicted Values: tensor([0.0000, 0.0000, 0.0000, 0.0000, 0.1210, 0.7688, 0.0628, 0.0413, 0.0062,\n",
      "        0.0000, 0.0000], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 0., 0., 1., 1., 1., 1., 0., 1., 0.])\n",
      "tensor([[1., 1., 1., 1., 0., 0., 0., 0., 1., 0., 1.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1), Probabilities: [0.         0.         0.         0.         0.32262497 0.32262497\n",
      " 0.01606255 0.01606255 0.         0.32262497 0.        ], Predicted Values: tensor([0.0000, 0.0000, 0.0000, 0.0000, 0.1214, 0.7721, 0.0629, 0.0414, 0.0000,\n",
      "        0.0021, 0.0000], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 0., 0., 1., 1., 1., 1., 0., 0., 1.])\n",
      "tensor([[1., 1., 1., 1., 0., 0., 0., 0., 1., 1., 0.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0), Probabilities: [0.         0.         0.         0.         0.32262497 0.32262497\n",
      " 0.01606255 0.01606255 0.         0.         0.32262497], Predicted Values: tensor([0.0000, 0.0000, 0.0000, 0.0000, 0.1218, 0.7724, 0.0630, 0.0415, 0.0000,\n",
      "        0.0000, 0.0013], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 0., 0., 1., 1., 1., 0., 1., 1., 0.])\n",
      "tensor([[1., 1., 1., 1., 0., 0., 0., 1., 0., 0., 1.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1), Probabilities: [0.         0.         0.         0.         0.43053263 0.43053263\n",
      " 0.02143496 0.         0.09606482 0.02143496 0.        ], Predicted Values: tensor([0.0000, 0.0000, 0.0000, 0.0000, 0.1265, 0.8047, 0.0069, 0.0000, 0.0597,\n",
      "        0.0022, 0.0000], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 0., 0., 1., 1., 1., 0., 1., 0., 1.])\n",
      "tensor([[1., 1., 1., 1., 0., 0., 0., 1., 0., 1., 0.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0), Probabilities: [0.         0.         0.         0.         0.30553782 0.30553782\n",
      " 0.01521183 0.         0.0681747  0.         0.30553782], Predicted Values: tensor([0.0000, 0.0000, 0.0000, 0.0000, 0.1270, 0.8053, 0.0069, 0.0000, 0.0599,\n",
      "        0.0000, 0.0009], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 0., 0., 1., 1., 1., 0., 0., 1., 1.])\n",
      "tensor([[1., 1., 1., 1., 0., 0., 0., 1., 1., 0., 0.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0), Probabilities: [0.         0.         0.         0.         0.32262497 0.32262497\n",
      " 0.01606255 0.         0.         0.32262497 0.01606255], Predicted Values: tensor([0.0000, 0.0000, 0.0000, 0.0000, 0.1347, 0.8548, 0.0073, 0.0000, 0.0000,\n",
      "        0.0023, 0.0009], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 0., 0., 1., 1., 0., 1., 1., 1., 0.])\n",
      "tensor([[1., 1., 1., 1., 0., 0., 1., 0., 0., 0., 1.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1), Probabilities: [0.         0.         0.         0.         0.43053263 0.43053263\n",
      " 0.         0.02143496 0.09606482 0.02143496 0.        ], Predicted Values: tensor([0.0000, 0.0000, 0.0000, 0.0000, 0.1287, 0.8174, 0.0000, 0.0442, 0.0075,\n",
      "        0.0022, 0.0000], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 0., 0., 1., 1., 0., 1., 1., 0., 1.])\n",
      "tensor([[1., 1., 1., 1., 0., 0., 1., 0., 0., 1., 0.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0), Probabilities: [0.         0.         0.         0.         0.30553782 0.30553782\n",
      " 0.         0.01521183 0.0681747  0.         0.30553782], Predicted Values: tensor([0.0000, 0.0000, 0.0000, 0.0000, 0.1291, 0.8178, 0.0000, 0.0443, 0.0075,\n",
      "        0.0000, 0.0013], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 0., 0., 1., 1., 0., 1., 0., 1., 1.])\n",
      "tensor([[1., 1., 1., 1., 0., 0., 1., 0., 1., 0., 0.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0), Probabilities: [0.         0.         0.         0.         0.32262497 0.32262497\n",
      " 0.         0.01606255 0.         0.32262497 0.01606255], Predicted Values: tensor([0.0000, 0.0000, 0.0000, 0.0000, 0.1297, 0.8223, 0.0000, 0.0445, 0.0000,\n",
      "        0.0023, 0.0013], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 0., 0., 1., 1., 0., 0., 1., 1., 1.])\n",
      "tensor([[1., 1., 1., 1., 0., 0., 1., 1., 0., 0., 0.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0), Probabilities: [0.         0.         0.         0.         0.32262497 0.32262497\n",
      " 0.         0.         0.32262497 0.01606255 0.01606255], Predicted Values: tensor([    0.0000,     0.0000,     0.0000,     0.0000,     0.1267,     0.8026,\n",
      "            0.0000,     0.0000,     0.0677,     0.0022,     0.0008],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 0., 0., 1., 0., 1., 1., 1., 1., 0.])\n",
      "tensor([[1., 1., 1., 1., 0., 1., 0., 0., 0., 0., 1.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1), Probabilities: [0.         0.         0.         0.         0.46525451 0.\n",
      " 0.02316366 0.46525451 0.02316366 0.02316366 0.        ], Predicted Values: tensor([0.0000, 0.0000, 0.0000, 0.0000, 0.4438, 0.0000, 0.3755, 0.1526, 0.0228,\n",
      "        0.0052, 0.0000], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 0., 0., 1., 0., 1., 1., 1., 0., 1.])\n",
      "tensor([[1., 1., 1., 1., 0., 1., 0., 0., 0., 1., 0.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0), Probabilities: [0.         0.         0.         0.         0.32262497 0.\n",
      " 0.01606255 0.32262497 0.01606255 0.         0.32262497], Predicted Values: tensor([0.0000, 0.0000, 0.0000, 0.0000, 0.4457, 0.0000, 0.3760, 0.1531, 0.0229,\n",
      "        0.0000, 0.0022], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 0., 0., 1., 0., 1., 1., 0., 1., 1.])\n",
      "tensor([[1., 1., 1., 1., 0., 1., 0., 0., 1., 0., 0.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0), Probabilities: [0.         0.         0.         0.         0.32262497 0.\n",
      " 0.01606255 0.32262497 0.         0.32262497 0.01606255], Predicted Values: tensor([0.0000, 0.0000, 0.0000, 0.0000, 0.4538, 0.0000, 0.3826, 0.1560, 0.0000,\n",
      "        0.0054, 0.0023], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1.])\n",
      "tensor([[1., 1., 1., 1., 0., 1., 0., 1., 0., 0., 0.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0), Probabilities: [0.         0.         0.         0.         0.72860203 0.\n",
      " 0.03627496 0.         0.16257309 0.03627496 0.03627496], Predicted Values: tensor([0.0000, 0.0000, 0.0000, 0.0000, 0.6348, 0.0000, 0.0561, 0.0000, 0.2996,\n",
      "        0.0075, 0.0020], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 0., 0., 1., 0., 0., 1., 1., 1., 1.])\n",
      "tensor([[1., 1., 1., 1., 0., 1., 1., 0., 0., 0., 0.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0), Probabilities: [0.         0.         0.         0.         0.43053263 0.\n",
      " 0.         0.43053263 0.09606482 0.02143496 0.02143496], Predicted Values: tensor([0.0000, 0.0000, 0.0000, 0.0000, 0.7041, 0.0000, 0.0000, 0.2433, 0.0410,\n",
      "        0.0083, 0.0033], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 0.])\n",
      "tensor([[1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 1.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1), Probabilities: [0.         0.         0.         0.         0.         0.46525451\n",
      " 0.46525451 0.02316366 0.02316366 0.02316366 0.        ], Predicted Values: tensor([0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.8305, 0.0677, 0.0928, 0.0067,\n",
      "        0.0023, 0.0000], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 0., 0., 0., 1., 1., 1., 1., 0., 1.])\n",
      "tensor([[1., 1., 1., 1., 1., 0., 0., 0., 0., 1., 0.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0), Probabilities: [0.         0.         0.         0.         0.         0.32262497\n",
      " 0.32262497 0.01606255 0.01606255 0.         0.32262497], Predicted Values: tensor([    0.0000,     0.0000,     0.0000,     0.0000,     0.0000,     0.8316,\n",
      "            0.0678,     0.0931,     0.0068,     0.0000,     0.0007],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 0., 0., 0., 1., 1., 1., 0., 1., 1.])\n",
      "tensor([[1., 1., 1., 1., 1., 0., 0., 0., 1., 0., 0.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0), Probabilities: [0.         0.         0.         0.         0.         0.32262497\n",
      " 0.32262497 0.01606255 0.         0.32262497 0.01606255], Predicted Values: tensor([    0.0000,     0.0000,     0.0000,     0.0000,     0.0000,     0.8355,\n",
      "            0.0680,     0.0934,     0.0000,     0.0023,     0.0007],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 0., 0., 0., 1., 1., 0., 1., 1., 1.])\n",
      "tensor([[1., 1., 1., 1., 1., 0., 0., 1., 0., 0., 0.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0), Probabilities: [0.         0.         0.         0.         0.         0.43053263\n",
      " 0.43053263 0.         0.09606482 0.02143496 0.02143496], Predicted Values: tensor([    0.0000,     0.0000,     0.0000,     0.0000,     0.0000,     0.9203,\n",
      "            0.0079,     0.0000,     0.0688,     0.0025,     0.0005],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 0., 0., 0., 1., 0., 1., 1., 1., 1.])\n",
      "tensor([[1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 0.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0), Probabilities: [0.         0.         0.         0.         0.         0.72860203\n",
      " 0.         0.03627496 0.16257309 0.03627496 0.03627496], Predicted Values: tensor([    0.0000,     0.0000,     0.0000,     0.0000,     0.0000,     0.8886,\n",
      "            0.0000,     0.1001,     0.0082,     0.0024,     0.0007],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1.])\n",
      "tensor([[1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0), Probabilities: [0.         0.         0.         0.         0.         0.\n",
      " 0.46525451 0.46525451 0.02316366 0.02316366 0.02316366], Predicted Values: tensor([0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.5190, 0.4403, 0.0318,\n",
      "        0.0073, 0.0016], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0.])\n",
      "tensor([[1., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1), Probabilities: [0.         0.32789174 0.32789174 0.32789174 0.01632477 0.\n",
      " 0.         0.         0.         0.         0.        ], Predicted Values: tensor([0.0000, 0.1502, 0.3905, 0.4479, 0.0115, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 1., 1., 0., 1., 0., 0., 0., 0., 0.])\n",
      "tensor([[1., 0., 0., 0., 1., 0., 1., 1., 1., 1., 1.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1), Probabilities: [0.         0.32789174 0.32789174 0.32789174 0.         0.01632477\n",
      " 0.         0.         0.         0.         0.        ], Predicted Values: tensor([0.0000, 0.1506, 0.3904, 0.4482, 0.0000, 0.0108, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 1., 1., 0., 0., 1., 0., 0., 0., 0.])\n",
      "tensor([[1., 0., 0., 0., 1., 1., 0., 1., 1., 1., 1.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1), Probabilities: [0.   0.25 0.25 0.25 0.   0.   0.25 0.   0.   0.   0.  ], Predicted Values: tensor([0.0000, 0.1517, 0.3944, 0.4528, 0.0000, 0.0000, 0.0010, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 1., 1., 0., 0., 0., 1., 0., 0., 0.])\n",
      "tensor([[1., 0., 0., 0., 1., 1., 1., 0., 1., 1., 1.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1), Probabilities: [0.   0.25 0.25 0.25 0.   0.   0.   0.25 0.   0.   0.  ], Predicted Values: tensor([0.0000, 0.1507, 0.3917, 0.4492, 0.0000, 0.0000, 0.0000, 0.0083, 0.0000,\n",
      "        0.0000, 0.0000], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 1., 1., 0., 0., 0., 0., 1., 0., 0.])\n",
      "tensor([[1., 0., 0., 0., 1., 1., 1., 1., 0., 1., 1.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1), Probabilities: [0.   0.25 0.25 0.25 0.   0.   0.   0.   0.25 0.   0.  ], Predicted Values: tensor([0.0000, 0.1458, 0.3788, 0.4348, 0.0000, 0.0000, 0.0000, 0.0000, 0.0407,\n",
      "        0.0000, 0.0000], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 1., 1., 0., 0., 0., 0., 0., 1., 0.])\n",
      "tensor([[1., 0., 0., 0., 1., 1., 1., 1., 1., 0., 1.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1), Probabilities: [0.   0.25 0.25 0.25 0.   0.   0.   0.   0.   0.25 0.  ], Predicted Values: tensor([0.0000, 0.1513, 0.3931, 0.4507, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0049, 0.0000], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 1., 1., 0., 0., 0., 0., 0., 0., 1.])\n",
      "tensor([[1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 0.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0), Probabilities: [0.   0.25 0.25 0.25 0.   0.   0.   0.   0.   0.   0.25], Predicted Values: tensor([0.0000, 0.1518, 0.3948, 0.4527, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0007], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 1., 0., 1., 1., 0., 0., 0., 0., 0.])\n",
      "tensor([[1., 0., 0., 1., 0., 0., 1., 1., 1., 1., 1.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1), Probabilities: [0.         0.43996323 0.43996323 0.         0.02190448 0.09816907\n",
      " 0.         0.         0.         0.         0.        ], Predicted Values: tensor([0.0000, 0.1536, 0.8045, 0.0000, 0.0100, 0.0319, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 1., 0., 1., 0., 1., 0., 0., 0., 0.])\n",
      "tensor([[1., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1), Probabilities: [0.         0.47628706 0.47628706 0.         0.02371294 0.\n",
      " 0.02371294 0.         0.         0.         0.        ], Predicted Values: tensor([0.0000, 0.1582, 0.8307, 0.0000, 0.0102, 0.0000, 0.0009, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 1., 0., 1., 0., 0., 1., 0., 0., 0.])\n",
      "tensor([[1., 0., 0., 1., 0., 1., 1., 0., 1., 1., 1.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1), Probabilities: [0.         0.32789174 0.32789174 0.         0.01632477 0.\n",
      " 0.         0.32789174 0.         0.         0.        ], Predicted Values: tensor([0.0000, 0.1578, 0.8285, 0.0000, 0.0102, 0.0000, 0.0000, 0.0035, 0.0000,\n",
      "        0.0000, 0.0000], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 1., 0., 1., 0., 0., 0., 1., 0., 0.])\n",
      "tensor([[1., 0., 0., 1., 0., 1., 1., 1., 0., 1., 1.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1), Probabilities: [0.         0.32789174 0.32789174 0.         0.01632477 0.\n",
      " 0.         0.         0.32789174 0.         0.        ], Predicted Values: tensor([0.0000, 0.1549, 0.8133, 0.0000, 0.0101, 0.0000, 0.0000, 0.0000, 0.0217,\n",
      "        0.0000, 0.0000], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 1., 0., 1., 0., 0., 0., 0., 1., 0.])\n",
      "tensor([[1., 0., 0., 1., 0., 1., 1., 1., 1., 0., 1.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1), Probabilities: [0.         0.32789174 0.32789174 0.         0.01632477 0.\n",
      " 0.         0.         0.         0.32789174 0.        ], Predicted Values: tensor([0.0000, 0.1582, 0.8306, 0.0000, 0.0103, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0009, 0.0000], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 1., 0., 1., 0., 0., 0., 0., 0., 1.])\n",
      "tensor([[1., 0., 0., 1., 0., 1., 1., 1., 1., 1., 0.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0), Probabilities: [0.         0.32789174 0.32789174 0.         0.01632477 0.\n",
      " 0.         0.         0.         0.         0.32789174], Predicted Values: tensor([    0.0000,     0.1582,     0.8313,     0.0000,     0.0103,     0.0000,\n",
      "            0.0000,     0.0000,     0.0000,     0.0000,     0.0002],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 1., 0., 0., 1., 1., 0., 0., 0., 0.])\n",
      "tensor([[1., 0., 0., 1., 1., 0., 0., 1., 1., 1., 1.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1), Probabilities: [0.         0.31025741 0.31025741 0.         0.         0.06922778\n",
      " 0.31025741 0.         0.         0.         0.        ], Predicted Values: tensor([    0.0000,     0.1551,     0.8122,     0.0000,     0.0000,     0.0322,\n",
      "            0.0005,     0.0000,     0.0000,     0.0000,     0.0000],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 1., 0., 0., 1., 0., 1., 0., 0., 0.])\n",
      "tensor([[1., 0., 0., 1., 1., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1), Probabilities: [0.         0.43996323 0.43996323 0.         0.         0.09816907\n",
      " 0.         0.02190448 0.         0.         0.        ], Predicted Values: tensor([0.0000, 0.1541, 0.8068, 0.0000, 0.0000, 0.0320, 0.0000, 0.0071, 0.0000,\n",
      "        0.0000, 0.0000], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 1., 0., 0., 1., 0., 0., 1., 0., 0.])\n",
      "tensor([[1., 0., 0., 1., 1., 0., 1., 1., 0., 1., 1.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1), Probabilities: [0.         0.31025741 0.31025741 0.         0.         0.06922778\n",
      " 0.         0.         0.31025741 0.         0.        ], Predicted Values: tensor([0.0000, 0.1519, 0.7952, 0.0000, 0.0000, 0.0315, 0.0000, 0.0000, 0.0213,\n",
      "        0.0000, 0.0000], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 1., 0., 0., 1., 0., 0., 0., 1., 0.])\n",
      "tensor([[1., 0., 0., 1., 1., 0., 1., 1., 1., 0., 1.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1), Probabilities: [0.         0.31025741 0.31025741 0.         0.         0.06922778\n",
      " 0.         0.         0.         0.31025741 0.        ], Predicted Values: tensor([0.0000, 0.1550, 0.8114, 0.0000, 0.0000, 0.0322, 0.0000, 0.0000, 0.0000,\n",
      "        0.0014, 0.0000], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 1., 0., 0., 1., 0., 0., 0., 0., 1.])\n",
      "tensor([[1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 0.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0), Probabilities: [0.         0.31025741 0.31025741 0.         0.         0.06922778\n",
      " 0.         0.         0.         0.         0.31025741], Predicted Values: tensor([    0.0000,     0.1551,     0.8125,     0.0000,     0.0000,     0.0322,\n",
      "            0.0000,     0.0000,     0.0000,     0.0000,     0.0003],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 1., 0., 0., 0., 1., 1., 0., 0., 0.])\n",
      "tensor([[1., 0., 0., 1., 1., 1., 0., 0., 1., 1., 1.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1), Probabilities: [0.   0.25 0.25 0.   0.   0.   0.25 0.25 0.   0.   0.  ], Predicted Values: tensor([0.0000, 0.1575, 0.8267, 0.0000, 0.0000, 0.0000, 0.0086, 0.0073, 0.0000,\n",
      "        0.0000, 0.0000], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 1., 0., 0., 0., 1., 0., 1., 0., 0.])\n",
      "tensor([[1., 0., 0., 1., 1., 1., 0., 1., 0., 1., 1.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1), Probabilities: [0.         0.31025741 0.31025741 0.         0.         0.\n",
      " 0.31025741 0.         0.06922778 0.         0.        ], Predicted Values: tensor([0.0000, 0.1568, 0.8229, 0.0000, 0.0000, 0.0000, 0.0009, 0.0000, 0.0194,\n",
      "        0.0000, 0.0000], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 1., 0., 0., 0., 1., 0., 0., 1., 0.])\n",
      "tensor([[1., 0., 0., 1., 1., 1., 0., 1., 1., 0., 1.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1), Probabilities: [0.   0.25 0.25 0.   0.   0.   0.25 0.   0.   0.25 0.  ], Predicted Values: tensor([0.0000, 0.1598, 0.8384, 0.0000, 0.0000, 0.0000, 0.0009, 0.0000, 0.0000,\n",
      "        0.0010, 0.0000], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 1., 0., 0., 0., 1., 0., 0., 0., 1.])\n",
      "tensor([[1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 0.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0), Probabilities: [0.   0.25 0.25 0.   0.   0.   0.25 0.   0.   0.   0.25], Predicted Values: tensor([    0.0000,     0.1598,     0.8392,     0.0000,     0.0000,     0.0000,\n",
      "            0.0009,     0.0000,     0.0000,     0.0000,     0.0001],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 1., 0., 0., 0., 0., 1., 1., 0., 0.])\n",
      "tensor([[1., 0., 0., 1., 1., 1., 1., 0., 0., 1., 1.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1), Probabilities: [0.         0.31025741 0.31025741 0.         0.         0.\n",
      " 0.         0.31025741 0.06922778 0.         0.        ], Predicted Values: tensor([0.0000, 0.1585, 0.8317, 0.0000, 0.0000, 0.0000, 0.0000, 0.0074, 0.0024,\n",
      "        0.0000, 0.0000], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 0.])\n",
      "tensor([[1., 0., 0., 1., 1., 1., 1., 0., 1., 0., 1.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1), Probabilities: [0.   0.25 0.25 0.   0.   0.   0.   0.25 0.   0.25 0.  ], Predicted Values: tensor([0.0000, 0.1588, 0.8329, 0.0000, 0.0000, 0.0000, 0.0000, 0.0074, 0.0000,\n",
      "        0.0009, 0.0000], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 1., 0., 0., 0., 0., 1., 0., 0., 1.])\n",
      "tensor([[1., 0., 0., 1., 1., 1., 1., 0., 1., 1., 0.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0), Probabilities: [0.   0.25 0.25 0.   0.   0.   0.   0.25 0.   0.   0.25], Predicted Values: tensor([    0.0000,     0.1588,     0.8336,     0.0000,     0.0000,     0.0000,\n",
      "            0.0000,     0.0074,     0.0000,     0.0000,     0.0002],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 1., 0., 0., 0., 0., 0., 1., 1., 0.])\n",
      "tensor([[1., 0., 0., 1., 1., 1., 1., 1., 0., 0., 1.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1), Probabilities: [0.         0.32789174 0.32789174 0.         0.         0.\n",
      " 0.         0.         0.32789174 0.01632477 0.        ], Predicted Values: tensor([0.0000, 0.1565, 0.8207, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0219,\n",
      "        0.0009, 0.0000], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 1., 0., 0., 0., 0., 0., 1., 0., 1.])\n",
      "tensor([[1., 0., 0., 1., 1., 1., 1., 1., 0., 1., 0.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0), Probabilities: [0.   0.25 0.25 0.   0.   0.   0.   0.   0.25 0.   0.25], Predicted Values: tensor([    0.0000,     0.1565,     0.8214,     0.0000,     0.0000,     0.0000,\n",
      "            0.0000,     0.0000,     0.0220,     0.0000,     0.0001],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 1., 0., 0., 0., 0., 0., 0., 1., 1.])\n",
      "tensor([[1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 0.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0), Probabilities: [0.         0.32789174 0.32789174 0.         0.         0.\n",
      " 0.         0.         0.         0.32789174 0.01632477], Predicted Values: tensor([    0.0000,     0.1599,     0.8391,     0.0000,     0.0000,     0.0000,\n",
      "            0.0000,     0.0000,     0.0000,     0.0010,     0.0001],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 0., 1., 1., 1., 0., 0., 0., 0., 0.])\n",
      "tensor([[1., 0., 1., 0., 0., 0., 1., 1., 1., 1., 1.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1), Probabilities: [0.         0.40878724 0.         0.40878724 0.09121276 0.09121276\n",
      " 0.         0.         0.         0.         0.        ], Predicted Values: tensor([0.0000, 0.4035, 0.0000, 0.5771, 0.0095, 0.0098, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 0., 1., 1., 0., 1., 0., 0., 0., 0.])\n",
      "tensor([[1., 0., 1., 0., 0., 1., 0., 1., 1., 1., 1.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1), Probabilities: [0.         0.43996323 0.         0.43996323 0.09816907 0.\n",
      " 0.02190448 0.         0.         0.         0.        ], Predicted Values: tensor([0.0000, 0.4066, 0.0000, 0.5830, 0.0096, 0.0000, 0.0008, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 0., 1., 1., 0., 0., 1., 0., 0., 0.])\n",
      "tensor([[1., 0., 1., 0., 0., 1., 1., 0., 1., 1., 1.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1), Probabilities: [0.         0.31025741 0.         0.31025741 0.06922778 0.\n",
      " 0.         0.31025741 0.         0.         0.        ], Predicted Values: tensor([0.0000, 0.4059, 0.0000, 0.5812, 0.0096, 0.0000, 0.0000, 0.0033, 0.0000,\n",
      "        0.0000, 0.0000], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 0., 1., 1., 0., 0., 0., 1., 0., 0.])\n",
      "tensor([[1., 0., 1., 0., 0., 1., 1., 1., 0., 1., 1.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1), Probabilities: [0.         0.31025741 0.         0.31025741 0.06922778 0.\n",
      " 0.         0.         0.31025741 0.         0.        ], Predicted Values: tensor([0.0000, 0.4026, 0.0000, 0.5768, 0.0095, 0.0000, 0.0000, 0.0000, 0.0110,\n",
      "        0.0000, 0.0000], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 0., 1., 1., 0., 0., 0., 0., 1., 0.])\n",
      "tensor([[1., 0., 1., 0., 0., 1., 1., 1., 1., 0., 1.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1), Probabilities: [0.         0.31025741 0.         0.31025741 0.06922778 0.\n",
      " 0.         0.         0.         0.31025741 0.        ], Predicted Values: tensor([0.0000, 0.4067, 0.0000, 0.5821, 0.0096, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0015, 0.0000], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 0., 1., 1., 0., 0., 0., 0., 0., 1.])\n",
      "tensor([[1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 0.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0), Probabilities: [0.         0.31025741 0.         0.31025741 0.06922778 0.\n",
      " 0.         0.         0.         0.         0.31025741], Predicted Values: tensor([    0.0000,     0.4069,     0.0000,     0.5831,     0.0096,     0.0000,\n",
      "            0.0000,     0.0000,     0.0000,     0.0000,     0.0004],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 0., 1., 0., 1., 1., 0., 0., 0., 0.])\n",
      "tensor([[1., 0., 1., 0., 1., 0., 0., 1., 1., 1., 1.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1), Probabilities: [0.         0.31025741 0.         0.31025741 0.         0.06922778\n",
      " 0.31025741 0.         0.         0.         0.        ], Predicted Values: tensor([    0.0000,     0.4071,     0.0000,     0.5825,     0.0000,     0.0099,\n",
      "            0.0005,     0.0000,     0.0000,     0.0000,     0.0000],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 0., 1., 0., 1., 0., 1., 0., 0., 0.])\n",
      "tensor([[1., 0., 1., 0., 1., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1), Probabilities: [0.         0.43996323 0.         0.43996323 0.         0.09816907\n",
      " 0.         0.02190448 0.         0.         0.        ], Predicted Values: tensor([0.0000, 0.4048, 0.0000, 0.5785, 0.0000, 0.0098, 0.0000, 0.0069, 0.0000,\n",
      "        0.0000, 0.0000], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 0., 1., 0., 1., 0., 0., 1., 0., 0.])\n",
      "tensor([[1., 0., 1., 0., 1., 0., 1., 1., 0., 1., 1.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1), Probabilities: [0.         0.31025741 0.         0.31025741 0.         0.06922778\n",
      " 0.         0.         0.31025741 0.         0.        ], Predicted Values: tensor([0.0000, 0.4030, 0.0000, 0.5762, 0.0000, 0.0098, 0.0000, 0.0000, 0.0111,\n",
      "        0.0000, 0.0000], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 0., 1., 0., 1., 0., 0., 0., 1., 0.])\n",
      "tensor([[1., 0., 1., 0., 1., 0., 1., 1., 1., 0., 1.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1), Probabilities: [0.         0.31025741 0.         0.31025741 0.         0.06922778\n",
      " 0.         0.         0.         0.31025741 0.        ], Predicted Values: tensor([0.0000, 0.4068, 0.0000, 0.5811, 0.0000, 0.0099, 0.0000, 0.0000, 0.0000,\n",
      "        0.0022, 0.0000], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 0., 1., 0., 1., 0., 0., 0., 0., 1.])\n",
      "tensor([[1., 0., 1., 0., 1., 0., 1., 1., 1., 1., 0.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0), Probabilities: [0.         0.31025741 0.         0.31025741 0.         0.06922778\n",
      " 0.         0.         0.         0.         0.31025741], Predicted Values: tensor([    0.0000,     0.4073,     0.0000,     0.5824,     0.0000,     0.0099,\n",
      "            0.0000,     0.0000,     0.0000,     0.0000,     0.0004],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 0., 1., 0., 0., 1., 1., 0., 0., 0.])\n",
      "tensor([[1., 0., 1., 0., 1., 1., 0., 0., 1., 1., 1.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1), Probabilities: [0.   0.25 0.   0.25 0.   0.   0.25 0.25 0.   0.   0.  ], Predicted Values: tensor([0.0000, 0.4049, 0.0000, 0.5802, 0.0000, 0.0000, 0.0080, 0.0069, 0.0000,\n",
      "        0.0000, 0.0000], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 0., 1., 0., 0., 1., 0., 1., 0., 0.])\n",
      "tensor([[1., 0., 1., 0., 1., 1., 0., 1., 0., 1., 1.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1), Probabilities: [0.         0.31025741 0.         0.31025741 0.         0.\n",
      " 0.31025741 0.         0.06922778 0.         0.        ], Predicted Values: tensor([0.0000, 0.4065, 0.0000, 0.5828, 0.0000, 0.0000, 0.0008, 0.0000, 0.0099,\n",
      "        0.0000, 0.0000], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 0., 1., 0., 0., 1., 0., 0., 1., 0.])\n",
      "tensor([[1., 0., 1., 0., 1., 1., 0., 1., 1., 0., 1.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1), Probabilities: [0.   0.25 0.   0.25 0.   0.   0.25 0.   0.   0.25 0.  ], Predicted Values: tensor([0.0000, 0.4102, 0.0000, 0.5874, 0.0000, 0.0000, 0.0009, 0.0000, 0.0000,\n",
      "        0.0015, 0.0000], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 0., 1., 0., 0., 1., 0., 0., 0., 1.])\n",
      "tensor([[1., 0., 1., 0., 1., 1., 0., 1., 1., 1., 0.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0), Probabilities: [0.   0.25 0.   0.25 0.   0.   0.25 0.   0.   0.   0.25], Predicted Values: tensor([    0.0000,     0.4105,     0.0000,     0.5884,     0.0000,     0.0000,\n",
      "            0.0009,     0.0000,     0.0000,     0.0000,     0.0002],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 0., 1., 0., 0., 0., 1., 1., 0., 0.])\n",
      "tensor([[1., 0., 1., 0., 1., 1., 1., 0., 0., 1., 1.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1), Probabilities: [0.         0.31025741 0.         0.31025741 0.         0.\n",
      " 0.         0.31025741 0.06922778 0.         0.        ], Predicted Values: tensor([0.0000, 0.4079, 0.0000, 0.5839, 0.0000, 0.0000, 0.0000, 0.0070, 0.0012,\n",
      "        0.0000, 0.0000], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 0., 1., 0., 0., 0., 1., 0., 1., 0.])\n",
      "tensor([[1., 0., 1., 0., 1., 1., 1., 0., 1., 0., 1.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1), Probabilities: [0.   0.25 0.   0.25 0.   0.   0.   0.25 0.   0.25 0.  ], Predicted Values: tensor([0.0000, 0.4080, 0.0000, 0.5835, 0.0000, 0.0000, 0.0000, 0.0070, 0.0000,\n",
      "        0.0015, 0.0000], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 0., 1., 0., 0., 0., 1., 0., 0., 1.])\n",
      "tensor([[1., 0., 1., 0., 1., 1., 1., 0., 1., 1., 0.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0), Probabilities: [0.   0.25 0.   0.25 0.   0.   0.   0.25 0.   0.   0.25], Predicted Values: tensor([    0.0000,     0.4083,     0.0000,     0.5845,     0.0000,     0.0000,\n",
      "            0.0000,     0.0070,     0.0000,     0.0000,     0.0003],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 0., 1., 0., 0., 0., 0., 1., 1., 0.])\n",
      "tensor([[1., 0., 1., 0., 1., 1., 1., 1., 0., 0., 1.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1), Probabilities: [0.         0.32789174 0.         0.32789174 0.         0.\n",
      " 0.         0.         0.32789174 0.01632477 0.        ], Predicted Values: tensor([0.0000, 0.4062, 0.0000, 0.5812, 0.0000, 0.0000, 0.0000, 0.0000, 0.0112,\n",
      "        0.0015, 0.0000], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 0., 1., 0., 0., 0., 0., 1., 0., 1.])\n",
      "tensor([[1., 0., 1., 0., 1., 1., 1., 1., 0., 1., 0.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0), Probabilities: [0.   0.25 0.   0.25 0.   0.   0.   0.   0.25 0.   0.25], Predicted Values: tensor([    0.0000,     0.4064,     0.0000,     0.5822,     0.0000,     0.0000,\n",
      "            0.0000,     0.0000,     0.0112,     0.0000,     0.0002],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 0., 1., 0., 0., 0., 0., 0., 1., 1.])\n",
      "tensor([[1., 0., 1., 0., 1., 1., 1., 1., 1., 0., 0.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0), Probabilities: [0.         0.32789174 0.         0.32789174 0.         0.\n",
      " 0.         0.         0.         0.32789174 0.01632477], Predicted Values: tensor([    0.0000,     0.4107,     0.0000,     0.5876,     0.0000,     0.0000,\n",
      "            0.0000,     0.0000,     0.0000,     0.0015,     0.0002],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 0., 0., 1., 1., 1., 0., 0., 0., 0.])\n",
      "tensor([[1., 0., 1., 1., 0., 0., 0., 1., 1., 1., 1.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1), Probabilities: [0.         0.43996323 0.         0.         0.09816907 0.43996323\n",
      " 0.02190448 0.         0.         0.         0.        ], Predicted Values: tensor([0.0000, 0.9164, 0.0000, 0.0000, 0.0183, 0.0643, 0.0010, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 0., 0., 1., 1., 0., 1., 0., 0., 0.])\n",
      "tensor([[1., 0., 1., 1., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1), Probabilities: [0.         0.43996323 0.         0.         0.09816907 0.43996323\n",
      " 0.         0.02190448 0.         0.         0.        ], Predicted Values: tensor([0.0000, 0.9115, 0.0000, 0.0000, 0.0182, 0.0640, 0.0000, 0.0063, 0.0000,\n",
      "        0.0000, 0.0000], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 0., 0., 1., 1., 0., 0., 1., 0., 0.])\n",
      "tensor([[1., 0., 1., 1., 0., 0., 1., 1., 0., 1., 1.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1), Probabilities: [0.         0.31025741 0.         0.         0.06922778 0.31025741\n",
      " 0.         0.         0.31025741 0.         0.        ], Predicted Values: tensor([0.0000, 0.9058, 0.0000, 0.0000, 0.0181, 0.0636, 0.0000, 0.0000, 0.0125,\n",
      "        0.0000, 0.0000], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 0., 0., 1., 1., 0., 0., 0., 1., 0.])\n",
      "tensor([[1., 0., 1., 1., 0., 0., 1., 1., 1., 0., 1.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1), Probabilities: [0.         0.31025741 0.         0.         0.06922778 0.31025741\n",
      " 0.         0.         0.         0.31025741 0.        ], Predicted Values: tensor([0.0000, 0.9164, 0.0000, 0.0000, 0.0183, 0.0644, 0.0000, 0.0000, 0.0000,\n",
      "        0.0009, 0.0000], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 0., 0., 1., 1., 0., 0., 0., 0., 1.])\n",
      "tensor([[1., 0., 1., 1., 0., 0., 1., 1., 1., 1., 0.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0), Probabilities: [0.         0.31025741 0.         0.         0.06922778 0.31025741\n",
      " 0.         0.         0.         0.         0.31025741], Predicted Values: tensor([    0.0000,     0.9170,     0.0000,     0.0000,     0.0184,     0.0644,\n",
      "            0.0000,     0.0000,     0.0000,     0.0000,     0.0003],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 0., 0., 1., 0., 1., 1., 0., 0., 0.])\n",
      "tensor([[1., 0., 1., 1., 0., 1., 0., 0., 1., 1., 1.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1), Probabilities: [0.         0.43996323 0.         0.         0.09816907 0.\n",
      " 0.02190448 0.43996323 0.         0.         0.        ], Predicted Values: tensor([0.0000, 0.9582, 0.0000, 0.0000, 0.0191, 0.0000, 0.0161, 0.0066, 0.0000,\n",
      "        0.0000, 0.0000], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 0., 0., 1., 0., 1., 0., 1., 0., 0.])\n",
      "tensor([[1., 0., 1., 1., 0., 1., 0., 1., 0., 1., 1.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1), Probabilities: [0.         0.66842802 0.         0.         0.14914645 0.\n",
      " 0.03327907 0.         0.14914645 0.         0.        ], Predicted Values: tensor([0.0000, 0.9672, 0.0000, 0.0000, 0.0193, 0.0000, 0.0017, 0.0000, 0.0117,\n",
      "        0.0000, 0.0000], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 0., 0., 1., 0., 1., 0., 0., 1., 0.])\n",
      "tensor([[1., 0., 1., 1., 0., 1., 0., 1., 1., 0., 1.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1), Probabilities: [0.         0.43996323 0.         0.         0.09816907 0.\n",
      " 0.02190448 0.         0.         0.43996323 0.        ], Predicted Values: tensor([    0.0000,     0.9781,     0.0000,     0.0000,     0.0195,     0.0000,\n",
      "            0.0017,     0.0000,     0.0000,     0.0007,     0.0000],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 0., 0., 1., 0., 1., 0., 0., 0., 1.])\n",
      "tensor([[1., 0., 1., 1., 0., 1., 0., 1., 1., 1., 0.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0), Probabilities: [0.         0.43996323 0.         0.         0.09816907 0.\n",
      " 0.02190448 0.         0.         0.         0.43996323], Predicted Values: tensor([    0.0000,     0.9786,     0.0000,     0.0000,     0.0196,     0.0000,\n",
      "            0.0017,     0.0000,     0.0000,     0.0000,     0.0002],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 0., 0., 1., 0., 0., 1., 1., 0., 0.])\n",
      "tensor([[1., 0., 1., 1., 0., 1., 1., 0., 0., 1., 1.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1), Probabilities: [0.         0.40878724 0.         0.         0.09121276 0.\n",
      " 0.         0.40878724 0.09121276 0.         0.        ], Predicted Values: tensor([0.0000, 0.9724, 0.0000, 0.0000, 0.0194, 0.0000, 0.0000, 0.0067, 0.0015,\n",
      "        0.0000, 0.0000], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 0., 0., 1., 0., 0., 1., 0., 1., 0.])\n",
      "tensor([[1., 0., 1., 1., 0., 1., 1., 0., 1., 0., 1.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1), Probabilities: [0.         0.31025741 0.         0.         0.06922778 0.\n",
      " 0.         0.31025741 0.         0.31025741 0.        ], Predicted Values: tensor([    0.0000,     0.9732,     0.0000,     0.0000,     0.0194,     0.0000,\n",
      "            0.0000,     0.0067,     0.0000,     0.0007,     0.0000],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 0., 0., 1., 0., 0., 1., 0., 0., 1.])\n",
      "tensor([[1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 0.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0), Probabilities: [0.         0.31025741 0.         0.         0.06922778 0.\n",
      " 0.         0.31025741 0.         0.         0.31025741], Predicted Values: tensor([    0.0000,     0.9736,     0.0000,     0.0000,     0.0195,     0.0000,\n",
      "            0.0000,     0.0067,     0.0000,     0.0000,     0.0002],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 0., 0., 1., 0., 0., 0., 1., 1., 0.])\n",
      "tensor([[1., 0., 1., 1., 0., 1., 1., 1., 0., 0., 1.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1), Probabilities: [0.         0.43996323 0.         0.         0.09816907 0.\n",
      " 0.         0.         0.43996323 0.02190448 0.        ], Predicted Values: tensor([    0.0000,     0.9667,     0.0000,     0.0000,     0.0193,     0.0000,\n",
      "            0.0000,     0.0000,     0.0133,     0.0007,     0.0000],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 0., 0., 1., 0., 0., 0., 1., 0., 1.])\n",
      "tensor([[1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 0.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0), Probabilities: [0.         0.31025741 0.         0.         0.06922778 0.\n",
      " 0.         0.         0.31025741 0.         0.31025741], Predicted Values: tensor([    0.0000,     0.9671,     0.0000,     0.0000,     0.0194,     0.0000,\n",
      "            0.0000,     0.0000,     0.0134,     0.0000,     0.0001],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 0., 0., 1., 0., 0., 0., 0., 1., 1.])\n",
      "tensor([[1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 0.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0), Probabilities: [0.         0.43996323 0.         0.         0.09816907 0.\n",
      " 0.         0.         0.         0.43996323 0.02190448], Predicted Values: tensor([    0.0000,     0.9796,     0.0000,     0.0000,     0.0196,     0.0000,\n",
      "            0.0000,     0.0000,     0.0000,     0.0007,     0.0001],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 0., 0., 0., 1., 1., 1., 0., 0., 0.])\n",
      "tensor([[1., 0., 1., 1., 1., 0., 0., 0., 1., 1., 1.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1), Probabilities: [0.         0.32789174 0.         0.         0.         0.32789174\n",
      " 0.32789174 0.01632477 0.         0.         0.        ], Predicted Values: tensor([0.0000, 0.9136, 0.0000, 0.0000, 0.0000, 0.0640, 0.0094, 0.0129, 0.0000,\n",
      "        0.0000, 0.0000], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 0., 0., 0., 1., 1., 0., 1., 0., 0.])\n",
      "tensor([[1., 0., 1., 1., 1., 0., 0., 1., 0., 1., 1.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1), Probabilities: [0.         0.31025741 0.         0.         0.         0.31025741\n",
      " 0.31025741 0.         0.06922778 0.         0.        ], Predicted Values: tensor([0.0000, 0.9231, 0.0000, 0.0000, 0.0000, 0.0647, 0.0010, 0.0000, 0.0112,\n",
      "        0.0000, 0.0000], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 0., 0., 0., 1., 1., 0., 0., 1., 0.])\n",
      "tensor([[1., 0., 1., 1., 1., 0., 0., 1., 1., 0., 1.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1), Probabilities: [0.   0.25 0.   0.   0.   0.25 0.25 0.   0.   0.25 0.  ], Predicted Values: tensor([0.0000, 0.9327, 0.0000, 0.0000, 0.0000, 0.0653, 0.0010, 0.0000, 0.0000,\n",
      "        0.0009, 0.0000], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 0., 0., 0., 1., 1., 0., 0., 0., 1.])\n",
      "tensor([[1., 0., 1., 1., 1., 0., 0., 1., 1., 1., 0.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0), Probabilities: [0.   0.25 0.   0.   0.   0.25 0.25 0.   0.   0.   0.25], Predicted Values: tensor([    0.0000,     0.9335,     0.0000,     0.0000,     0.0000,     0.0654,\n",
      "            0.0010,     0.0000,     0.0000,     0.0000,     0.0002],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 0., 0., 0., 1., 0., 1., 1., 0., 0.])\n",
      "tensor([[1., 0., 1., 1., 1., 0., 1., 0., 0., 1., 1.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1), Probabilities: [0.         0.43996323 0.         0.         0.         0.43996323\n",
      " 0.         0.02190448 0.09816907 0.         0.        ], Predicted Values: tensor([0.0000, 0.9209, 0.0000, 0.0000, 0.0000, 0.0645, 0.0000, 0.0131, 0.0014,\n",
      "        0.0000, 0.0000], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 0., 0., 0., 1., 0., 1., 0., 1., 0.])\n",
      "tensor([[1., 0., 1., 1., 1., 0., 1., 0., 1., 0., 1.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1), Probabilities: [0.         0.32789174 0.         0.         0.         0.32789174\n",
      " 0.         0.01632477 0.         0.32789174 0.        ], Predicted Values: tensor([0.0000, 0.9214, 0.0000, 0.0000, 0.0000, 0.0646, 0.0000, 0.0131, 0.0000,\n",
      "        0.0009, 0.0000], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 0., 0., 0., 1., 0., 1., 0., 0., 1.])\n",
      "tensor([[1., 0., 1., 1., 1., 0., 1., 0., 1., 1., 0.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0), Probabilities: [0.         0.32789174 0.         0.         0.         0.32789174\n",
      " 0.         0.01632477 0.         0.         0.32789174], Predicted Values: tensor([    0.0000,     0.9220,     0.0000,     0.0000,     0.0000,     0.0646,\n",
      "            0.0000,     0.0132,     0.0000,     0.0000,     0.0002],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 0., 0., 0., 1., 0., 0., 1., 1., 0.])\n",
      "tensor([[1., 0., 1., 1., 1., 0., 1., 1., 0., 0., 1.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1), Probabilities: [0.         0.32789174 0.         0.         0.         0.32789174\n",
      " 0.         0.         0.32789174 0.01632477 0.        ], Predicted Values: tensor([0.0000, 0.9217, 0.0000, 0.0000, 0.0000, 0.0646, 0.0000, 0.0000, 0.0127,\n",
      "        0.0009, 0.0000], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 0., 0., 0., 1., 0., 0., 1., 0., 1.])\n",
      "tensor([[1., 0., 1., 1., 1., 0., 1., 1., 0., 1., 0.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0), Probabilities: [0.   0.25 0.   0.   0.   0.25 0.   0.   0.25 0.   0.25], Predicted Values: tensor([    0.0000,     0.9224,     0.0000,     0.0000,     0.0000,     0.0646,\n",
      "            0.0000,     0.0000,     0.0128,     0.0000,     0.0002],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 0., 0., 0., 1., 0., 0., 0., 1., 1.])\n",
      "tensor([[1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 0.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0), Probabilities: [0.         0.32789174 0.         0.         0.         0.32789174\n",
      " 0.         0.         0.         0.32789174 0.01632477], Predicted Values: tensor([    0.0000,     0.9335,     0.0000,     0.0000,     0.0000,     0.0654,\n",
      "            0.0000,     0.0000,     0.0000,     0.0009,     0.0002],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 0., 0., 0., 0., 1., 1., 1., 0., 0.])\n",
      "tensor([[1., 0., 1., 1., 1., 1., 0., 0., 0., 1., 1.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1), Probabilities: [0.         0.32789174 0.         0.         0.         0.\n",
      " 0.32789174 0.32789174 0.01632477 0.         0.        ], Predicted Values: tensor([0.0000, 0.9686, 0.0000, 0.0000, 0.0000, 0.0000, 0.0163, 0.0138, 0.0013,\n",
      "        0.0000, 0.0000], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 0., 0., 0., 0., 1., 1., 0., 1., 0.])\n",
      "tensor([[1., 0., 1., 1., 1., 1., 0., 0., 1., 0., 1.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1), Probabilities: [0.   0.25 0.   0.   0.   0.   0.25 0.25 0.   0.25 0.  ], Predicted Values: tensor([    0.0000,     0.9693,     0.0000,     0.0000,     0.0000,     0.0000,\n",
      "            0.0163,     0.0138,     0.0000,     0.0007,     0.0000],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 0., 0., 0., 0., 1., 1., 0., 0., 1.])\n",
      "tensor([[1., 0., 1., 1., 1., 1., 0., 0., 1., 1., 0.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0), Probabilities: [0.   0.25 0.   0.   0.   0.   0.25 0.25 0.   0.   0.25], Predicted Values: tensor([    0.0000,     0.9698,     0.0000,     0.0000,     0.0000,     0.0000,\n",
      "            0.0163,     0.0138,     0.0000,     0.0000,     0.0001],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 0., 0., 0., 0., 1., 0., 1., 1., 0.])\n",
      "tensor([[1., 0., 1., 1., 1., 1., 0., 1., 0., 0., 1.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1), Probabilities: [0.         0.43996323 0.         0.         0.         0.\n",
      " 0.43996323 0.         0.09816907 0.02190448 0.        ], Predicted Values: tensor([    0.0000,     0.9856,     0.0000,     0.0000,     0.0000,     0.0000,\n",
      "            0.0017,     0.0000,     0.0120,     0.0007,     0.0000],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 0., 0., 0., 0., 1., 0., 1., 0., 1.])\n",
      "tensor([[1., 0., 1., 1., 1., 1., 0., 1., 0., 1., 0.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0), Probabilities: [0.         0.31025741 0.         0.         0.         0.\n",
      " 0.31025741 0.         0.06922778 0.         0.31025741], Predicted Values: tensor([    0.0000,     0.9861,     0.0000,     0.0000,     0.0000,     0.0000,\n",
      "            0.0017,     0.0000,     0.0120,     0.0000,     0.0001],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 0., 0., 0., 0., 1., 0., 0., 1., 1.])\n",
      "tensor([[1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 0.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0), Probabilities: [0.         0.32789174 0.         0.         0.         0.\n",
      " 0.32789174 0.         0.         0.32789174 0.01632477], Predicted Values: tensor([    0.0000,     0.9975,     0.0000,     0.0000,     0.0000,     0.0000,\n",
      "            0.0018,     0.0000,     0.0000,     0.0007,     0.0001],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 0., 0., 0., 0., 0., 1., 1., 1., 0.])\n",
      "tensor([[1., 0., 1., 1., 1., 1., 1., 0., 0., 0., 1.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1), Probabilities: [0.         0.43996323 0.         0.         0.         0.\n",
      " 0.         0.43996323 0.09816907 0.02190448 0.        ], Predicted Values: tensor([    0.0000,     0.9837,     0.0000,     0.0000,     0.0000,     0.0000,\n",
      "            0.0000,     0.0141,     0.0015,     0.0007,     0.0000],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 0., 0., 0., 0., 0., 1., 1., 0., 1.])\n",
      "tensor([[1., 0., 1., 1., 1., 1., 1., 0., 0., 1., 0.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0), Probabilities: [0.         0.31025741 0.         0.         0.         0.\n",
      " 0.         0.31025741 0.06922778 0.         0.31025741], Predicted Values: tensor([    0.0000,     0.9842,     0.0000,     0.0000,     0.0000,     0.0000,\n",
      "            0.0000,     0.0142,     0.0015,     0.0000,     0.0001],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 0., 0., 0., 0., 0., 1., 0., 1., 1.])\n",
      "tensor([[1., 0., 1., 1., 1., 1., 1., 0., 1., 0., 0.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0), Probabilities: [0.         0.32789174 0.         0.         0.         0.\n",
      " 0.         0.32789174 0.         0.32789174 0.01632477], Predicted Values: tensor([    0.0000,     0.9850,     0.0000,     0.0000,     0.0000,     0.0000,\n",
      "            0.0000,     0.0142,     0.0000,     0.0007,     0.0001],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 0., 0., 0., 0., 0., 0., 1., 1., 1.])\n",
      "tensor([[1., 0., 1., 1., 1., 1., 1., 1., 0., 0., 0.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0), Probabilities: [0.         0.47628706 0.         0.         0.         0.\n",
      " 0.         0.         0.47628706 0.02371294 0.02371294], Predicted Values: tensor([    0.0000,     0.9856,     0.0000,     0.0000,     0.0000,     0.0000,\n",
      "            0.0000,     0.0000,     0.0136,     0.0007,     0.0001],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 1., 1., 1., 1., 0., 0., 0., 0., 0.])\n",
      "tensor([[1., 1., 0., 0., 0., 0., 1., 1., 1., 1., 1.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1), Probabilities: [0.         0.         0.43996323 0.43996323 0.09816907 0.02190448\n",
      " 0.         0.         0.         0.         0.        ], Predicted Values: tensor([0.0000, 0.0000, 0.4643, 0.5138, 0.0081, 0.0138, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 1., 1., 1., 0., 1., 0., 0., 0., 0.])\n",
      "tensor([[1., 1., 0., 0., 0., 1., 0., 1., 1., 1., 1.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1), Probabilities: [0.         0.         0.43996323 0.43996323 0.09816907 0.\n",
      " 0.02190448 0.         0.         0.         0.        ], Predicted Values: tensor([0.0000, 0.0000, 0.4704, 0.5207, 0.0082, 0.0000, 0.0007, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 1., 1., 1., 0., 0., 1., 0., 0., 0.])\n",
      "tensor([[1., 1., 0., 0., 0., 1., 1., 0., 1., 1., 1.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1), Probabilities: [0.         0.         0.31025741 0.31025741 0.06922778 0.\n",
      " 0.         0.31025741 0.         0.         0.        ], Predicted Values: tensor([0.0000, 0.0000, 0.4697, 0.5193, 0.0082, 0.0000, 0.0000, 0.0028, 0.0000,\n",
      "        0.0000, 0.0000], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 1., 1., 1., 0., 0., 0., 1., 0., 0.])\n",
      "tensor([[1., 1., 0., 0., 0., 1., 1., 1., 0., 1., 1.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1), Probabilities: [0.         0.         0.31025741 0.31025741 0.06922778 0.\n",
      " 0.         0.         0.31025741 0.         0.        ], Predicted Values: tensor([0.0000, 0.0000, 0.4602, 0.5092, 0.0080, 0.0000, 0.0000, 0.0000, 0.0226,\n",
      "        0.0000, 0.0000], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 1., 1., 1., 0., 0., 0., 0., 1., 0.])\n",
      "tensor([[1., 1., 0., 0., 0., 1., 1., 1., 1., 0., 1.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1), Probabilities: [0.         0.         0.31025741 0.31025741 0.06922778 0.\n",
      " 0.         0.         0.         0.31025741 0.        ], Predicted Values: tensor([0.0000, 0.0000, 0.4705, 0.5201, 0.0082, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0012, 0.0000], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 1., 1., 1., 0., 0., 0., 0., 0., 1.])\n",
      "tensor([[1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 0.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0), Probabilities: [0.         0.         0.31025741 0.31025741 0.06922778 0.\n",
      " 0.         0.         0.         0.         0.31025741], Predicted Values: tensor([    0.0000,     0.0000,     0.4708,     0.5206,     0.0082,     0.0000,\n",
      "            0.0000,     0.0000,     0.0000,     0.0000,     0.0004],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 1., 1., 0., 1., 1., 0., 0., 0., 0.])\n",
      "tensor([[1., 1., 0., 0., 1., 0., 0., 1., 1., 1., 1.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1), Probabilities: [0.         0.         0.32789174 0.32789174 0.         0.01632477\n",
      " 0.32789174 0.         0.         0.         0.        ], Predicted Values: tensor([    0.0000,     0.0000,     0.4677,     0.5180,     0.0000,     0.0138,\n",
      "            0.0004,     0.0000,     0.0000,     0.0000,     0.0000],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 1., 1., 0., 1., 0., 1., 0., 0., 0.])\n",
      "tensor([[1., 1., 0., 0., 1., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1), Probabilities: [0.         0.         0.47628706 0.47628706 0.         0.02371294\n",
      " 0.         0.02371294 0.         0.         0.        ], Predicted Values: tensor([0.0000, 0.0000, 0.4655, 0.5150, 0.0000, 0.0138, 0.0000, 0.0058, 0.0000,\n",
      "        0.0000, 0.0000], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 1., 1., 0., 1., 0., 0., 1., 0., 0.])\n",
      "tensor([[1., 1., 0., 0., 1., 0., 1., 1., 0., 1., 1.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1), Probabilities: [0.         0.         0.32789174 0.32789174 0.         0.01632477\n",
      " 0.         0.         0.32789174 0.         0.        ], Predicted Values: tensor([0.0000, 0.0000, 0.4574, 0.5065, 0.0000, 0.0135, 0.0000, 0.0000, 0.0226,\n",
      "        0.0000, 0.0000], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 1., 1., 0., 1., 0., 0., 0., 1., 0.])\n",
      "tensor([[1., 1., 0., 0., 1., 0., 1., 1., 1., 0., 1.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1), Probabilities: [0.         0.         0.32789174 0.32789174 0.         0.01632477\n",
      " 0.         0.         0.         0.32789174 0.        ], Predicted Values: tensor([0.0000, 0.0000, 0.4674, 0.5171, 0.0000, 0.0138, 0.0000, 0.0000, 0.0000,\n",
      "        0.0017, 0.0000], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 1., 1., 0., 1., 0., 0., 0., 0., 1.])\n",
      "tensor([[1., 1., 0., 0., 1., 0., 1., 1., 1., 1., 0.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0), Probabilities: [0.         0.         0.32789174 0.32789174 0.         0.01632477\n",
      " 0.         0.         0.         0.         0.32789174], Predicted Values: tensor([    0.0000,     0.0000,     0.4680,     0.5178,     0.0000,     0.0138,\n",
      "            0.0000,     0.0000,     0.0000,     0.0000,     0.0004],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 1., 1., 0., 0., 1., 1., 0., 0., 0.])\n",
      "tensor([[1., 1., 0., 0., 1., 1., 0., 0., 1., 1., 1.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1), Probabilities: [0.   0.   0.25 0.25 0.   0.   0.25 0.25 0.   0.   0.  ], Predicted Values: tensor([0.0000, 0.0000, 0.4687, 0.5186, 0.0000, 0.0000, 0.0069, 0.0058, 0.0000,\n",
      "        0.0000, 0.0000], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 1., 1., 0., 0., 1., 0., 1., 0., 0.])\n",
      "tensor([[1., 1., 0., 0., 1., 1., 0., 1., 0., 1., 1.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1), Probabilities: [0.         0.         0.31025741 0.31025741 0.         0.\n",
      " 0.31025741 0.         0.06922778 0.         0.        ], Predicted Values: tensor([0.0000, 0.0000, 0.4646, 0.5146, 0.0000, 0.0000, 0.0007, 0.0000, 0.0202,\n",
      "        0.0000, 0.0000], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 1., 1., 0., 0., 1., 0., 0., 1., 0.])\n",
      "tensor([[1., 1., 0., 0., 1., 1., 0., 1., 1., 0., 1.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1), Probabilities: [0.   0.   0.25 0.25 0.   0.   0.25 0.   0.   0.25 0.  ], Predicted Values: tensor([0.0000, 0.0000, 0.4738, 0.5242, 0.0000, 0.0000, 0.0007, 0.0000, 0.0000,\n",
      "        0.0012, 0.0000], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 1., 1., 0., 0., 1., 0., 0., 0., 1.])\n",
      "tensor([[1., 1., 0., 0., 1., 1., 0., 1., 1., 1., 0.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0), Probabilities: [0.   0.   0.25 0.25 0.   0.   0.25 0.   0.   0.   0.25], Predicted Values: tensor([    0.0000,     0.0000,     0.4742,     0.5248,     0.0000,     0.0000,\n",
      "            0.0007,     0.0000,     0.0000,     0.0000,     0.0002],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 1., 1., 0., 0., 0., 1., 1., 0., 0.])\n",
      "tensor([[1., 1., 0., 0., 1., 1., 1., 0., 0., 1., 1.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1), Probabilities: [0.         0.         0.31025741 0.31025741 0.         0.\n",
      " 0.         0.31025741 0.06922778 0.         0.        ], Predicted Values: tensor([0.0000, 0.0000, 0.4708, 0.5208, 0.0000, 0.0000, 0.0000, 0.0059, 0.0025,\n",
      "        0.0000, 0.0000], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 1., 1., 0., 0., 0., 1., 0., 1., 0.])\n",
      "tensor([[1., 1., 0., 0., 1., 1., 1., 0., 1., 0., 1.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1), Probabilities: [0.   0.   0.25 0.25 0.   0.   0.   0.25 0.   0.25 0.  ], Predicted Values: tensor([0.0000, 0.0000, 0.4717, 0.5212, 0.0000, 0.0000, 0.0000, 0.0059, 0.0000,\n",
      "        0.0012, 0.0000], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 1., 1., 0., 0., 0., 1., 0., 0., 1.])\n",
      "tensor([[1., 1., 0., 0., 1., 1., 1., 0., 1., 1., 0.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0), Probabilities: [0.   0.   0.25 0.25 0.   0.   0.   0.25 0.   0.   0.25], Predicted Values: tensor([    0.0000,     0.0000,     0.4720,     0.5217,     0.0000,     0.0000,\n",
      "            0.0000,     0.0059,     0.0000,     0.0000,     0.0003],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 1., 1., 0., 0., 0., 0., 1., 1., 0.])\n",
      "tensor([[1., 1., 0., 0., 1., 1., 1., 1., 0., 0., 1.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1), Probabilities: [0.         0.         0.32789174 0.32789174 0.         0.\n",
      " 0.         0.         0.32789174 0.01632477 0.        ], Predicted Values: tensor([0.0000, 0.0000, 0.4634, 0.5126, 0.0000, 0.0000, 0.0000, 0.0000, 0.0228,\n",
      "        0.0012, 0.0000], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 1., 1., 0., 0., 0., 0., 1., 0., 1.])\n",
      "tensor([[1., 1., 0., 0., 1., 1., 1., 1., 0., 1., 0.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0), Probabilities: [0.   0.   0.25 0.25 0.   0.   0.   0.   0.25 0.   0.25], Predicted Values: tensor([    0.0000,     0.0000,     0.4638,     0.5131,     0.0000,     0.0000,\n",
      "            0.0000,     0.0000,     0.0229,     0.0000,     0.0002],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 1., 1., 0., 0., 0., 0., 0., 1., 1.])\n",
      "tensor([[1., 1., 0., 0., 1., 1., 1., 1., 1., 0., 0.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0), Probabilities: [0.         0.         0.32789174 0.32789174 0.         0.\n",
      " 0.         0.         0.         0.32789174 0.01632477], Predicted Values: tensor([    0.0000,     0.0000,     0.4744,     0.5243,     0.0000,     0.0000,\n",
      "            0.0000,     0.0000,     0.0000,     0.0012,     0.0002],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 1., 0., 1., 1., 1., 0., 0., 0., 0.])\n",
      "tensor([[1., 1., 0., 1., 0., 0., 0., 1., 1., 1., 1.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1), Probabilities: [0.         0.         0.66842802 0.         0.14914645 0.14914645\n",
      " 0.03327907 0.         0.         0.         0.        ], Predicted Values: tensor([    0.0000,     0.0000,     0.9523,     0.0000,     0.0070,     0.0404,\n",
      "            0.0004,     0.0000,     0.0000,     0.0000,     0.0000],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 1., 0., 1., 1., 0., 1., 0., 0., 0.])\n",
      "tensor([[1., 1., 0., 1., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1), Probabilities: [0.         0.         0.66842802 0.         0.14914645 0.14914645\n",
      " 0.         0.03327907 0.         0.         0.        ], Predicted Values: tensor([0.0000, 0.0000, 0.9503, 0.0000, 0.0070, 0.0403, 0.0000, 0.0024, 0.0000,\n",
      "        0.0000, 0.0000], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 1., 0., 1., 1., 0., 0., 1., 0., 0.])\n",
      "tensor([[1., 1., 0., 1., 0., 0., 1., 1., 0., 1., 1.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1), Probabilities: [0.         0.         0.40878724 0.         0.09121276 0.09121276\n",
      " 0.         0.         0.40878724 0.         0.        ], Predicted Values: tensor([0.0000, 0.0000, 0.9416, 0.0000, 0.0069, 0.0400, 0.0000, 0.0000, 0.0115,\n",
      "        0.0000, 0.0000], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 1., 0., 1., 1., 0., 0., 0., 1., 0.])\n",
      "tensor([[1., 1., 0., 1., 0., 0., 1., 1., 1., 0., 1.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1), Probabilities: [0.         0.         0.40878724 0.         0.09121276 0.09121276\n",
      " 0.         0.         0.         0.40878724 0.        ], Predicted Values: tensor([    0.0000,     0.0000,     0.9523,     0.0000,     0.0070,     0.0404,\n",
      "            0.0000,     0.0000,     0.0000,     0.0003,     0.0000],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 1., 0., 1., 1., 0., 0., 0., 0., 1.])\n",
      "tensor([[1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 0.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0), Probabilities: [0.         0.         0.40878724 0.         0.09121276 0.09121276\n",
      " 0.         0.         0.         0.         0.40878724], Predicted Values: tensor([    0.0000,     0.0000,     0.9525,     0.0000,     0.0070,     0.0404,\n",
      "            0.0000,     0.0000,     0.0000,     0.0000,     0.0001],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 1., 0., 1., 0., 1., 1., 0., 0., 0.])\n",
      "tensor([[1., 1., 0., 1., 0., 1., 0., 0., 1., 1., 1.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1), Probabilities: [0.         0.         0.43996323 0.         0.09816907 0.\n",
      " 0.02190448 0.43996323 0.         0.         0.        ], Predicted Values: tensor([0.0000, 0.0000, 0.9843, 0.0000, 0.0072, 0.0000, 0.0061, 0.0025, 0.0000,\n",
      "        0.0000, 0.0000], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 1., 0., 1., 0., 1., 0., 1., 0., 0.])\n",
      "tensor([[1., 1., 0., 1., 0., 1., 0., 1., 0., 1., 1.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1), Probabilities: [0.         0.         0.66842802 0.         0.14914645 0.\n",
      " 0.03327907 0.         0.14914645 0.         0.        ], Predicted Values: tensor([    0.0000,     0.0000,     0.9816,     0.0000,     0.0072,     0.0000,\n",
      "            0.0006,     0.0000,     0.0106,     0.0000,     0.0000],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 1., 0., 1., 0., 1., 0., 0., 1., 0.])\n",
      "tensor([[1., 1., 0., 1., 0., 1., 0., 1., 1., 0., 1.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1), Probabilities: [0.         0.         0.43996323 0.         0.09816907 0.\n",
      " 0.02190448 0.         0.         0.43996323 0.        ], Predicted Values: tensor([    0.0000,     0.0000,     0.9919,     0.0000,     0.0072,     0.0000,\n",
      "            0.0006,     0.0000,     0.0000,     0.0002,     0.0000],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 1., 0., 1., 0., 1., 0., 0., 0., 1.])\n",
      "tensor([[1., 1., 0., 1., 0., 1., 0., 1., 1., 1., 0.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0), Probabilities: [0.         0.         0.43996323 0.         0.09816907 0.\n",
      " 0.02190448 0.         0.         0.         0.43996323], Predicted Values: tensor([    0.0000,     0.0000,     0.9921,     0.0000,     0.0072,     0.0000,\n",
      "            0.0006,     0.0000,     0.0000,     0.0000,     0.0001],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 1., 0., 1., 0., 0., 1., 1., 0., 0.])\n",
      "tensor([[1., 1., 0., 1., 0., 1., 1., 0., 0., 1., 1.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1), Probabilities: [0.         0.         0.40878724 0.         0.09121276 0.\n",
      " 0.         0.40878724 0.09121276 0.         0.        ], Predicted Values: tensor([0.0000, 0.0000, 0.9890, 0.0000, 0.0072, 0.0000, 0.0000, 0.0025, 0.0013,\n",
      "        0.0000, 0.0000], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 1., 0., 1., 0., 0., 1., 0., 1., 0.])\n",
      "tensor([[1., 1., 0., 1., 0., 1., 1., 0., 1., 0., 1.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1), Probabilities: [0.         0.         0.31025741 0.         0.06922778 0.\n",
      " 0.         0.31025741 0.         0.31025741 0.        ], Predicted Values: tensor([    0.0000,     0.0000,     0.9901,     0.0000,     0.0072,     0.0000,\n",
      "            0.0000,     0.0025,     0.0000,     0.0002,     0.0000],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 1., 0., 1., 0., 0., 1., 0., 0., 1.])\n",
      "tensor([[1., 1., 0., 1., 0., 1., 1., 0., 1., 1., 0.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0), Probabilities: [0.         0.         0.31025741 0.         0.06922778 0.\n",
      " 0.         0.31025741 0.         0.         0.31025741], Predicted Values: tensor([    0.0000,     0.0000,     0.9902,     0.0000,     0.0072,     0.0000,\n",
      "            0.0000,     0.0025,     0.0000,     0.0000,     0.0001],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 1., 0., 1., 0., 0., 0., 1., 1., 0.])\n",
      "tensor([[1., 1., 0., 1., 0., 1., 1., 1., 0., 0., 1.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1), Probabilities: [0.         0.         0.43996323 0.         0.09816907 0.\n",
      " 0.         0.         0.43996323 0.02190448 0.        ], Predicted Values: tensor([    0.0000,     0.0000,     0.9806,     0.0000,     0.0072,     0.0000,\n",
      "            0.0000,     0.0000,     0.0120,     0.0002,     0.0000],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 1., 0., 1., 0., 0., 0., 1., 0., 1.])\n",
      "tensor([[1., 1., 0., 1., 0., 1., 1., 1., 0., 1., 0.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0), Probabilities: [0.         0.         0.31025741 0.         0.06922778 0.\n",
      " 0.         0.         0.31025741 0.         0.31025741], Predicted Values: tensor([    0.0000,     0.0000,     0.9808,     0.0000,     0.0072,     0.0000,\n",
      "            0.0000,     0.0000,     0.0120,     0.0000,     0.0001],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 1., 0., 1., 0., 0., 0., 0., 1., 1.])\n",
      "tensor([[1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 0.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0), Probabilities: [0.         0.         0.43996323 0.         0.09816907 0.\n",
      " 0.         0.         0.         0.43996323 0.02190448], Predicted Values: tensor([    0.0000,     0.0000,     0.9925,     0.0000,     0.0072,     0.0000,\n",
      "            0.0000,     0.0000,     0.0000,     0.0002,     0.0001],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 1., 0., 0., 1., 1., 1., 0., 0., 0.])\n",
      "tensor([[1., 1., 0., 1., 1., 0., 0., 0., 1., 1., 1.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1), Probabilities: [0.         0.         0.43996323 0.         0.         0.09816907\n",
      " 0.43996323 0.02190448 0.         0.         0.        ], Predicted Values: tensor([0.0000, 0.0000, 0.9512, 0.0000, 0.0000, 0.0403, 0.0036, 0.0049, 0.0000,\n",
      "        0.0000, 0.0000], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 1., 0., 0., 1., 1., 0., 1., 0., 0.])\n",
      "tensor([[1., 1., 0., 1., 1., 0., 0., 1., 0., 1., 1.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1), Probabilities: [0.         0.         0.40878724 0.         0.         0.09121276\n",
      " 0.40878724 0.         0.09121276 0.         0.        ], Predicted Values: tensor([    0.0000,     0.0000,     0.9491,     0.0000,     0.0000,     0.0402,\n",
      "            0.0004,     0.0000,     0.0103,     0.0000,     0.0000],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 1., 0., 0., 1., 1., 0., 0., 1., 0.])\n",
      "tensor([[1., 1., 0., 1., 1., 0., 0., 1., 1., 0., 1.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1), Probabilities: [0.         0.         0.31025741 0.         0.         0.06922778\n",
      " 0.31025741 0.         0.         0.31025741 0.        ], Predicted Values: tensor([    0.0000,     0.0000,     0.9587,     0.0000,     0.0000,     0.0406,\n",
      "            0.0004,     0.0000,     0.0000,     0.0003,     0.0000],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 1., 0., 0., 1., 1., 0., 0., 0., 1.])\n",
      "tensor([[1., 1., 0., 1., 1., 0., 0., 1., 1., 1., 0.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0), Probabilities: [0.         0.         0.31025741 0.         0.         0.06922778\n",
      " 0.31025741 0.         0.         0.         0.31025741], Predicted Values: tensor([    0.0000,     0.0000,     0.9590,     0.0000,     0.0000,     0.0406,\n",
      "            0.0004,     0.0000,     0.0000,     0.0000,     0.0001],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 1., 0., 0., 1., 0., 1., 1., 0., 0.])\n",
      "tensor([[1., 1., 0., 1., 1., 0., 1., 0., 0., 1., 1.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1), Probabilities: [0.         0.         0.66842802 0.         0.         0.14914645\n",
      " 0.         0.03327907 0.14914645 0.         0.        ], Predicted Values: tensor([0.0000, 0.0000, 0.9533, 0.0000, 0.0000, 0.0404, 0.0000, 0.0050, 0.0013,\n",
      "        0.0000, 0.0000], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 1., 0., 0., 1., 0., 1., 0., 1., 0.])\n",
      "tensor([[1., 1., 0., 1., 1., 0., 1., 0., 1., 0., 1.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1), Probabilities: [0.         0.         0.43996323 0.         0.         0.09816907\n",
      " 0.         0.02190448 0.         0.43996323 0.        ], Predicted Values: tensor([    0.0000,     0.0000,     0.9543,     0.0000,     0.0000,     0.0404,\n",
      "            0.0000,     0.0050,     0.0000,     0.0003,     0.0000],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 1., 0., 0., 1., 0., 1., 0., 0., 1.])\n",
      "tensor([[1., 1., 0., 1., 1., 0., 1., 0., 1., 1., 0.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0), Probabilities: [0.         0.         0.43996323 0.         0.         0.09816907\n",
      " 0.         0.02190448 0.         0.         0.43996323], Predicted Values: tensor([    0.0000,     0.0000,     0.9545,     0.0000,     0.0000,     0.0404,\n",
      "            0.0000,     0.0050,     0.0000,     0.0000,     0.0001],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 1., 0., 0., 1., 0., 0., 1., 1., 0.])\n",
      "tensor([[1., 1., 0., 1., 1., 0., 1., 1., 0., 0., 1.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1), Probabilities: [0.         0.         0.43996323 0.         0.         0.09816907\n",
      " 0.         0.         0.43996323 0.02190448 0.        ], Predicted Values: tensor([    0.0000,     0.0000,     0.9478,     0.0000,     0.0000,     0.0402,\n",
      "            0.0000,     0.0000,     0.0116,     0.0003,     0.0000],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 1., 0., 0., 1., 0., 0., 1., 0., 1.])\n",
      "tensor([[1., 1., 0., 1., 1., 0., 1., 1., 0., 1., 0.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0), Probabilities: [0.         0.         0.31025741 0.         0.         0.06922778\n",
      " 0.         0.         0.31025741 0.         0.31025741], Predicted Values: tensor([    0.0000,     0.0000,     0.9481,     0.0000,     0.0000,     0.0402,\n",
      "            0.0000,     0.0000,     0.0117,     0.0000,     0.0001],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 1., 0., 0., 1., 0., 0., 0., 1., 1.])\n",
      "tensor([[1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 0.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0), Probabilities: [0.         0.         0.43996323 0.         0.         0.09816907\n",
      " 0.         0.         0.         0.43996323 0.02190448], Predicted Values: tensor([    0.0000,     0.0000,     0.9590,     0.0000,     0.0000,     0.0406,\n",
      "            0.0000,     0.0000,     0.0000,     0.0003,     0.0001],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 1., 0., 0., 0., 1., 1., 1., 0., 0.])\n",
      "tensor([[1., 1., 0., 1., 1., 1., 0., 0., 0., 1., 1.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1), Probabilities: [0.         0.         0.32789174 0.         0.         0.\n",
      " 0.32789174 0.32789174 0.01632477 0.         0.        ], Predicted Values: tensor([0.0000, 0.0000, 0.9876, 0.0000, 0.0000, 0.0000, 0.0061, 0.0051, 0.0012,\n",
      "        0.0000, 0.0000], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 1., 0., 0., 0., 1., 1., 0., 1., 0.])\n",
      "tensor([[1., 1., 0., 1., 1., 1., 0., 0., 1., 0., 1.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1), Probabilities: [0.   0.   0.25 0.   0.   0.   0.25 0.25 0.   0.25 0.  ], Predicted Values: tensor([    0.0000,     0.0000,     0.9886,     0.0000,     0.0000,     0.0000,\n",
      "            0.0061,     0.0051,     0.0000,     0.0002,     0.0000],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 1.])\n",
      "tensor([[1., 1., 0., 1., 1., 1., 0., 0., 1., 1., 0.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0), Probabilities: [0.   0.   0.25 0.   0.   0.   0.25 0.25 0.   0.   0.25], Predicted Values: tensor([    0.0000,     0.0000,     0.9887,     0.0000,     0.0000,     0.0000,\n",
      "            0.0061,     0.0051,     0.0000,     0.0000,     0.0001],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 1., 0., 0., 0., 1., 0., 1., 1., 0.])\n",
      "tensor([[1., 1., 0., 1., 1., 1., 0., 1., 0., 0., 1.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1), Probabilities: [0.         0.         0.43996323 0.         0.         0.\n",
      " 0.43996323 0.         0.09816907 0.02190448 0.        ], Predicted Values: tensor([    0.0000,     0.0000,     0.9885,     0.0000,     0.0000,     0.0000,\n",
      "            0.0006,     0.0000,     0.0107,     0.0002,     0.0000],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 1., 0., 0., 0., 1., 0., 1., 0., 1.])\n",
      "tensor([[1., 1., 0., 1., 1., 1., 0., 1., 0., 1., 0.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0), Probabilities: [0.         0.         0.31025741 0.         0.         0.\n",
      " 0.31025741 0.         0.06922778 0.         0.31025741], Predicted Values: tensor([    0.0000,     0.0000,     0.9886,     0.0000,     0.0000,     0.0000,\n",
      "            0.0006,     0.0000,     0.0107,     0.0000,     0.0000],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 1., 0., 0., 0., 1., 0., 0., 1., 1.])\n",
      "tensor([[1., 1., 0., 1., 1., 1., 0., 1., 1., 0., 0.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0), Probabilities: [0.         0.         0.32789174 0.         0.         0.\n",
      " 0.32789174 0.         0.         0.32789174 0.01632477], Predicted Values: tensor([    0.0000,     0.0000,     0.9991,     0.0000,     0.0000,     0.0000,\n",
      "            0.0006,     0.0000,     0.0000,     0.0002,     0.0000],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 1., 0., 0., 0., 0., 1., 1., 1., 0.])\n",
      "tensor([[1., 1., 0., 1., 1., 1., 1., 0., 0., 0., 1.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1), Probabilities: [0.         0.         0.43996323 0.         0.         0.\n",
      " 0.         0.43996323 0.09816907 0.02190448 0.        ], Predicted Values: tensor([    0.0000,     0.0000,     0.9932,     0.0000,     0.0000,     0.0000,\n",
      "            0.0000,     0.0052,     0.0013,     0.0002,     0.0000],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.])\n",
      "tensor([[1., 1., 0., 1., 1., 1., 1., 0., 0., 1., 0.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0), Probabilities: [0.         0.         0.31025741 0.         0.         0.\n",
      " 0.         0.31025741 0.06922778 0.         0.31025741], Predicted Values: tensor([    0.0000,     0.0000,     0.9934,     0.0000,     0.0000,     0.0000,\n",
      "            0.0000,     0.0052,     0.0013,     0.0000,     0.0001],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 1., 0., 0., 0., 0., 1., 0., 1., 1.])\n",
      "tensor([[1., 1., 0., 1., 1., 1., 1., 0., 1., 0., 0.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0), Probabilities: [0.         0.         0.32789174 0.         0.         0.\n",
      " 0.         0.32789174 0.         0.32789174 0.01632477], Predicted Values: tensor([    0.0000,     0.0000,     0.9945,     0.0000,     0.0000,     0.0000,\n",
      "            0.0000,     0.0052,     0.0000,     0.0002,     0.0001],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 1., 0., 0., 0., 0., 0., 1., 1., 1.])\n",
      "tensor([[1., 1., 0., 1., 1., 1., 1., 1., 0., 0., 0.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0), Probabilities: [0.         0.         0.47628706 0.         0.         0.\n",
      " 0.         0.         0.47628706 0.02371294 0.02371294], Predicted Values: tensor([    0.0000,     0.0000,     0.9876,     0.0000,     0.0000,     0.0000,\n",
      "            0.0000,     0.0000,     0.0121,     0.0002,     0.0000],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 0., 1., 1., 1., 1., 0., 0., 0., 0.])\n",
      "tensor([[1., 1., 1., 0., 0., 0., 0., 1., 1., 1., 1.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1), Probabilities: [0.         0.         0.         0.43996323 0.43996323 0.09816907\n",
      " 0.02190448 0.         0.         0.         0.        ], Predicted Values: tensor([    0.0000,     0.0000,     0.0000,     0.9714,     0.0098,     0.0183,\n",
      "            0.0005,     0.0000,     0.0000,     0.0000,     0.0000],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 0., 1., 1., 1., 0., 1., 0., 0., 0.])\n",
      "tensor([[1., 1., 1., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1), Probabilities: [0.         0.         0.         0.43996323 0.43996323 0.09816907\n",
      " 0.         0.02190448 0.         0.         0.        ], Predicted Values: tensor([0.0000, 0.0000, 0.0000, 0.9686, 0.0098, 0.0182, 0.0000, 0.0034, 0.0000,\n",
      "        0.0000, 0.0000], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 0., 1., 1., 1., 0., 0., 1., 0., 0.])\n",
      "tensor([[1., 1., 1., 0., 0., 0., 1., 1., 0., 1., 1.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1), Probabilities: [0.         0.         0.         0.31025741 0.31025741 0.06922778\n",
      " 0.         0.         0.31025741 0.         0.        ], Predicted Values: tensor([0.0000, 0.0000, 0.0000, 0.9633, 0.0098, 0.0181, 0.0000, 0.0000, 0.0088,\n",
      "        0.0000, 0.0000], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 0., 1., 1., 1., 0., 0., 0., 1., 0.])\n",
      "tensor([[1., 1., 1., 0., 0., 0., 1., 1., 1., 0., 1.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1), Probabilities: [0.         0.         0.         0.31025741 0.31025741 0.06922778\n",
      " 0.         0.         0.         0.31025741 0.        ], Predicted Values: tensor([    0.0000,     0.0000,     0.0000,     0.9711,     0.0098,     0.0183,\n",
      "            0.0000,     0.0000,     0.0000,     0.0008,     0.0000],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 0., 1., 1., 1., 0., 0., 0., 0., 1.])\n",
      "tensor([[1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 0.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0), Probabilities: [0.         0.         0.         0.31025741 0.31025741 0.06922778\n",
      " 0.         0.         0.         0.         0.31025741], Predicted Values: tensor([    0.0000,     0.0000,     0.0000,     0.9715,     0.0099,     0.0183,\n",
      "            0.0000,     0.0000,     0.0000,     0.0000,     0.0003],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 0., 1., 1., 0., 1., 1., 0., 0., 0.])\n",
      "tensor([[1., 1., 1., 0., 0., 1., 0., 0., 1., 1., 1.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1), Probabilities: [0.         0.         0.         0.32789174 0.32789174 0.\n",
      " 0.01632477 0.32789174 0.         0.         0.        ], Predicted Values: tensor([0.0000, 0.0000, 0.0000, 0.9784, 0.0099, 0.0000, 0.0083, 0.0034, 0.0000,\n",
      "        0.0000, 0.0000], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 0., 1., 1., 0., 1., 0., 1., 0., 0.])\n",
      "tensor([[1., 1., 1., 0., 0., 1., 0., 1., 0., 1., 1.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1), Probabilities: [0.         0.         0.         0.43996323 0.43996323 0.\n",
      " 0.02190448 0.         0.09816907 0.         0.        ], Predicted Values: tensor([    0.0000,     0.0000,     0.0000,     0.9814,     0.0099,     0.0000,\n",
      "            0.0009,     0.0000,     0.0079,     0.0000,     0.0000],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 0., 1., 1., 0., 1., 0., 0., 1., 0.])\n",
      "tensor([[1., 1., 1., 0., 0., 1., 0., 1., 1., 0., 1.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1), Probabilities: [0.         0.         0.         0.32789174 0.32789174 0.\n",
      " 0.01632477 0.         0.         0.32789174 0.        ], Predicted Values: tensor([    0.0000,     0.0000,     0.0000,     0.9886,     0.0100,     0.0000,\n",
      "            0.0009,     0.0000,     0.0000,     0.0005,     0.0000],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 0., 1., 1., 0., 1., 0., 0., 0., 1.])\n",
      "tensor([[1., 1., 1., 0., 0., 1., 0., 1., 1., 1., 0.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0), Probabilities: [0.         0.         0.         0.32789174 0.32789174 0.\n",
      " 0.01632477 0.         0.         0.         0.32789174], Predicted Values: tensor([    0.0000,     0.0000,     0.0000,     0.9890,     0.0100,     0.0000,\n",
      "            0.0009,     0.0000,     0.0000,     0.0000,     0.0002],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 0., 1., 1., 0., 0., 1., 1., 0., 0.])\n",
      "tensor([[1., 1., 1., 0., 0., 1., 1., 0., 0., 1., 1.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1), Probabilities: [0.         0.         0.         0.31025741 0.31025741 0.\n",
      " 0.         0.31025741 0.06922778 0.         0.        ], Predicted Values: tensor([    0.0000,     0.0000,     0.0000,     0.9856,     0.0100,     0.0000,\n",
      "            0.0000,     0.0035,     0.0010,     0.0000,     0.0000],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 0., 1., 1., 0., 0., 1., 0., 1., 0.])\n",
      "tensor([[1., 1., 1., 0., 0., 1., 1., 0., 1., 0., 1.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1), Probabilities: [0.   0.   0.   0.25 0.25 0.   0.   0.25 0.   0.25 0.  ], Predicted Values: tensor([    0.0000,     0.0000,     0.0000,     0.9860,     0.0100,     0.0000,\n",
      "            0.0000,     0.0035,     0.0000,     0.0005,     0.0000],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 0., 1., 1., 0., 0., 1., 0., 0., 1.])\n",
      "tensor([[1., 1., 1., 0., 0., 1., 1., 0., 1., 1., 0.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0), Probabilities: [0.   0.   0.   0.25 0.25 0.   0.   0.25 0.   0.   0.25], Predicted Values: tensor([    0.0000,     0.0000,     0.0000,     0.9863,     0.0100,     0.0000,\n",
      "            0.0000,     0.0035,     0.0000,     0.0000,     0.0002],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 0., 1., 1., 0., 0., 0., 1., 1., 0.])\n",
      "tensor([[1., 1., 1., 0., 0., 1., 1., 1., 0., 0., 1.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1), Probabilities: [0.         0.         0.         0.32789174 0.32789174 0.\n",
      " 0.         0.         0.32789174 0.01632477 0.        ], Predicted Values: tensor([    0.0000,     0.0000,     0.0000,     0.9806,     0.0099,     0.0000,\n",
      "            0.0000,     0.0000,     0.0089,     0.0005,     0.0000],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 0., 1., 1., 0., 0., 0., 1., 0., 1.])\n",
      "tensor([[1., 1., 1., 0., 0., 1., 1., 1., 0., 1., 0.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0), Probabilities: [0.   0.   0.   0.25 0.25 0.   0.   0.   0.25 0.   0.25], Predicted Values: tensor([    0.0000,     0.0000,     0.0000,     0.9810,     0.0099,     0.0000,\n",
      "            0.0000,     0.0000,     0.0090,     0.0000,     0.0001],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 0., 1., 1., 0., 0., 0., 0., 1., 1.])\n",
      "tensor([[1., 1., 1., 0., 0., 1., 1., 1., 1., 0., 0.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0), Probabilities: [0.         0.         0.         0.32789174 0.32789174 0.\n",
      " 0.         0.         0.         0.32789174 0.01632477], Predicted Values: tensor([    0.0000,     0.0000,     0.0000,     0.9893,     0.0100,     0.0000,\n",
      "            0.0000,     0.0000,     0.0000,     0.0005,     0.0002],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 0., 1., 0., 1., 1., 1., 0., 0., 0.])\n",
      "tensor([[1., 1., 1., 0., 1., 0., 0., 0., 1., 1., 1.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1), Probabilities: [0.         0.         0.         0.43996323 0.         0.09816907\n",
      " 0.43996323 0.02190448 0.         0.         0.        ], Predicted Values: tensor([0.0000, 0.0000, 0.0000, 0.9698, 0.0000, 0.0182, 0.0051, 0.0070, 0.0000,\n",
      "        0.0000, 0.0000], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 0., 1., 0., 1., 1., 0., 1., 0., 0.])\n",
      "tensor([[1., 1., 1., 0., 1., 0., 0., 1., 0., 1., 1.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1), Probabilities: [0.         0.         0.         0.40878724 0.         0.09121276\n",
      " 0.40878724 0.         0.09121276 0.         0.        ], Predicted Values: tensor([    0.0000,     0.0000,     0.0000,     0.9734,     0.0000,     0.0183,\n",
      "            0.0005,     0.0000,     0.0078,     0.0000,     0.0000],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 0., 1., 0., 1., 1., 0., 0., 1., 0.])\n",
      "tensor([[1., 1., 1., 0., 1., 0., 0., 1., 1., 0., 1.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1), Probabilities: [0.         0.         0.         0.31025741 0.         0.06922778\n",
      " 0.31025741 0.         0.         0.31025741 0.        ], Predicted Values: tensor([    0.0000,     0.0000,     0.0000,     0.9803,     0.0000,     0.0184,\n",
      "            0.0005,     0.0000,     0.0000,     0.0008,     0.0000],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 0., 1., 0., 1., 1., 0., 0., 0., 1.])\n",
      "tensor([[1., 1., 1., 0., 1., 0., 0., 1., 1., 1., 0.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0), Probabilities: [0.         0.         0.         0.31025741 0.         0.06922778\n",
      " 0.31025741 0.         0.         0.         0.31025741], Predicted Values: tensor([    0.0000,     0.0000,     0.0000,     0.9809,     0.0000,     0.0184,\n",
      "            0.0005,     0.0000,     0.0000,     0.0000,     0.0002],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 0., 1., 0., 1., 0., 1., 1., 0., 0.])\n",
      "tensor([[1., 1., 1., 0., 1., 0., 1., 0., 0., 1., 1.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1), Probabilities: [0.         0.         0.         0.66842802 0.         0.14914645\n",
      " 0.         0.03327907 0.14914645 0.         0.        ], Predicted Values: tensor([    0.0000,     0.0000,     0.0000,     0.9737,     0.0000,     0.0183,\n",
      "            0.0000,     0.0071,     0.0010,     0.0000,     0.0000],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 0., 1., 0., 1., 0., 1., 0., 1., 0.])\n",
      "tensor([[1., 1., 1., 0., 1., 0., 1., 0., 1., 0., 1.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1), Probabilities: [0.         0.         0.         0.43996323 0.         0.09816907\n",
      " 0.         0.02190448 0.         0.43996323 0.        ], Predicted Values: tensor([    0.0000,     0.0000,     0.0000,     0.9738,     0.0000,     0.0183,\n",
      "            0.0000,     0.0071,     0.0000,     0.0008,     0.0000],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 0., 1., 0., 1., 0., 1., 0., 0., 1.])\n",
      "tensor([[1., 1., 1., 0., 1., 0., 1., 0., 1., 1., 0.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0), Probabilities: [0.         0.         0.         0.43996323 0.         0.09816907\n",
      " 0.         0.02190448 0.         0.         0.43996323], Predicted Values: tensor([    0.0000,     0.0000,     0.0000,     0.9744,     0.0000,     0.0183,\n",
      "            0.0000,     0.0071,     0.0000,     0.0000,     0.0003],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 0., 1., 0., 1., 0., 0., 1., 1., 0.])\n",
      "tensor([[1., 1., 1., 0., 1., 0., 1., 1., 0., 0., 1.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1), Probabilities: [0.         0.         0.         0.43996323 0.         0.09816907\n",
      " 0.         0.         0.43996323 0.02190448 0.        ], Predicted Values: tensor([    0.0000,     0.0000,     0.0000,     0.9720,     0.0000,     0.0183,\n",
      "            0.0000,     0.0000,     0.0089,     0.0008,     0.0000],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 0., 1., 0., 1., 0., 0., 1., 0., 1.])\n",
      "tensor([[1., 1., 1., 0., 1., 0., 1., 1., 0., 1., 0.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0), Probabilities: [0.         0.         0.         0.31025741 0.         0.06922778\n",
      " 0.         0.         0.31025741 0.         0.31025741], Predicted Values: tensor([    0.0000,     0.0000,     0.0000,     0.9726,     0.0000,     0.0183,\n",
      "            0.0000,     0.0000,     0.0089,     0.0000,     0.0002],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 0., 1., 0., 1., 0., 0., 0., 1., 1.])\n",
      "tensor([[1., 1., 1., 0., 1., 0., 1., 1., 1., 0., 0.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0), Probabilities: [0.         0.         0.         0.43996323 0.         0.09816907\n",
      " 0.         0.         0.         0.43996323 0.02190448], Predicted Values: tensor([    0.0000,     0.0000,     0.0000,     0.9806,     0.0000,     0.0184,\n",
      "            0.0000,     0.0000,     0.0000,     0.0008,     0.0002],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 0., 1., 0., 0., 1., 1., 1., 0., 0.])\n",
      "tensor([[1., 1., 1., 0., 1., 1., 0., 0., 0., 1., 1.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1), Probabilities: [0.         0.         0.         0.32789174 0.         0.\n",
      " 0.32789174 0.32789174 0.01632477 0.         0.        ], Predicted Values: tensor([    0.0000,     0.0000,     0.0000,     0.9837,     0.0000,     0.0000,\n",
      "            0.0084,     0.0071,     0.0009,     0.0000,     0.0000],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 0., 1., 0., 0., 1., 1., 0., 1., 0.])\n",
      "tensor([[1., 1., 1., 0., 1., 1., 0., 0., 1., 0., 1.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1), Probabilities: [0.   0.   0.   0.25 0.   0.   0.25 0.25 0.   0.25 0.  ], Predicted Values: tensor([    0.0000,     0.0000,     0.0000,     0.9840,     0.0000,     0.0000,\n",
      "            0.0084,     0.0071,     0.0000,     0.0005,     0.0000],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 0., 1., 0., 0., 1., 1., 0., 0., 1.])\n",
      "tensor([[1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 0.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0), Probabilities: [0.   0.   0.   0.25 0.   0.   0.25 0.25 0.   0.   0.25], Predicted Values: tensor([    0.0000,     0.0000,     0.0000,     0.9844,     0.0000,     0.0000,\n",
      "            0.0083,     0.0071,     0.0000,     0.0000,     0.0001],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 0., 1., 0., 0., 1., 0., 1., 1., 0.])\n",
      "tensor([[1., 1., 1., 0., 1., 1., 0., 1., 0., 0., 1.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1), Probabilities: [0.         0.         0.         0.43996323 0.         0.\n",
      " 0.43996323 0.         0.09816907 0.02190448 0.        ], Predicted Values: tensor([    0.0000,     0.0000,     0.0000,     0.9906,     0.0000,     0.0000,\n",
      "            0.0009,     0.0000,     0.0080,     0.0005,     0.0000],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 0., 1., 0., 0., 1., 0., 1., 0., 1.])\n",
      "tensor([[1., 1., 1., 0., 1., 1., 0., 1., 0., 1., 0.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0), Probabilities: [0.         0.         0.         0.31025741 0.         0.\n",
      " 0.31025741 0.         0.06922778 0.         0.31025741], Predicted Values: tensor([    0.0000,     0.0000,     0.0000,     0.9910,     0.0000,     0.0000,\n",
      "            0.0009,     0.0000,     0.0080,     0.0000,     0.0001],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 0., 1., 0., 0., 1., 0., 0., 1., 1.])\n",
      "tensor([[1., 1., 1., 0., 1., 1., 0., 1., 1., 0., 0.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0), Probabilities: [0.         0.         0.         0.32789174 0.         0.\n",
      " 0.32789174 0.         0.         0.32789174 0.01632477], Predicted Values: tensor([    0.0000,     0.0000,     0.0000,     0.9985,     0.0000,     0.0000,\n",
      "            0.0009,     0.0000,     0.0000,     0.0005,     0.0001],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 0., 1., 0., 0., 0., 1., 1., 1., 0.])\n",
      "tensor([[1., 1., 1., 0., 1., 1., 1., 0., 0., 0., 1.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1), Probabilities: [0.         0.         0.         0.43996323 0.         0.\n",
      " 0.         0.43996323 0.09816907 0.02190448 0.        ], Predicted Values: tensor([    0.0000,     0.0000,     0.0000,     0.9913,     0.0000,     0.0000,\n",
      "            0.0000,     0.0072,     0.0010,     0.0005,     0.0000],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 1.])\n",
      "tensor([[1., 1., 1., 0., 1., 1., 1., 0., 0., 1., 0.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0), Probabilities: [0.         0.         0.         0.31025741 0.         0.\n",
      " 0.         0.31025741 0.06922778 0.         0.31025741], Predicted Values: tensor([    0.0000,     0.0000,     0.0000,     0.9917,     0.0000,     0.0000,\n",
      "            0.0000,     0.0072,     0.0010,     0.0000,     0.0001],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 0., 1., 0., 0., 0., 1., 0., 1., 1.])\n",
      "tensor([[1., 1., 1., 0., 1., 1., 1., 0., 1., 0., 0.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0), Probabilities: [0.         0.         0.         0.32789174 0.         0.\n",
      " 0.         0.32789174 0.         0.32789174 0.01632477], Predicted Values: tensor([    0.0000,     0.0000,     0.0000,     0.9921,     0.0000,     0.0000,\n",
      "            0.0000,     0.0072,     0.0000,     0.0005,     0.0001],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 1.])\n",
      "tensor([[1., 1., 1., 0., 1., 1., 1., 1., 0., 0., 0.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0), Probabilities: [0.         0.         0.         0.47628706 0.         0.\n",
      " 0.         0.         0.47628706 0.02371294 0.02371294], Predicted Values: tensor([    0.0000,     0.0000,     0.0000,     0.9903,     0.0000,     0.0000,\n",
      "            0.0000,     0.0000,     0.0091,     0.0005,     0.0001],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 0., 0., 1., 1., 1., 1., 0., 0., 0.])\n",
      "tensor([[1., 1., 1., 1., 0., 0., 0., 0., 1., 1., 1.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1), Probabilities: [0.         0.         0.         0.         0.47628706 0.47628706\n",
      " 0.02371294 0.02371294 0.         0.         0.        ], Predicted Values: tensor([0.0000, 0.0000, 0.0000, 0.0000, 0.1216, 0.7739, 0.0630, 0.0415, 0.0000,\n",
      "        0.0000, 0.0000], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 0., 0., 1., 1., 1., 0., 1., 0., 0.])\n",
      "tensor([[1., 1., 1., 1., 0., 0., 0., 1., 0., 1., 1.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1), Probabilities: [0.         0.         0.         0.         0.43996323 0.43996323\n",
      " 0.02190448 0.         0.09816907 0.         0.        ], Predicted Values: tensor([0.0000, 0.0000, 0.0000, 0.0000, 0.1268, 0.8064, 0.0069, 0.0000, 0.0599,\n",
      "        0.0000, 0.0000], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 0., 0., 1., 1., 1., 0., 0., 1., 0.])\n",
      "tensor([[1., 1., 1., 1., 0., 0., 0., 1., 1., 0., 1.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1), Probabilities: [0.         0.         0.         0.         0.32789174 0.32789174\n",
      " 0.01632477 0.         0.         0.32789174 0.        ], Predicted Values: tensor([0.0000, 0.0000, 0.0000, 0.0000, 0.1344, 0.8559, 0.0073, 0.0000, 0.0000,\n",
      "        0.0023, 0.0000], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 0., 0., 1., 1., 1., 0., 0., 0., 1.])\n",
      "tensor([[1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 0.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0), Probabilities: [0.         0.         0.         0.         0.32789174 0.32789174\n",
      " 0.01632477 0.         0.         0.         0.32789174], Predicted Values: tensor([0.0000, 0.0000, 0.0000, 0.0000, 0.1349, 0.8568, 0.0073, 0.0000, 0.0000,\n",
      "        0.0000, 0.0009], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 0., 0., 1., 1., 0., 1., 1., 0., 0.])\n",
      "tensor([[1., 1., 1., 1., 0., 0., 1., 0., 0., 1., 1.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1), Probabilities: [0.         0.         0.         0.         0.43996323 0.43996323\n",
      " 0.         0.02190448 0.09816907 0.         0.        ], Predicted Values: tensor([0.0000, 0.0000, 0.0000, 0.0000, 0.1289, 0.8193, 0.0000, 0.0442, 0.0075,\n",
      "        0.0000, 0.0000], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 0., 0., 1., 1., 0., 1., 0., 1., 0.])\n",
      "tensor([[1., 1., 1., 1., 0., 0., 1., 0., 1., 0., 1.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1), Probabilities: [0.         0.         0.         0.         0.32789174 0.32789174\n",
      " 0.         0.01632477 0.         0.32789174 0.        ], Predicted Values: tensor([0.0000, 0.0000, 0.0000, 0.0000, 0.1295, 0.8238, 0.0000, 0.0444, 0.0000,\n",
      "        0.0023, 0.0000], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 0., 0., 1., 1., 0., 1., 0., 0., 1.])\n",
      "tensor([[1., 1., 1., 1., 0., 0., 1., 0., 1., 1., 0.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0), Probabilities: [0.         0.         0.         0.         0.32789174 0.32789174\n",
      " 0.         0.01632477 0.         0.         0.32789174], Predicted Values: tensor([0.0000, 0.0000, 0.0000, 0.0000, 0.1300, 0.8242, 0.0000, 0.0445, 0.0000,\n",
      "        0.0000, 0.0013], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 0., 0., 1., 1., 0., 0., 1., 1., 0.])\n",
      "tensor([[1., 1., 1., 1., 0., 0., 1., 1., 0., 0., 1.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1), Probabilities: [0.         0.         0.         0.         0.32789174 0.32789174\n",
      " 0.         0.         0.32789174 0.01632477 0.        ], Predicted Values: tensor([0.0000, 0.0000, 0.0000, 0.0000, 0.1264, 0.8037, 0.0000, 0.0000, 0.0677,\n",
      "        0.0022, 0.0000], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 0., 0., 1., 1., 0., 0., 1., 0., 1.])\n",
      "tensor([[1., 1., 1., 1., 0., 0., 1., 1., 0., 1., 0.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0), Probabilities: [0.   0.   0.   0.   0.25 0.25 0.   0.   0.25 0.   0.25], Predicted Values: tensor([    0.0000,     0.0000,     0.0000,     0.0000,     0.1269,     0.8044,\n",
      "            0.0000,     0.0000,     0.0679,     0.0000,     0.0008],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 0., 0., 1., 1., 0., 0., 0., 1., 1.])\n",
      "tensor([[1., 1., 1., 1., 0., 0., 1., 1., 1., 0., 0.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0), Probabilities: [0.         0.         0.         0.         0.32789174 0.32789174\n",
      " 0.         0.         0.         0.32789174 0.01632477], Predicted Values: tensor([    0.0000,     0.0000,     0.0000,     0.0000,     0.1357,     0.8611,\n",
      "            0.0000,     0.0000,     0.0000,     0.0024,     0.0009],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 0., 0., 1., 0., 1., 1., 1., 0., 0.])\n",
      "tensor([[1., 1., 1., 1., 0., 1., 0., 0., 0., 1., 1.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1), Probabilities: [0.         0.         0.         0.         0.47628706 0.\n",
      " 0.02371294 0.47628706 0.02371294 0.         0.        ], Predicted Values: tensor([0.0000, 0.0000, 0.0000, 0.0000, 0.4463, 0.0000, 0.3773, 0.1534, 0.0230,\n",
      "        0.0000, 0.0000], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 0., 0., 1., 0., 1., 1., 0., 1., 0.])\n",
      "tensor([[1., 1., 1., 1., 0., 1., 0., 0., 1., 0., 1.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1), Probabilities: [0.         0.         0.         0.         0.32789174 0.\n",
      " 0.01632477 0.32789174 0.         0.32789174 0.        ], Predicted Values: tensor([0.0000, 0.0000, 0.0000, 0.0000, 0.4544, 0.0000, 0.3839, 0.1563, 0.0000,\n",
      "        0.0054, 0.0000], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 0., 0., 1., 0., 1., 1., 0., 0., 1.])\n",
      "tensor([[1., 1., 1., 1., 0., 1., 0., 0., 1., 1., 0.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0), Probabilities: [0.         0.         0.         0.         0.32789174 0.\n",
      " 0.01632477 0.32789174 0.         0.         0.32789174], Predicted Values: tensor([0.0000, 0.0000, 0.0000, 0.0000, 0.4564, 0.0000, 0.3845, 0.1568, 0.0000,\n",
      "        0.0000, 0.0023], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 0.])\n",
      "tensor([[1., 1., 1., 1., 0., 1., 0., 1., 0., 0., 1.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1), Probabilities: [0.         0.         0.         0.         0.75602688 0.\n",
      " 0.03764036 0.         0.1686924  0.03764036 0.        ], Predicted Values: tensor([0.0000, 0.0000, 0.0000, 0.0000, 0.6357, 0.0000, 0.0564, 0.0000, 0.3004,\n",
      "        0.0075, 0.0000], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 0., 0., 1., 0., 1., 0., 1., 0., 1.])\n",
      "tensor([[1., 1., 1., 1., 0., 1., 0., 1., 0., 1., 0.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0), Probabilities: [0.         0.         0.         0.         0.43996323 0.\n",
      " 0.02190448 0.         0.09816907 0.         0.43996323], Predicted Values: tensor([0.0000, 0.0000, 0.0000, 0.0000, 0.6393, 0.0000, 0.0565, 0.0000, 0.3022,\n",
      "        0.0000, 0.0021], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 0., 0., 1., 0., 1., 0., 0., 1., 1.])\n",
      "tensor([[1., 1., 1., 1., 0., 1., 0., 1., 1., 0., 0.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0), Probabilities: [0.         0.         0.         0.         0.47628706 0.\n",
      " 0.02371294 0.         0.         0.47628706 0.02371294], Predicted Values: tensor([0.0000, 0.0000, 0.0000, 0.0000, 0.9063, 0.0000, 0.0801, 0.0000, 0.0000,\n",
      "        0.0107, 0.0029], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 0., 0., 1., 0., 0., 1., 1., 1., 0.])\n",
      "tensor([[1., 1., 1., 1., 0., 1., 1., 0., 0., 0., 1.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1), Probabilities: [0.         0.         0.         0.         0.43996323 0.\n",
      " 0.         0.43996323 0.09816907 0.02190448 0.        ], Predicted Values: tensor([0.0000, 0.0000, 0.0000, 0.0000, 0.7063, 0.0000, 0.0000, 0.2442, 0.0412,\n",
      "        0.0083, 0.0000], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 0., 0., 1., 0., 0., 1., 1., 0., 1.])\n",
      "tensor([[1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 0.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0), Probabilities: [0.         0.         0.         0.         0.31025741 0.\n",
      " 0.         0.31025741 0.06922778 0.         0.31025741], Predicted Values: tensor([0.0000, 0.0000, 0.0000, 0.0000, 0.7101, 0.0000, 0.0000, 0.2452, 0.0414,\n",
      "        0.0000, 0.0033], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 0., 0., 1., 0., 0., 1., 0., 1., 1.])\n",
      "tensor([[1., 1., 1., 1., 0., 1., 1., 0., 1., 0., 0.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0), Probabilities: [0.         0.         0.         0.         0.32789174 0.\n",
      " 0.         0.32789174 0.         0.32789174 0.01632477], Predicted Values: tensor([0.0000, 0.0000, 0.0000, 0.0000, 0.7343, 0.0000, 0.0000, 0.2537, 0.0000,\n",
      "        0.0087, 0.0034], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 1.])\n",
      "tensor([[1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 0.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0), Probabilities: [0.         0.         0.         0.         0.47628706 0.\n",
      " 0.         0.         0.47628706 0.02371294 0.02371294], Predicted Values: tensor([0.0000, 0.0000, 0.0000, 0.0000, 0.6451, 0.0000, 0.0000, 0.0000, 0.3454,\n",
      "        0.0076, 0.0019], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 0., 0., 0., 1., 1., 1., 1., 0., 0.])\n",
      "tensor([[1., 1., 1., 1., 1., 0., 0., 0., 0., 1., 1.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1), Probabilities: [0.         0.         0.         0.         0.         0.47628706\n",
      " 0.47628706 0.02371294 0.02371294 0.         0.        ], Predicted Values: tensor([0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.8325, 0.0678, 0.0929, 0.0068,\n",
      "        0.0000, 0.0000], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 0., 0., 0., 1., 1., 1., 0., 1., 0.])\n",
      "tensor([[1., 1., 1., 1., 1., 0., 0., 0., 1., 0., 1.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1), Probabilities: [0.         0.         0.         0.         0.         0.32789174\n",
      " 0.32789174 0.01632477 0.         0.32789174 0.        ], Predicted Values: tensor([0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.8364, 0.0680, 0.0933, 0.0000,\n",
      "        0.0023, 0.0000], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 0., 0., 0., 1., 1., 1., 0., 0., 1.])\n",
      "tensor([[1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 0.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0), Probabilities: [0.         0.         0.         0.         0.         0.32789174\n",
      " 0.32789174 0.01632477 0.         0.         0.32789174], Predicted Values: tensor([    0.0000,     0.0000,     0.0000,     0.0000,     0.0000,     0.8376,\n",
      "            0.0681,     0.0936,     0.0000,     0.0000,     0.0007],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 0., 0., 0., 1., 1., 0., 1., 1., 0.])\n",
      "tensor([[1., 1., 1., 1., 1., 0., 0., 1., 0., 0., 1.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1), Probabilities: [0.         0.         0.         0.         0.         0.43996323\n",
      " 0.43996323 0.         0.09816907 0.02190448 0.        ], Predicted Values: tensor([0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.9209, 0.0079, 0.0000, 0.0687,\n",
      "        0.0025, 0.0000], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 0., 0., 0., 1., 1., 0., 1., 0., 1.])\n",
      "tensor([[1., 1., 1., 1., 1., 0., 0., 1., 0., 1., 0.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0), Probabilities: [0.         0.         0.         0.         0.         0.31025741\n",
      " 0.31025741 0.         0.06922778 0.         0.31025741], Predicted Values: tensor([    0.0000,     0.0000,     0.0000,     0.0000,     0.0000,     0.9226,\n",
      "            0.0079,     0.0000,     0.0690,     0.0000,     0.0005],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 0., 0., 0., 1., 1., 0., 0., 1., 1.])\n",
      "tensor([[1., 1., 1., 1., 1., 0., 0., 1., 1., 0., 0.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0), Probabilities: [0.         0.         0.         0.         0.         0.32789174\n",
      " 0.32789174 0.         0.         0.32789174 0.01632477], Predicted Values: tensor([    0.0000,     0.0000,     0.0000,     0.0000,     0.0000,     0.9883,\n",
      "            0.0084,     0.0000,     0.0000,     0.0027,     0.0006],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 0., 0., 0., 1., 0., 1., 1., 1., 0.])\n",
      "tensor([[1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1), Probabilities: [0.         0.         0.         0.         0.         0.75602688\n",
      " 0.         0.03764036 0.1686924  0.03764036 0.        ], Predicted Values: tensor([0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.8895, 0.0000, 0.0999, 0.0082,\n",
      "        0.0024, 0.0000], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 0., 0., 0., 1., 0., 1., 1., 0., 1.])\n",
      "tensor([[1., 1., 1., 1., 1., 0., 1., 0., 0., 1., 0.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0), Probabilities: [0.         0.         0.         0.         0.         0.43996323\n",
      " 0.         0.02190448 0.09816907 0.         0.43996323], Predicted Values: tensor([    0.0000,     0.0000,     0.0000,     0.0000,     0.0000,     0.8908,\n",
      "            0.0000,     0.1002,     0.0082,     0.0000,     0.0007],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1.])\n",
      "tensor([[1., 1., 1., 1., 1., 0., 1., 0., 1., 0., 0.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0), Probabilities: [0.         0.         0.         0.         0.         0.47628706\n",
      " 0.         0.02371294 0.         0.47628706 0.02371294], Predicted Values: tensor([    0.0000,     0.0000,     0.0000,     0.0000,     0.0000,     0.8961,\n",
      "            0.0000,     0.1007,     0.0000,     0.0025,     0.0007],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 0., 0., 0., 1., 0., 0., 1., 1., 1.])\n",
      "tensor([[1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 0.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0), Probabilities: [0.         0.         0.         0.         0.         0.47628706\n",
      " 0.         0.         0.47628706 0.02371294 0.02371294], Predicted Values: tensor([    0.0000,     0.0000,     0.0000,     0.0000,     0.0000,     0.9191,\n",
      "            0.0000,     0.0000,     0.0779,     0.0025,     0.0005],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 0.])\n",
      "tensor([[1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 1.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1), Probabilities: [0.         0.         0.         0.         0.         0.\n",
      " 0.47628706 0.47628706 0.02371294 0.02371294 0.        ], Predicted Values: tensor([0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.5202, 0.4406, 0.0319,\n",
      "        0.0073, 0.0000], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 0., 0., 0., 0., 1., 1., 1., 0., 1.])\n",
      "tensor([[1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 0.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0), Probabilities: [0.         0.         0.         0.         0.         0.\n",
      " 0.32789174 0.32789174 0.01632477 0.         0.32789174], Predicted Values: tensor([0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.5227, 0.4435, 0.0321,\n",
      "        0.0000, 0.0016], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 0., 0., 0., 0., 1., 1., 0., 1., 1.])\n",
      "tensor([[1., 1., 1., 1., 1., 1., 0., 0., 1., 0., 0.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0), Probabilities: [0.         0.         0.         0.         0.         0.\n",
      " 0.32789174 0.32789174 0.         0.32789174 0.01632477], Predicted Values: tensor([0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.5357, 0.4551, 0.0000,\n",
      "        0.0075, 0.0017], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 0., 0., 0., 0., 1., 0., 1., 1., 1.])\n",
      "tensor([[1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0), Probabilities: [0.         0.         0.         0.         0.         0.\n",
      " 0.75602688 0.         0.1686924  0.03764036 0.03764036], Predicted Values: tensor([0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1532, 0.0000, 0.8234,\n",
      "        0.0205, 0.0029], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1.])\n",
      "tensor([[1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0), Probabilities: [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.75602688 0.1686924  0.03764036 0.03764036], Predicted Values: tensor([0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.9080, 0.0741,\n",
      "        0.0149, 0.0031], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0.])\n",
      "tensor([[1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1), Probabilities: [0.         0.33333333 0.33333333 0.33333333 0.         0.\n",
      " 0.         0.         0.         0.         0.        ], Predicted Values: tensor([0.0000, 0.1521, 0.3949, 0.4530, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 1., 0., 1., 0., 0., 0., 0., 0., 0.])\n",
      "tensor([[1., 0., 0., 1., 0., 1., 1., 1., 1., 1., 1.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1), Probabilities: [0.         0.48785555 0.48785555 0.         0.0242889  0.\n",
      " 0.         0.         0.         0.         0.        ], Predicted Values: tensor([0.0000, 0.1584, 0.8313, 0.0000, 0.0103, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 1., 0., 0., 1., 0., 0., 0., 0., 0.])\n",
      "tensor([[1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 1.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1), Probabilities: [0.         0.44981622 0.44981622 0.         0.         0.10036756\n",
      " 0.         0.         0.         0.         0.        ], Predicted Values: tensor([0.0000, 0.1553, 0.8125, 0.0000, 0.0000, 0.0322, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 1., 0., 0., 0., 1., 0., 0., 0., 0.])\n",
      "tensor([[1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1), Probabilities: [0.         0.33333333 0.33333333 0.         0.         0.\n",
      " 0.33333333 0.         0.         0.         0.        ], Predicted Values: tensor([0.0000, 0.1600, 0.8391, 0.0000, 0.0000, 0.0000, 0.0009, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 1., 0., 0., 0., 0., 1., 0., 0., 0.])\n",
      "tensor([[1., 0., 0., 1., 1., 1., 1., 0., 1., 1., 1.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1), Probabilities: [0.         0.33333333 0.33333333 0.         0.         0.\n",
      " 0.         0.33333333 0.         0.         0.        ], Predicted Values: tensor([0.0000, 0.1589, 0.8336, 0.0000, 0.0000, 0.0000, 0.0000, 0.0074, 0.0000,\n",
      "        0.0000, 0.0000], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 1., 0., 0., 0., 0., 0., 1., 0., 0.])\n",
      "tensor([[1., 0., 0., 1., 1., 1., 1., 1., 0., 1., 1.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1), Probabilities: [0.         0.33333333 0.33333333 0.         0.         0.\n",
      " 0.         0.         0.33333333 0.         0.        ], Predicted Values: tensor([0.0000, 0.1567, 0.8214, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0220,\n",
      "        0.0000, 0.0000], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 1., 0., 0., 0., 0., 0., 0., 1., 0.])\n",
      "tensor([[1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1), Probabilities: [0.         0.33333333 0.33333333 0.         0.         0.\n",
      " 0.         0.         0.         0.33333333 0.        ], Predicted Values: tensor([0.0000, 0.1600, 0.8390, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0010, 0.0000], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 1.])\n",
      "tensor([[1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0), Probabilities: [0.         0.33333333 0.33333333 0.         0.         0.\n",
      " 0.         0.         0.         0.         0.33333333], Predicted Values: tensor([    0.0000,     0.1601,     0.8398,     0.0000,     0.0000,     0.0000,\n",
      "            0.0000,     0.0000,     0.0000,     0.0000,     0.0001],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 0., 1., 1., 0., 0., 0., 0., 0., 0.])\n",
      "tensor([[1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1), Probabilities: [0.         0.44981622 0.         0.44981622 0.10036756 0.\n",
      " 0.         0.         0.         0.         0.        ], Predicted Values: tensor([0.0000, 0.4073, 0.0000, 0.5830, 0.0096, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 0., 1., 0., 1., 0., 0., 0., 0., 0.])\n",
      "tensor([[1., 0., 1., 0., 1., 0., 1., 1., 1., 1., 1.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1), Probabilities: [0.         0.44981622 0.         0.44981622 0.         0.10036756\n",
      " 0.         0.         0.         0.         0.        ], Predicted Values: tensor([0.0000, 0.4077, 0.0000, 0.5824, 0.0000, 0.0099, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 0., 1., 0., 0., 1., 0., 0., 0., 0.])\n",
      "tensor([[1., 0., 1., 0., 1., 1., 0., 1., 1., 1., 1.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1), Probabilities: [0.         0.33333333 0.         0.33333333 0.         0.\n",
      " 0.33333333 0.         0.         0.         0.        ], Predicted Values: tensor([0.0000, 0.4108, 0.0000, 0.5883, 0.0000, 0.0000, 0.0009, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 0., 1., 0., 0., 0., 1., 0., 0., 0.])\n",
      "tensor([[1., 0., 1., 0., 1., 1., 1., 0., 1., 1., 1.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1), Probabilities: [0.         0.33333333 0.         0.33333333 0.         0.\n",
      " 0.         0.33333333 0.         0.         0.        ], Predicted Values: tensor([0.0000, 0.4086, 0.0000, 0.5844, 0.0000, 0.0000, 0.0000, 0.0070, 0.0000,\n",
      "        0.0000, 0.0000], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 0., 1., 0., 0., 0., 0., 1., 0., 0.])\n",
      "tensor([[1., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1), Probabilities: [0.         0.33333333 0.         0.33333333 0.         0.\n",
      " 0.         0.         0.33333333 0.         0.        ], Predicted Values: tensor([0.0000, 0.4068, 0.0000, 0.5820, 0.0000, 0.0000, 0.0000, 0.0000, 0.0112,\n",
      "        0.0000, 0.0000], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 0., 1., 0., 0., 0., 0., 0., 1., 0.])\n",
      "tensor([[1., 0., 1., 0., 1., 1., 1., 1., 1., 0., 1.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1), Probabilities: [0.         0.33333333 0.         0.33333333 0.         0.\n",
      " 0.         0.         0.         0.33333333 0.        ], Predicted Values: tensor([0.0000, 0.4110, 0.0000, 0.5875, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0015, 0.0000], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 1.])\n",
      "tensor([[1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 0.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0), Probabilities: [0.         0.33333333 0.         0.33333333 0.         0.\n",
      " 0.         0.         0.         0.         0.33333333], Predicted Values: tensor([    0.0000,     0.4113,     0.0000,     0.5885,     0.0000,     0.0000,\n",
      "            0.0000,     0.0000,     0.0000,     0.0000,     0.0002],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 0., 0., 1., 1., 0., 0., 0., 0., 0.])\n",
      "tensor([[1., 0., 1., 1., 0., 0., 1., 1., 1., 1., 1.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1), Probabilities: [0.         0.44981622 0.         0.         0.10036756 0.44981622\n",
      " 0.         0.         0.         0.         0.        ], Predicted Values: tensor([0.0000, 0.9172, 0.0000, 0.0000, 0.0183, 0.0644, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 0., 0., 1., 0., 1., 0., 0., 0., 0.])\n",
      "tensor([[1., 0., 1., 1., 0., 1., 0., 1., 1., 1., 1.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1), Probabilities: [0.         0.78559703 0.         0.         0.17529039 0.\n",
      " 0.03911257 0.         0.         0.         0.        ], Predicted Values: tensor([0.0000, 0.9788, 0.0000, 0.0000, 0.0195, 0.0000, 0.0017, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 0., 0., 1., 0., 0., 1., 0., 0., 0.])\n",
      "tensor([[1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 1.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1), Probabilities: [0.         0.44981622 0.         0.         0.10036756 0.\n",
      " 0.         0.44981622 0.         0.         0.        ], Predicted Values: tensor([0.0000, 0.9738, 0.0000, 0.0000, 0.0194, 0.0000, 0.0000, 0.0067, 0.0000,\n",
      "        0.0000, 0.0000], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 0., 0., 1., 0., 0., 0., 1., 0., 0.])\n",
      "tensor([[1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 1.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1), Probabilities: [0.         0.44981622 0.         0.         0.10036756 0.\n",
      " 0.         0.         0.44981622 0.         0.        ], Predicted Values: tensor([0.0000, 0.9673, 0.0000, 0.0000, 0.0193, 0.0000, 0.0000, 0.0000, 0.0133,\n",
      "        0.0000, 0.0000], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 0., 0., 1., 0., 0., 0., 0., 1., 0.])\n",
      "tensor([[1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 1.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1), Probabilities: [0.         0.44981622 0.         0.         0.10036756 0.\n",
      " 0.         0.         0.         0.44981622 0.        ], Predicted Values: tensor([    0.0000,     0.9798,     0.0000,     0.0000,     0.0195,     0.0000,\n",
      "            0.0000,     0.0000,     0.0000,     0.0007,     0.0000],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 1.])\n",
      "tensor([[1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0), Probabilities: [0.         0.44981622 0.         0.         0.10036756 0.\n",
      " 0.         0.         0.         0.         0.44981622], Predicted Values: tensor([    0.0000,     0.9803,     0.0000,     0.0000,     0.0196,     0.0000,\n",
      "            0.0000,     0.0000,     0.0000,     0.0000,     0.0001],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 0., 0., 0., 1., 1., 0., 0., 0., 0.])\n",
      "tensor([[1., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1), Probabilities: [0.         0.33333333 0.         0.         0.         0.33333333\n",
      " 0.33333333 0.         0.         0.         0.        ], Predicted Values: tensor([0.0000, 0.9336, 0.0000, 0.0000, 0.0000, 0.0654, 0.0010, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 0., 0., 0., 1., 0., 1., 0., 0., 0.])\n",
      "tensor([[1., 0., 1., 1., 1., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1), Probabilities: [0.         0.48785555 0.         0.         0.         0.48785555\n",
      " 0.         0.0242889  0.         0.         0.        ], Predicted Values: tensor([0.0000, 0.9222, 0.0000, 0.0000, 0.0000, 0.0646, 0.0000, 0.0131, 0.0000,\n",
      "        0.0000, 0.0000], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 0., 0., 0., 1., 0., 0., 1., 0., 0.])\n",
      "tensor([[1., 0., 1., 1., 1., 0., 1., 1., 0., 1., 1.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1), Probabilities: [0.         0.33333333 0.         0.         0.         0.33333333\n",
      " 0.         0.         0.33333333 0.         0.        ], Predicted Values: tensor([0.0000, 0.9226, 0.0000, 0.0000, 0.0000, 0.0647, 0.0000, 0.0000, 0.0128,\n",
      "        0.0000, 0.0000], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 0., 0., 0., 1., 0., 0., 0., 1., 0.])\n",
      "tensor([[1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1), Probabilities: [0.         0.33333333 0.         0.         0.         0.33333333\n",
      " 0.         0.         0.         0.33333333 0.        ], Predicted Values: tensor([0.0000, 0.9336, 0.0000, 0.0000, 0.0000, 0.0654, 0.0000, 0.0000, 0.0000,\n",
      "        0.0009, 0.0000], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1.])\n",
      "tensor([[1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0), Probabilities: [0.         0.33333333 0.         0.         0.         0.33333333\n",
      " 0.         0.         0.         0.         0.33333333], Predicted Values: tensor([    0.0000,     0.9344,     0.0000,     0.0000,     0.0000,     0.0655,\n",
      "            0.0000,     0.0000,     0.0000,     0.0000,     0.0002],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 0., 0., 0., 0., 1., 1., 0., 0., 0.])\n",
      "tensor([[1., 0., 1., 1., 1., 1., 0., 0., 1., 1., 1.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1), Probabilities: [0.         0.33333333 0.         0.         0.         0.\n",
      " 0.33333333 0.33333333 0.         0.         0.        ], Predicted Values: tensor([0.0000, 0.9699, 0.0000, 0.0000, 0.0000, 0.0000, 0.0163, 0.0138, 0.0000,\n",
      "        0.0000, 0.0000], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 0., 0., 0., 0., 1., 0., 1., 0., 0.])\n",
      "tensor([[1., 0., 1., 1., 1., 1., 0., 1., 0., 1., 1.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1), Probabilities: [0.         0.44981622 0.         0.         0.         0.\n",
      " 0.44981622 0.         0.10036756 0.         0.        ], Predicted Values: tensor([0.0000, 0.9862, 0.0000, 0.0000, 0.0000, 0.0000, 0.0017, 0.0000, 0.0120,\n",
      "        0.0000, 0.0000], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 0., 0., 0., 0., 1., 0., 0., 1., 0.])\n",
      "tensor([[1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 1.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1), Probabilities: [0.         0.33333333 0.         0.         0.         0.\n",
      " 0.33333333 0.         0.         0.33333333 0.        ], Predicted Values: tensor([    0.0000,     0.9976,     0.0000,     0.0000,     0.0000,     0.0000,\n",
      "            0.0018,     0.0000,     0.0000,     0.0007,     0.0000],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 1.])\n",
      "tensor([[1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 0.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0), Probabilities: [0.         0.33333333 0.         0.         0.         0.\n",
      " 0.33333333 0.         0.         0.         0.33333333], Predicted Values: tensor([    0.0000,     0.9982,     0.0000,     0.0000,     0.0000,     0.0000,\n",
      "            0.0018,     0.0000,     0.0000,     0.0000,     0.0001],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 0., 0., 0., 0., 0., 1., 1., 0., 0.])\n",
      "tensor([[1., 0., 1., 1., 1., 1., 1., 0., 0., 1., 1.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1), Probabilities: [0.         0.44981622 0.         0.         0.         0.\n",
      " 0.         0.44981622 0.10036756 0.         0.        ], Predicted Values: tensor([0.0000, 0.9844, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0141, 0.0015,\n",
      "        0.0000, 0.0000], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 0., 0., 0., 0., 0., 1., 0., 1., 0.])\n",
      "tensor([[1., 0., 1., 1., 1., 1., 1., 0., 1., 0., 1.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1), Probabilities: [0.         0.33333333 0.         0.         0.         0.\n",
      " 0.         0.33333333 0.         0.33333333 0.        ], Predicted Values: tensor([    0.0000,     0.9852,     0.0000,     0.0000,     0.0000,     0.0000,\n",
      "            0.0000,     0.0141,     0.0000,     0.0007,     0.0000],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 1.])\n",
      "tensor([[1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 0.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0), Probabilities: [0.         0.33333333 0.         0.         0.         0.\n",
      " 0.         0.33333333 0.         0.         0.33333333], Predicted Values: tensor([    0.0000,     0.9857,     0.0000,     0.0000,     0.0000,     0.0000,\n",
      "            0.0000,     0.0142,     0.0000,     0.0000,     0.0001],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 0., 0., 0., 0., 0., 0., 1., 1., 0.])\n",
      "tensor([[1., 0., 1., 1., 1., 1., 1., 1., 0., 0., 1.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1), Probabilities: [0.         0.48785555 0.         0.         0.         0.\n",
      " 0.         0.         0.48785555 0.0242889  0.        ], Predicted Values: tensor([    0.0000,     0.9857,     0.0000,     0.0000,     0.0000,     0.0000,\n",
      "            0.0000,     0.0000,     0.0136,     0.0007,     0.0000],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 1.])\n",
      "tensor([[1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0), Probabilities: [0.         0.33333333 0.         0.         0.         0.\n",
      " 0.         0.         0.33333333 0.         0.33333333], Predicted Values: tensor([    0.0000,     0.9863,     0.0000,     0.0000,     0.0000,     0.0000,\n",
      "            0.0000,     0.0000,     0.0137,     0.0000,     0.0001],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 1.])\n",
      "tensor([[1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 0.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0), Probabilities: [0.         0.48785555 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.48785555 0.0242889 ], Predicted Values: tensor([    0.0000,     0.9992,     0.0000,     0.0000,     0.0000,     0.0000,\n",
      "            0.0000,     0.0000,     0.0000,     0.0007,     0.0001],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0.])\n",
      "tensor([[1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1), Probabilities: [0.         0.         0.44981622 0.44981622 0.10036756 0.\n",
      " 0.         0.         0.         0.         0.        ], Predicted Values: tensor([0.0000, 0.0000, 0.4710, 0.5208, 0.0082, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 1., 1., 0., 1., 0., 0., 0., 0., 0.])\n",
      "tensor([[1., 1., 0., 0., 1., 0., 1., 1., 1., 1., 1.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1), Probabilities: [0.         0.         0.48785555 0.48785555 0.         0.0242889\n",
      " 0.         0.         0.         0.         0.        ], Predicted Values: tensor([0.0000, 0.0000, 0.4681, 0.5180, 0.0000, 0.0139, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 1., 1., 0., 0., 1., 0., 0., 0., 0.])\n",
      "tensor([[1., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1), Probabilities: [0.         0.         0.33333333 0.33333333 0.         0.\n",
      " 0.33333333 0.         0.         0.         0.        ], Predicted Values: tensor([0.0000, 0.0000, 0.4743, 0.5250, 0.0000, 0.0000, 0.0007, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 1., 1., 0., 0., 0., 1., 0., 0., 0.])\n",
      "tensor([[1., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1), Probabilities: [0.         0.         0.33333333 0.33333333 0.         0.\n",
      " 0.         0.33333333 0.         0.         0.        ], Predicted Values: tensor([0.0000, 0.0000, 0.4721, 0.5219, 0.0000, 0.0000, 0.0000, 0.0059, 0.0000,\n",
      "        0.0000, 0.0000], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 1., 1., 0., 0., 0., 0., 1., 0., 0.])\n",
      "tensor([[1., 1., 0., 0., 1., 1., 1., 1., 0., 1., 1.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1), Probabilities: [0.         0.         0.33333333 0.33333333 0.         0.\n",
      " 0.         0.         0.33333333 0.         0.        ], Predicted Values: tensor([0.0000, 0.0000, 0.4638, 0.5133, 0.0000, 0.0000, 0.0000, 0.0000, 0.0229,\n",
      "        0.0000, 0.0000], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 1., 1., 0., 0., 0., 0., 0., 1., 0.])\n",
      "tensor([[1., 1., 0., 0., 1., 1., 1., 1., 1., 0., 1.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1), Probabilities: [0.         0.         0.33333333 0.33333333 0.         0.\n",
      " 0.         0.         0.         0.33333333 0.        ], Predicted Values: tensor([0.0000, 0.0000, 0.4744, 0.5244, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0012, 0.0000], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 1.])\n",
      "tensor([[1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0), Probabilities: [0.         0.         0.33333333 0.33333333 0.         0.\n",
      " 0.         0.         0.         0.         0.33333333], Predicted Values: tensor([    0.0000,     0.0000,     0.4748,     0.5250,     0.0000,     0.0000,\n",
      "            0.0000,     0.0000,     0.0000,     0.0000,     0.0002],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 1., 0., 1., 1., 0., 0., 0., 0., 0.])\n",
      "tensor([[1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1), Probabilities: [0.         0.         0.69143845 0.         0.15428077 0.15428077\n",
      " 0.         0.         0.         0.         0.        ], Predicted Values: tensor([0.0000, 0.0000, 0.9526, 0.0000, 0.0070, 0.0405, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 1., 0., 1., 0., 1., 0., 0., 0., 0.])\n",
      "tensor([[1., 1., 0., 1., 0., 1., 0., 1., 1., 1., 1.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1), Probabilities: [0.         0.         0.78559703 0.         0.17529039 0.\n",
      " 0.03911257 0.         0.         0.         0.        ], Predicted Values: tensor([    0.0000,     0.0000,     0.9921,     0.0000,     0.0072,     0.0000,\n",
      "            0.0006,     0.0000,     0.0000,     0.0000,     0.0000],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 1., 0., 1., 0., 0., 1., 0., 0., 0.])\n",
      "tensor([[1., 1., 0., 1., 0., 1., 1., 0., 1., 1., 1.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1), Probabilities: [0.         0.         0.44981622 0.         0.10036756 0.\n",
      " 0.         0.44981622 0.         0.         0.        ], Predicted Values: tensor([0.0000, 0.0000, 0.9903, 0.0000, 0.0072, 0.0000, 0.0000, 0.0025, 0.0000,\n",
      "        0.0000, 0.0000], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 1., 0., 1., 0., 0., 0., 1., 0., 0.])\n",
      "tensor([[1., 1., 0., 1., 0., 1., 1., 1., 0., 1., 1.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1), Probabilities: [0.         0.         0.44981622 0.         0.10036756 0.\n",
      " 0.         0.         0.44981622 0.         0.        ], Predicted Values: tensor([0.0000, 0.0000, 0.9808, 0.0000, 0.0072, 0.0000, 0.0000, 0.0000, 0.0120,\n",
      "        0.0000, 0.0000], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 1., 0., 1., 0., 0., 0., 0., 1., 0.])\n",
      "tensor([[1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1), Probabilities: [0.         0.         0.44981622 0.         0.10036756 0.\n",
      " 0.         0.         0.         0.44981622 0.        ], Predicted Values: tensor([    0.0000,     0.0000,     0.9925,     0.0000,     0.0072,     0.0000,\n",
      "            0.0000,     0.0000,     0.0000,     0.0002,     0.0000],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 1.])\n",
      "tensor([[1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 0.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0), Probabilities: [0.         0.         0.44981622 0.         0.10036756 0.\n",
      " 0.         0.         0.         0.         0.44981622], Predicted Values: tensor([    0.0000,     0.0000,     0.9927,     0.0000,     0.0072,     0.0000,\n",
      "            0.0000,     0.0000,     0.0000,     0.0000,     0.0001],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 1., 0., 0., 1., 1., 0., 0., 0., 0.])\n",
      "tensor([[1., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1), Probabilities: [0.         0.         0.44981622 0.         0.         0.10036756\n",
      " 0.44981622 0.         0.         0.         0.        ], Predicted Values: tensor([    0.0000,     0.0000,     0.9590,     0.0000,     0.0000,     0.0407,\n",
      "            0.0004,     0.0000,     0.0000,     0.0000,     0.0000],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 1., 0., 0., 1., 0., 1., 0., 0., 0.])\n",
      "tensor([[1., 1., 0., 1., 1., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1), Probabilities: [0.         0.         0.78559703 0.         0.         0.17529039\n",
      " 0.         0.03911257 0.         0.         0.        ], Predicted Values: tensor([0.0000, 0.0000, 0.9546, 0.0000, 0.0000, 0.0405, 0.0000, 0.0050, 0.0000,\n",
      "        0.0000, 0.0000], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 1., 0., 0., 1., 0., 0., 1., 0., 0.])\n",
      "tensor([[1., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1), Probabilities: [0.         0.         0.44981622 0.         0.         0.10036756\n",
      " 0.         0.         0.44981622 0.         0.        ], Predicted Values: tensor([0.0000, 0.0000, 0.9481, 0.0000, 0.0000, 0.0402, 0.0000, 0.0000, 0.0117,\n",
      "        0.0000, 0.0000], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 1., 0., 0., 1., 0., 0., 0., 1., 0.])\n",
      "tensor([[1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1), Probabilities: [0.         0.         0.44981622 0.         0.         0.10036756\n",
      " 0.         0.         0.         0.44981622 0.        ], Predicted Values: tensor([    0.0000,     0.0000,     0.9590,     0.0000,     0.0000,     0.0407,\n",
      "            0.0000,     0.0000,     0.0000,     0.0003,     0.0000],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 1.])\n",
      "tensor([[1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 0.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0), Probabilities: [0.         0.         0.44981622 0.         0.         0.10036756\n",
      " 0.         0.         0.         0.         0.44981622], Predicted Values: tensor([    0.0000,     0.0000,     0.9593,     0.0000,     0.0000,     0.0407,\n",
      "            0.0000,     0.0000,     0.0000,     0.0000,     0.0001],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0.])\n",
      "tensor([[1., 1., 0., 1., 1., 1., 0., 0., 1., 1., 1.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1), Probabilities: [0.         0.         0.33333333 0.         0.         0.\n",
      " 0.33333333 0.33333333 0.         0.         0.        ], Predicted Values: tensor([0.0000, 0.0000, 0.9888, 0.0000, 0.0000, 0.0000, 0.0061, 0.0051, 0.0000,\n",
      "        0.0000, 0.0000], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 1., 0., 0., 0., 1., 0., 1., 0., 0.])\n",
      "tensor([[1., 1., 0., 1., 1., 1., 0., 1., 0., 1., 1.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1), Probabilities: [0.         0.         0.44981622 0.         0.         0.\n",
      " 0.44981622 0.         0.10036756 0.         0.        ], Predicted Values: tensor([    0.0000,     0.0000,     0.9887,     0.0000,     0.0000,     0.0000,\n",
      "            0.0006,     0.0000,     0.0107,     0.0000,     0.0000],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 1., 0., 0., 0., 1., 0., 0., 1., 0.])\n",
      "tensor([[1., 1., 0., 1., 1., 1., 0., 1., 1., 0., 1.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1), Probabilities: [0.         0.         0.33333333 0.         0.         0.\n",
      " 0.33333333 0.         0.         0.33333333 0.        ], Predicted Values: tensor([    0.0000,     0.0000,     0.9991,     0.0000,     0.0000,     0.0000,\n",
      "            0.0006,     0.0000,     0.0000,     0.0002,     0.0000],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 1.])\n",
      "tensor([[1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 0.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0), Probabilities: [0.         0.         0.33333333 0.         0.         0.\n",
      " 0.33333333 0.         0.         0.         0.33333333], Predicted Values: tensor([    0.0000,     0.0000,     0.9993,     0.0000,     0.0000,     0.0000,\n",
      "            0.0006,     0.0000,     0.0000,     0.0000,     0.0000],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 0.])\n",
      "tensor([[1., 1., 0., 1., 1., 1., 1., 0., 0., 1., 1.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1), Probabilities: [0.         0.         0.44981622 0.         0.         0.\n",
      " 0.         0.44981622 0.10036756 0.         0.        ], Predicted Values: tensor([0.0000, 0.0000, 0.9935, 0.0000, 0.0000, 0.0000, 0.0000, 0.0052, 0.0013,\n",
      "        0.0000, 0.0000], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 1., 0., 0., 0., 0., 1., 0., 1., 0.])\n",
      "tensor([[1., 1., 0., 1., 1., 1., 1., 0., 1., 0., 1.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1), Probabilities: [0.         0.         0.33333333 0.         0.         0.\n",
      " 0.         0.33333333 0.         0.33333333 0.        ], Predicted Values: tensor([    0.0000,     0.0000,     0.9946,     0.0000,     0.0000,     0.0000,\n",
      "            0.0000,     0.0052,     0.0000,     0.0002,     0.0000],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 1.])\n",
      "tensor([[1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0), Probabilities: [0.         0.         0.33333333 0.         0.         0.\n",
      " 0.         0.33333333 0.         0.         0.33333333], Predicted Values: tensor([    0.0000,     0.0000,     0.9947,     0.0000,     0.0000,     0.0000,\n",
      "            0.0000,     0.0052,     0.0000,     0.0000,     0.0001],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 1., 0., 0., 0., 0., 0., 1., 1., 0.])\n",
      "tensor([[1., 1., 0., 1., 1., 1., 1., 1., 0., 0., 1.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1), Probabilities: [0.         0.         0.48785555 0.         0.         0.\n",
      " 0.         0.         0.48785555 0.0242889  0.        ], Predicted Values: tensor([    0.0000,     0.0000,     0.9877,     0.0000,     0.0000,     0.0000,\n",
      "            0.0000,     0.0000,     0.0121,     0.0002,     0.0000],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 1.])\n",
      "tensor([[1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0), Probabilities: [0.         0.         0.33333333 0.         0.         0.\n",
      " 0.         0.         0.33333333 0.         0.33333333], Predicted Values: tensor([    0.0000,     0.0000,     0.9878,     0.0000,     0.0000,     0.0000,\n",
      "            0.0000,     0.0000,     0.0121,     0.0000,     0.0000],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 1.])\n",
      "tensor([[1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 0.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0), Probabilities: [0.         0.         0.48785555 0.         0.         0.\n",
      " 0.         0.         0.         0.48785555 0.0242889 ], Predicted Values: tensor([    0.0000,     0.0000,     0.9997,     0.0000,     0.0000,     0.0000,\n",
      "            0.0000,     0.0000,     0.0000,     0.0002,     0.0000],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 0., 1., 1., 1., 0., 0., 0., 0., 0.])\n",
      "tensor([[1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1), Probabilities: [0.         0.         0.         0.44981622 0.44981622 0.10036756\n",
      " 0.         0.         0.         0.         0.        ], Predicted Values: tensor([0.0000, 0.0000, 0.0000, 0.9718, 0.0098, 0.0183, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 0., 1., 1., 0., 1., 0., 0., 0., 0.])\n",
      "tensor([[1., 1., 1., 0., 0., 1., 0., 1., 1., 1., 1.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1), Probabilities: [0.         0.         0.         0.48785555 0.48785555 0.\n",
      " 0.0242889  0.         0.         0.         0.        ], Predicted Values: tensor([    0.0000,     0.0000,     0.0000,     0.9891,     0.0100,     0.0000,\n",
      "            0.0009,     0.0000,     0.0000,     0.0000,     0.0000],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 0., 1., 1., 0., 0., 1., 0., 0., 0.])\n",
      "tensor([[1., 1., 1., 0., 0., 1., 1., 0., 1., 1., 1.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1), Probabilities: [0.         0.         0.         0.33333333 0.33333333 0.\n",
      " 0.         0.33333333 0.         0.         0.        ], Predicted Values: tensor([0.0000, 0.0000, 0.0000, 0.9866, 0.0100, 0.0000, 0.0000, 0.0035, 0.0000,\n",
      "        0.0000, 0.0000], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 0., 1., 1., 0., 0., 0., 1., 0., 0.])\n",
      "tensor([[1., 1., 1., 0., 0., 1., 1., 1., 0., 1., 1.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1), Probabilities: [0.         0.         0.         0.33333333 0.33333333 0.\n",
      " 0.         0.         0.33333333 0.         0.        ], Predicted Values: tensor([0.0000, 0.0000, 0.0000, 0.9811, 0.0099, 0.0000, 0.0000, 0.0000, 0.0090,\n",
      "        0.0000, 0.0000], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 0., 1., 1., 0., 0., 0., 0., 1., 0.])\n",
      "tensor([[1., 1., 1., 0., 0., 1., 1., 1., 1., 0., 1.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1), Probabilities: [0.         0.         0.         0.33333333 0.33333333 0.\n",
      " 0.         0.         0.         0.33333333 0.        ], Predicted Values: tensor([    0.0000,     0.0000,     0.0000,     0.9895,     0.0100,     0.0000,\n",
      "            0.0000,     0.0000,     0.0000,     0.0005,     0.0000],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.])\n",
      "tensor([[1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 0.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0), Probabilities: [0.         0.         0.         0.33333333 0.33333333 0.\n",
      " 0.         0.         0.         0.         0.33333333], Predicted Values: tensor([    0.0000,     0.0000,     0.0000,     0.9898,     0.0100,     0.0000,\n",
      "            0.0000,     0.0000,     0.0000,     0.0000,     0.0002],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 0., 1., 0., 1., 1., 0., 0., 0., 0.])\n",
      "tensor([[1., 1., 1., 0., 1., 0., 0., 1., 1., 1., 1.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1), Probabilities: [0.         0.         0.         0.44981622 0.         0.10036756\n",
      " 0.44981622 0.         0.         0.         0.        ], Predicted Values: tensor([    0.0000,     0.0000,     0.0000,     0.9810,     0.0000,     0.0184,\n",
      "            0.0005,     0.0000,     0.0000,     0.0000,     0.0000],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 0., 1., 0., 1., 0., 1., 0., 0., 0.])\n",
      "tensor([[1., 1., 1., 0., 1., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1), Probabilities: [0.         0.         0.         0.78559703 0.         0.17529039\n",
      " 0.         0.03911257 0.         0.         0.        ], Predicted Values: tensor([0.0000, 0.0000, 0.0000, 0.9746, 0.0000, 0.0183, 0.0000, 0.0071, 0.0000,\n",
      "        0.0000, 0.0000], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 0., 1., 0., 1., 0., 0., 1., 0., 0.])\n",
      "tensor([[1., 1., 1., 0., 1., 0., 1., 1., 0., 1., 1.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1), Probabilities: [0.         0.         0.         0.44981622 0.         0.10036756\n",
      " 0.         0.         0.44981622 0.         0.        ], Predicted Values: tensor([0.0000, 0.0000, 0.0000, 0.9728, 0.0000, 0.0183, 0.0000, 0.0000, 0.0089,\n",
      "        0.0000, 0.0000], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 0., 1., 0., 1., 0., 0., 0., 1., 0.])\n",
      "tensor([[1., 1., 1., 0., 1., 0., 1., 1., 1., 0., 1.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1), Probabilities: [0.         0.         0.         0.44981622 0.         0.10036756\n",
      " 0.         0.         0.         0.44981622 0.        ], Predicted Values: tensor([    0.0000,     0.0000,     0.0000,     0.9808,     0.0000,     0.0185,\n",
      "            0.0000,     0.0000,     0.0000,     0.0008,     0.0000],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1.])\n",
      "tensor([[1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 0.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0), Probabilities: [0.         0.         0.         0.44981622 0.         0.10036756\n",
      " 0.         0.         0.         0.         0.44981622], Predicted Values: tensor([    0.0000,     0.0000,     0.0000,     0.9814,     0.0000,     0.0184,\n",
      "            0.0000,     0.0000,     0.0000,     0.0000,     0.0002],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 0., 1., 0., 0., 1., 1., 0., 0., 0.])\n",
      "tensor([[1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1), Probabilities: [0.         0.         0.         0.33333333 0.         0.\n",
      " 0.33333333 0.33333333 0.         0.         0.        ], Predicted Values: tensor([0.0000, 0.0000, 0.0000, 0.9845, 0.0000, 0.0000, 0.0083, 0.0071, 0.0000,\n",
      "        0.0000, 0.0000], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 0., 1., 0., 0., 1., 0., 1., 0., 0.])\n",
      "tensor([[1., 1., 1., 0., 1., 1., 0., 1., 0., 1., 1.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1), Probabilities: [0.         0.         0.         0.44981622 0.         0.\n",
      " 0.44981622 0.         0.10036756 0.         0.        ], Predicted Values: tensor([    0.0000,     0.0000,     0.0000,     0.9911,     0.0000,     0.0000,\n",
      "            0.0009,     0.0000,     0.0080,     0.0000,     0.0000],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 0., 1., 0., 0., 1., 0., 0., 1., 0.])\n",
      "tensor([[1., 1., 1., 0., 1., 1., 0., 1., 1., 0., 1.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1), Probabilities: [0.         0.         0.         0.33333333 0.         0.\n",
      " 0.33333333 0.         0.         0.33333333 0.        ], Predicted Values: tensor([    0.0000,     0.0000,     0.0000,     0.9986,     0.0000,     0.0000,\n",
      "            0.0009,     0.0000,     0.0000,     0.0005,     0.0000],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 1.])\n",
      "tensor([[1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0), Probabilities: [0.         0.         0.         0.33333333 0.         0.\n",
      " 0.33333333 0.         0.         0.         0.33333333], Predicted Values: tensor([    0.0000,     0.0000,     0.0000,     0.9990,     0.0000,     0.0000,\n",
      "            0.0009,     0.0000,     0.0000,     0.0000,     0.0001],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0.])\n",
      "tensor([[1., 1., 1., 0., 1., 1., 1., 0., 0., 1., 1.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1), Probabilities: [0.         0.         0.         0.44981622 0.         0.\n",
      " 0.         0.44981622 0.10036756 0.         0.        ], Predicted Values: tensor([    0.0000,     0.0000,     0.0000,     0.9918,     0.0000,     0.0000,\n",
      "            0.0000,     0.0072,     0.0010,     0.0000,     0.0000],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 0., 1., 0., 0., 0., 1., 0., 1., 0.])\n",
      "tensor([[1., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1), Probabilities: [0.         0.         0.         0.33333333 0.         0.\n",
      " 0.         0.33333333 0.         0.33333333 0.        ], Predicted Values: tensor([    0.0000,     0.0000,     0.0000,     0.9922,     0.0000,     0.0000,\n",
      "            0.0000,     0.0072,     0.0000,     0.0005,     0.0000],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 1.])\n",
      "tensor([[1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 0.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0), Probabilities: [0.         0.         0.         0.33333333 0.         0.\n",
      " 0.         0.33333333 0.         0.         0.33333333], Predicted Values: tensor([    0.0000,     0.0000,     0.0000,     0.9926,     0.0000,     0.0000,\n",
      "            0.0000,     0.0072,     0.0000,     0.0000,     0.0001],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0.])\n",
      "tensor([[1., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1), Probabilities: [0.         0.         0.         0.48785555 0.         0.\n",
      " 0.         0.         0.48785555 0.0242889  0.        ], Predicted Values: tensor([    0.0000,     0.0000,     0.0000,     0.9904,     0.0000,     0.0000,\n",
      "            0.0000,     0.0000,     0.0091,     0.0005,     0.0000],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 1.])\n",
      "tensor([[1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 0.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0), Probabilities: [0.         0.         0.         0.33333333 0.         0.\n",
      " 0.         0.         0.33333333 0.         0.33333333], Predicted Values: tensor([    0.0000,     0.0000,     0.0000,     0.9908,     0.0000,     0.0000,\n",
      "            0.0000,     0.0000,     0.0091,     0.0000,     0.0001],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 1.])\n",
      "tensor([[1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 0.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0), Probabilities: [0.         0.         0.         0.48785555 0.         0.\n",
      " 0.         0.         0.         0.48785555 0.0242889 ], Predicted Values: tensor([    0.0000,     0.0000,     0.0000,     0.9994,     0.0000,     0.0000,\n",
      "            0.0000,     0.0000,     0.0000,     0.0005,     0.0001],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 0., 0., 1., 1., 1., 0., 0., 0., 0.])\n",
      "tensor([[1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1), Probabilities: [0.         0.         0.         0.         0.48785555 0.48785555\n",
      " 0.0242889  0.         0.         0.         0.        ], Predicted Values: tensor([0.0000, 0.0000, 0.0000, 0.0000, 0.1347, 0.8580, 0.0073, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 0., 0., 1., 1., 0., 1., 0., 0., 0.])\n",
      "tensor([[1., 1., 1., 1., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1), Probabilities: [0.         0.         0.         0.         0.48785555 0.48785555\n",
      " 0.         0.0242889  0.         0.         0.        ], Predicted Values: tensor([0.0000, 0.0000, 0.0000, 0.0000, 0.1298, 0.8257, 0.0000, 0.0445, 0.0000,\n",
      "        0.0000, 0.0000], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 0., 0., 1., 1., 0., 0., 1., 0., 0.])\n",
      "tensor([[1., 1., 1., 1., 0., 0., 1., 1., 0., 1., 1.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1), Probabilities: [0.         0.         0.         0.         0.33333333 0.33333333\n",
      " 0.         0.         0.33333333 0.         0.        ], Predicted Values: tensor([0.0000, 0.0000, 0.0000, 0.0000, 0.1266, 0.8055, 0.0000, 0.0000, 0.0679,\n",
      "        0.0000, 0.0000], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 0., 0., 1., 1., 0., 0., 0., 1., 0.])\n",
      "tensor([[1., 1., 1., 1., 0., 0., 1., 1., 1., 0., 1.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1), Probabilities: [0.         0.         0.         0.         0.33333333 0.33333333\n",
      " 0.         0.         0.         0.33333333 0.        ], Predicted Values: tensor([0.0000, 0.0000, 0.0000, 0.0000, 0.1354, 0.8622, 0.0000, 0.0000, 0.0000,\n",
      "        0.0024, 0.0000], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 1.])\n",
      "tensor([[1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0), Probabilities: [0.         0.         0.         0.         0.33333333 0.33333333\n",
      " 0.         0.         0.         0.         0.33333333], Predicted Values: tensor([    0.0000,     0.0000,     0.0000,     0.0000,     0.1360,     0.8632,\n",
      "            0.0000,     0.0000,     0.0000,     0.0000,     0.0009],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 0., 0., 1., 0., 1., 1., 0., 0., 0.])\n",
      "tensor([[1., 1., 1., 1., 0., 1., 0., 0., 1., 1., 1.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1), Probabilities: [0.         0.         0.         0.         0.48785555 0.\n",
      " 0.0242889  0.48785555 0.         0.         0.        ], Predicted Values: tensor([0.0000, 0.0000, 0.0000, 0.0000, 0.4570, 0.0000, 0.3859, 0.1571, 0.0000,\n",
      "        0.0000, 0.0000], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 0., 0., 1., 0., 1., 0., 1., 0., 0.])\n",
      "tensor([[1., 1., 1., 1., 0., 1., 0., 1., 0., 1., 1.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1), Probabilities: [0.         0.         0.         0.         0.78559703 0.\n",
      " 0.03911257 0.         0.17529039 0.         0.        ], Predicted Values: tensor([0.0000, 0.0000, 0.0000, 0.0000, 0.6402, 0.0000, 0.0567, 0.0000, 0.3031,\n",
      "        0.0000, 0.0000], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 0., 0., 1., 0., 1., 0., 0., 1., 0.])\n",
      "tensor([[1., 1., 1., 1., 0., 1., 0., 1., 1., 0., 1.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1), Probabilities: [0.         0.         0.         0.         0.48785555 0.\n",
      " 0.0242889  0.         0.         0.48785555 0.        ], Predicted Values: tensor([0.0000, 0.0000, 0.0000, 0.0000, 0.9088, 0.0000, 0.0805, 0.0000, 0.0000,\n",
      "        0.0108, 0.0000], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 1.])\n",
      "tensor([[1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 0.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0), Probabilities: [0.         0.         0.         0.         0.48785555 0.\n",
      " 0.0242889  0.         0.         0.         0.48785555], Predicted Values: tensor([0.0000, 0.0000, 0.0000, 0.0000, 0.9162, 0.0000, 0.0809, 0.0000, 0.0000,\n",
      "        0.0000, 0.0029], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 0., 0., 1., 0., 0., 1., 1., 0., 0.])\n",
      "tensor([[1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1), Probabilities: [0.         0.         0.         0.         0.44981622 0.\n",
      " 0.         0.44981622 0.10036756 0.         0.        ], Predicted Values: tensor([0.0000, 0.0000, 0.0000, 0.0000, 0.7123, 0.0000, 0.0000, 0.2461, 0.0416,\n",
      "        0.0000, 0.0000], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 0., 0., 1., 0., 0., 1., 0., 1., 0.])\n",
      "tensor([[1., 1., 1., 1., 0., 1., 1., 0., 1., 0., 1.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1), Probabilities: [0.         0.         0.         0.         0.33333333 0.\n",
      " 0.         0.33333333 0.         0.33333333 0.        ], Predicted Values: tensor([0.0000, 0.0000, 0.0000, 0.0000, 0.7367, 0.0000, 0.0000, 0.2546, 0.0000,\n",
      "        0.0087, 0.0000], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 1.])\n",
      "tensor([[1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 0.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0), Probabilities: [0.         0.         0.         0.         0.33333333 0.\n",
      " 0.         0.33333333 0.         0.         0.33333333], Predicted Values: tensor([0.0000, 0.0000, 0.0000, 0.0000, 0.7408, 0.0000, 0.0000, 0.2558, 0.0000,\n",
      "        0.0000, 0.0034], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0.])\n",
      "tensor([[1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1), Probabilities: [0.         0.         0.         0.         0.48785555 0.\n",
      " 0.         0.         0.48785555 0.0242889  0.        ], Predicted Values: tensor([0.0000, 0.0000, 0.0000, 0.0000, 0.6460, 0.0000, 0.0000, 0.0000, 0.3464,\n",
      "        0.0076, 0.0000], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 1.])\n",
      "tensor([[1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 0.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0), Probabilities: [0.         0.         0.         0.         0.33333333 0.\n",
      " 0.         0.         0.33333333 0.         0.33333333], Predicted Values: tensor([0.0000, 0.0000, 0.0000, 0.0000, 0.6496, 0.0000, 0.0000, 0.0000, 0.3485,\n",
      "        0.0000, 0.0019], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1.])\n",
      "tensor([[1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 0.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0), Probabilities: [0.         0.         0.         0.         0.48785555 0.\n",
      " 0.         0.         0.         0.48785555 0.0242889 ], Predicted Values: tensor([0.0000, 0.0000, 0.0000, 0.0000, 0.9855, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0116, 0.0029], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 0., 0., 0., 1., 1., 1., 0., 0., 0.])\n",
      "tensor([[1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1), Probabilities: [0.         0.         0.         0.         0.         0.48785555\n",
      " 0.48785555 0.0242889  0.         0.         0.        ], Predicted Values: tensor([0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.8385, 0.0681, 0.0934, 0.0000,\n",
      "        0.0000, 0.0000], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 0., 0., 0., 1., 1., 0., 1., 0., 0.])\n",
      "tensor([[1., 1., 1., 1., 1., 0., 0., 1., 0., 1., 1.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1), Probabilities: [0.         0.         0.         0.         0.         0.44981622\n",
      " 0.44981622 0.         0.10036756 0.         0.        ], Predicted Values: tensor([0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.9232, 0.0079, 0.0000, 0.0689,\n",
      "        0.0000, 0.0000], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 0., 0., 0., 1., 1., 0., 0., 1., 0.])\n",
      "tensor([[1., 1., 1., 1., 1., 0., 0., 1., 1., 0., 1.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1), Probabilities: [0.         0.         0.         0.         0.         0.33333333\n",
      " 0.33333333 0.         0.         0.33333333 0.        ], Predicted Values: tensor([0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.9889, 0.0084, 0.0000, 0.0000,\n",
      "        0.0027, 0.0000], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 1.])\n",
      "tensor([[1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 0.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0), Probabilities: [0.         0.         0.         0.         0.         0.33333333\n",
      " 0.33333333 0.         0.         0.         0.33333333], Predicted Values: tensor([    0.0000,     0.0000,     0.0000,     0.0000,     0.0000,     0.9910,\n",
      "            0.0084,     0.0000,     0.0000,     0.0000,     0.0006],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 0., 0., 0., 1., 0., 1., 1., 0., 0.])\n",
      "tensor([[1., 1., 1., 1., 1., 0., 1., 0., 0., 1., 1.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1), Probabilities: [0.         0.         0.         0.         0.         0.78559703\n",
      " 0.         0.03911257 0.17529039 0.         0.        ], Predicted Values: tensor([0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.8917, 0.0000, 0.1001, 0.0082,\n",
      "        0.0000, 0.0000], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 0.])\n",
      "tensor([[1., 1., 1., 1., 1., 0., 1., 0., 1., 0., 1.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1), Probabilities: [0.         0.         0.         0.         0.         0.48785555\n",
      " 0.         0.0242889  0.         0.48785555 0.        ], Predicted Values: tensor([0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.8970, 0.0000, 0.1006, 0.0000,\n",
      "        0.0025, 0.0000], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 1.])\n",
      "tensor([[1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 0.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0), Probabilities: [0.         0.         0.         0.         0.         0.48785555\n",
      " 0.         0.0242889  0.         0.         0.48785555], Predicted Values: tensor([    0.0000,     0.0000,     0.0000,     0.0000,     0.0000,     0.8984,\n",
      "            0.0000,     0.1009,     0.0000,     0.0000,     0.0007],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 0., 0., 0., 1., 0., 0., 1., 1., 0.])\n",
      "tensor([[1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1), Probabilities: [0.         0.         0.         0.         0.         0.48785555\n",
      " 0.         0.         0.48785555 0.0242889  0.        ], Predicted Values: tensor([0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.9197, 0.0000, 0.0000, 0.0778,\n",
      "        0.0025, 0.0000], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 1.])\n",
      "tensor([[1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 0.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0), Probabilities: [0.         0.         0.         0.         0.         0.33333333\n",
      " 0.         0.         0.33333333 0.         0.33333333], Predicted Values: tensor([    0.0000,     0.0000,     0.0000,     0.0000,     0.0000,     0.9213,\n",
      "            0.0000,     0.0000,     0.0782,     0.0000,     0.0005],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1.])\n",
      "tensor([[1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0), Probabilities: [0.         0.         0.         0.         0.         0.48785555\n",
      " 0.         0.         0.         0.48785555 0.0242889 ], Predicted Values: tensor([    0.0000,     0.0000,     0.0000,     0.0000,     0.0000,     0.9967,\n",
      "            0.0000,     0.0000,     0.0000,     0.0027,     0.0005],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 0., 0., 0., 0., 1., 1., 1., 0., 0.])\n",
      "tensor([[1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1), Probabilities: [0.         0.         0.         0.         0.         0.\n",
      " 0.48785555 0.48785555 0.0242889  0.         0.        ], Predicted Values: tensor([0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.5240, 0.4439, 0.0322,\n",
      "        0.0000, 0.0000], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 0., 0., 0., 0., 1., 1., 0., 1., 0.])\n",
      "tensor([[1., 1., 1., 1., 1., 1., 0., 0., 1., 0., 1.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1), Probabilities: [0.         0.         0.         0.         0.         0.\n",
      " 0.33333333 0.33333333 0.         0.33333333 0.        ], Predicted Values: tensor([0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.5371, 0.4554, 0.0000,\n",
      "        0.0075, 0.0000], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 1.])\n",
      "tensor([[1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 0.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0), Probabilities: [0.         0.         0.         0.         0.         0.\n",
      " 0.33333333 0.33333333 0.         0.         0.33333333], Predicted Values: tensor([0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.5398, 0.4585, 0.0000,\n",
      "        0.0000, 0.0017], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 0., 0., 0., 0., 1., 0., 1., 1., 0.])\n",
      "tensor([[1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 1.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1), Probabilities: [0.         0.         0.         0.         0.         0.\n",
      " 0.78559703 0.         0.17529039 0.03911257 0.        ], Predicted Values: tensor([0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1537, 0.0000, 0.8257,\n",
      "        0.0205, 0.0000], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1.])\n",
      "tensor([[1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 0.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0), Probabilities: [0.         0.         0.         0.         0.         0.\n",
      " 0.44981622 0.         0.10036756 0.         0.44981622], Predicted Values: tensor([0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1561, 0.0000, 0.8409,\n",
      "        0.0000, 0.0030], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 1.])\n",
      "tensor([[1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0), Probabilities: [0.         0.         0.         0.         0.         0.\n",
      " 0.48785555 0.         0.         0.48785555 0.0242889 ], Predicted Values: tensor([0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.8671, 0.0000, 0.0000,\n",
      "        0.1163, 0.0166], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 0.])\n",
      "tensor([[1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1), Probabilities: [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.78559703 0.17529039 0.03911257 0.        ], Predicted Values: tensor([0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.9107, 0.0743,\n",
      "        0.0150, 0.0000], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 1.])\n",
      "tensor([[1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 0.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0), Probabilities: [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.44981622 0.10036756 0.         0.44981622], Predicted Values: tensor([0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.9216, 0.0753,\n",
      "        0.0000, 0.0031], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 1.])\n",
      "tensor([[1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0), Probabilities: [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.48785555 0.         0.48785555 0.0242889 ], Predicted Values: tensor([0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.9806, 0.0000,\n",
      "        0.0161, 0.0033], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1.])\n",
      "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0), Probabilities: [0.        0.        0.        0.        0.        0.        0.\n",
      " 0.        0.909443  0.0452785 0.0452785], Predicted Values: tensor([0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.9758,\n",
      "        0.0213, 0.0028], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "tensor([[1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1), Probabilities: [0.  0.5 0.5 0.  0.  0.  0.  0.  0.  0.  0. ], Predicted Values: tensor([0.0000, 0.1602, 0.8398, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0.])\n",
      "tensor([[1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1), Probabilities: [0.  0.5 0.  0.5 0.  0.  0.  0.  0.  0.  0. ], Predicted Values: tensor([0.0000, 0.4116, 0.0000, 0.5884, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0.])\n",
      "tensor([[1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1), Probabilities: [0.         0.81757448 0.         0.         0.18242552 0.\n",
      " 0.         0.         0.         0.         0.        ], Predicted Values: tensor([0.0000, 0.9804, 0.0000, 0.0000, 0.0196, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0.])\n",
      "tensor([[1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1), Probabilities: [0.  0.5 0.  0.  0.  0.5 0.  0.  0.  0.  0. ], Predicted Values: tensor([0.0000, 0.9345, 0.0000, 0.0000, 0.0000, 0.0655, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0.])\n",
      "tensor([[1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1), Probabilities: [0.  0.5 0.  0.  0.  0.  0.5 0.  0.  0.  0. ], Predicted Values: tensor([0.0000, 0.9982, 0.0000, 0.0000, 0.0000, 0.0000, 0.0018, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0.])\n",
      "tensor([[1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1), Probabilities: [0.  0.5 0.  0.  0.  0.  0.  0.5 0.  0.  0. ], Predicted Values: tensor([0.0000, 0.9859, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0141, 0.0000,\n",
      "        0.0000, 0.0000], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0.])\n",
      "tensor([[1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1), Probabilities: [0.  0.5 0.  0.  0.  0.  0.  0.  0.5 0.  0. ], Predicted Values: tensor([0.0000, 0.9864, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0136,\n",
      "        0.0000, 0.0000], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0.])\n",
      "tensor([[1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1), Probabilities: [0.  0.5 0.  0.  0.  0.  0.  0.  0.  0.5 0. ], Predicted Values: tensor([    0.0000,     0.9993,     0.0000,     0.0000,     0.0000,     0.0000,\n",
      "            0.0000,     0.0000,     0.0000,     0.0007,     0.0000],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1.])\n",
      "tensor([[1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0), Probabilities: [0.  0.5 0.  0.  0.  0.  0.  0.  0.  0.  0.5], Predicted Values: tensor([    0.0000,     0.9999,     0.0000,     0.0000,     0.0000,     0.0000,\n",
      "            0.0000,     0.0000,     0.0000,     0.0000,     0.0001],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0.])\n",
      "tensor([[1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1), Probabilities: [0.  0.  0.5 0.5 0.  0.  0.  0.  0.  0.  0. ], Predicted Values: tensor([0.0000, 0.0000, 0.4749, 0.5251, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0.])\n",
      "tensor([[1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1), Probabilities: [0.         0.         0.81757448 0.         0.18242552 0.\n",
      " 0.         0.         0.         0.         0.        ], Predicted Values: tensor([0.0000, 0.0000, 0.9928, 0.0000, 0.0072, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0.])\n",
      "tensor([[1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1), Probabilities: [0.         0.         0.81757448 0.         0.         0.18242552\n",
      " 0.         0.         0.         0.         0.        ], Predicted Values: tensor([0.0000, 0.0000, 0.9593, 0.0000, 0.0000, 0.0407, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0.])\n",
      "tensor([[1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1), Probabilities: [0.  0.  0.5 0.  0.  0.  0.5 0.  0.  0.  0. ], Predicted Values: tensor([    0.0000,     0.0000,     0.9994,     0.0000,     0.0000,     0.0000,\n",
      "            0.0006,     0.0000,     0.0000,     0.0000,     0.0000],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0.])\n",
      "tensor([[1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1), Probabilities: [0.  0.  0.5 0.  0.  0.  0.  0.5 0.  0.  0. ], Predicted Values: tensor([0.0000, 0.0000, 0.9948, 0.0000, 0.0000, 0.0000, 0.0000, 0.0052, 0.0000,\n",
      "        0.0000, 0.0000], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0.])\n",
      "tensor([[1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1), Probabilities: [0.  0.  0.5 0.  0.  0.  0.  0.  0.5 0.  0. ], Predicted Values: tensor([0.0000, 0.0000, 0.9879, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0121,\n",
      "        0.0000, 0.0000], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0.])\n",
      "tensor([[1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1), Probabilities: [0.  0.  0.5 0.  0.  0.  0.  0.  0.  0.5 0. ], Predicted Values: tensor([    0.0000,     0.0000,     0.9998,     0.0000,     0.0000,     0.0000,\n",
      "            0.0000,     0.0000,     0.0000,     0.0002,     0.0000],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1.])\n",
      "tensor([[1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0), Probabilities: [0.  0.  0.5 0.  0.  0.  0.  0.  0.  0.  0.5], Predicted Values: tensor([    0.0000,     0.0000,     1.0000,     0.0000,     0.0000,     0.0000,\n",
      "            0.0000,     0.0000,     0.0000,     0.0000,     0.0000],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0.])\n",
      "tensor([[1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1), Probabilities: [0.  0.  0.  0.5 0.5 0.  0.  0.  0.  0.  0. ], Predicted Values: tensor([0.0000, 0.0000, 0.0000, 0.9900, 0.0100, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0.])\n",
      "tensor([[1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1), Probabilities: [0.         0.         0.         0.81757448 0.         0.18242552\n",
      " 0.         0.         0.         0.         0.        ], Predicted Values: tensor([0.0000, 0.0000, 0.0000, 0.9815, 0.0000, 0.0185, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0.])\n",
      "tensor([[1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1), Probabilities: [0.  0.  0.  0.5 0.  0.  0.5 0.  0.  0.  0. ], Predicted Values: tensor([    0.0000,     0.0000,     0.0000,     0.9991,     0.0000,     0.0000,\n",
      "            0.0009,     0.0000,     0.0000,     0.0000,     0.0000],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0.])\n",
      "tensor([[1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1), Probabilities: [0.  0.  0.  0.5 0.  0.  0.  0.5 0.  0.  0. ], Predicted Values: tensor([0.0000, 0.0000, 0.0000, 0.9928, 0.0000, 0.0000, 0.0000, 0.0072, 0.0000,\n",
      "        0.0000, 0.0000], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0.])\n",
      "tensor([[1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1), Probabilities: [0.  0.  0.  0.5 0.  0.  0.  0.  0.5 0.  0. ], Predicted Values: tensor([0.0000, 0.0000, 0.0000, 0.9909, 0.0000, 0.0000, 0.0000, 0.0000, 0.0091,\n",
      "        0.0000, 0.0000], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0.])\n",
      "tensor([[1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1), Probabilities: [0.  0.  0.  0.5 0.  0.  0.  0.  0.  0.5 0. ], Predicted Values: tensor([    0.0000,     0.0000,     0.0000,     0.9995,     0.0000,     0.0000,\n",
      "            0.0000,     0.0000,     0.0000,     0.0005,     0.0000],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1.])\n",
      "tensor([[1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0), Probabilities: [0.  0.  0.  0.5 0.  0.  0.  0.  0.  0.  0.5], Predicted Values: tensor([    0.0000,     0.0000,     0.0000,     0.9999,     0.0000,     0.0000,\n",
      "            0.0000,     0.0000,     0.0000,     0.0000,     0.0001],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0.])\n",
      "tensor([[1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1), Probabilities: [0.  0.  0.  0.  0.5 0.5 0.  0.  0.  0.  0. ], Predicted Values: tensor([0.0000, 0.0000, 0.0000, 0.0000, 0.1357, 0.8643, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0.])\n",
      "tensor([[1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1), Probabilities: [0.         0.         0.         0.         0.95257413 0.\n",
      " 0.04742587 0.         0.         0.         0.        ], Predicted Values: tensor([0.0000, 0.0000, 0.0000, 0.0000, 0.9187, 0.0000, 0.0813, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0.])\n",
      "tensor([[1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1), Probabilities: [0.  0.  0.  0.  0.5 0.  0.  0.5 0.  0.  0. ], Predicted Values: tensor([0.0000, 0.0000, 0.0000, 0.0000, 0.7432, 0.0000, 0.0000, 0.2568, 0.0000,\n",
      "        0.0000, 0.0000], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0.])\n",
      "tensor([[1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1), Probabilities: [0.  0.  0.  0.  0.5 0.  0.  0.  0.5 0.  0. ], Predicted Values: tensor([0.0000, 0.0000, 0.0000, 0.0000, 0.6506, 0.0000, 0.0000, 0.0000, 0.3494,\n",
      "        0.0000, 0.0000], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0.])\n",
      "tensor([[1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1), Probabilities: [0.  0.  0.  0.  0.5 0.  0.  0.  0.  0.5 0. ], Predicted Values: tensor([0.0000, 0.0000, 0.0000, 0.0000, 0.9883, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0117, 0.0000], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1.])\n",
      "tensor([[1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0), Probabilities: [0.  0.  0.  0.  0.5 0.  0.  0.  0.  0.  0.5], Predicted Values: tensor([0.0000, 0.0000, 0.0000, 0.0000, 0.9971, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0029], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0.])\n",
      "tensor([[1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1), Probabilities: [0.  0.  0.  0.  0.  0.5 0.5 0.  0.  0.  0. ], Predicted Values: tensor([0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.9916, 0.0084, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0.])\n",
      "tensor([[1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1), Probabilities: [0.         0.         0.         0.         0.         0.95257413\n",
      " 0.         0.04742587 0.         0.         0.        ], Predicted Values: tensor([0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.8993, 0.0000, 0.1007, 0.0000,\n",
      "        0.0000, 0.0000], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0.])\n",
      "tensor([[1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1), Probabilities: [0.  0.  0.  0.  0.  0.5 0.  0.  0.5 0.  0. ], Predicted Values: tensor([0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.9219, 0.0000, 0.0000, 0.0781,\n",
      "        0.0000, 0.0000], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0.])\n",
      "tensor([[1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1), Probabilities: [0.  0.  0.  0.  0.  0.5 0.  0.  0.  0.5 0. ], Predicted Values: tensor([0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.9973, 0.0000, 0.0000, 0.0000,\n",
      "        0.0027, 0.0000], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1.])\n",
      "tensor([[1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0), Probabilities: [0.  0.  0.  0.  0.  0.5 0.  0.  0.  0.  0.5], Predicted Values: tensor([    0.0000,     0.0000,     0.0000,     0.0000,     0.0000,     0.9995,\n",
      "            0.0000,     0.0000,     0.0000,     0.0000,     0.0005],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0.])\n",
      "tensor([[1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1), Probabilities: [0.  0.  0.  0.  0.  0.  0.5 0.5 0.  0.  0. ], Predicted Values: tensor([0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.5411, 0.4589, 0.0000,\n",
      "        0.0000, 0.0000], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0.])\n",
      "tensor([[1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1), Probabilities: [0.         0.         0.         0.         0.         0.\n",
      " 0.81757448 0.         0.18242552 0.         0.        ], Predicted Values: tensor([0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1567, 0.0000, 0.8433,\n",
      "        0.0000, 0.0000], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0.])\n",
      "tensor([[1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1), Probabilities: [0.  0.  0.  0.  0.  0.  0.5 0.  0.  0.5 0. ], Predicted Values: tensor([0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.8818, 0.0000, 0.0000,\n",
      "        0.1182, 0.0000], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1.])\n",
      "tensor([[1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0), Probabilities: [0.  0.  0.  0.  0.  0.  0.5 0.  0.  0.  0.5], Predicted Values: tensor([0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.9812, 0.0000, 0.0000,\n",
      "        0.0000, 0.0188], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0.])\n",
      "tensor([[1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1), Probabilities: [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.81757448 0.18242552 0.         0.        ], Predicted Values: tensor([0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.9244, 0.0756,\n",
      "        0.0000, 0.0000], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0.])\n",
      "tensor([[1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1), Probabilities: [0.  0.  0.  0.  0.  0.  0.  0.5 0.  0.5 0. ], Predicted Values: tensor([0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.9838, 0.0000,\n",
      "        0.0162, 0.0000], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1.])\n",
      "tensor([[1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0), Probabilities: [0.  0.  0.  0.  0.  0.  0.  0.5 0.  0.  0.5], Predicted Values: tensor([0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.9966, 0.0000,\n",
      "        0.0000, 0.0034], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0.])\n",
      "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1), Probabilities: [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.95257413 0.04742587 0.        ], Predicted Values: tensor([0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.9786,\n",
      "        0.0214, 0.0000], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1.])\n",
      "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0), Probabilities: [0.  0.  0.  0.  0.  0.  0.  0.  0.5 0.  0.5], Predicted Values: tensor([0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.9971,\n",
      "        0.0000, 0.0029], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1.])\n",
      "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0), Probabilities: [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.95257413 0.04742587], Predicted Values: tensor([0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.8840, 0.1160], grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "tensor([[1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1.]])\n",
      "tensor(0.)\n",
      "State: (1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1), Probabilities: [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.], Predicted Values: tensor([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "tensor([[1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1), Probabilities: [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.], Predicted Values: tensor([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.])\n",
      "tensor([[1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1), Probabilities: [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.], Predicted Values: tensor([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.])\n",
      "tensor([[1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1), Probabilities: [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.], Predicted Values: tensor([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.])\n",
      "tensor([[1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1), Probabilities: [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.], Predicted Values: tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.])\n",
      "tensor([[1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1), Probabilities: [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.], Predicted Values: tensor([0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.])\n",
      "tensor([[1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1), Probabilities: [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.], Predicted Values: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.])\n",
      "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1), Probabilities: [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.], Predicted Values: tensor([0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.])\n",
      "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1), Probabilities: [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.], Predicted Values: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.])\n",
      "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0), Probabilities: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.], Predicted Values: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]])\n",
      "tensor(1.)\n",
      "State: (1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1), Probabilities: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.], Predicted Values: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1800x1000 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "State counts:\n",
      "State 10000000000: 0 students\n",
      "State 10010000000: 9 students\n",
      "State 10100000000: 6 students\n",
      "State 11000000000: 5 students\n",
      "State 10000000001: 0 students\n",
      "State 10000000010: 0 students\n",
      "State 10000000100: 0 students\n",
      "State 10000001000: 0 students\n",
      "State 10000010000: 0 students\n",
      "State 10000100000: 0 students\n",
      "State 10001000000: 0 students\n",
      "State 11100000000: 3 students\n",
      "State 10110000000: 7 students\n",
      "State 10010000010: 1 students\n",
      "State 10100001000: 1 students\n",
      "State 11001000000: 2 students\n",
      "State 11010000000: 3 students\n",
      "State 11000001000: 1 students\n",
      "State 10101000000: 1 students\n",
      "State 10000100010: 1 students\n",
      "State 10000000011: 0 students\n",
      "State 10000000101: 0 students\n",
      "State 10000000110: 0 students\n",
      "State 10000001001: 0 students\n",
      "State 10000001010: 0 students\n",
      "State 10000001100: 0 students\n",
      "State 10000010001: 0 students\n",
      "State 10000010010: 0 students\n",
      "State 10000010100: 0 students\n",
      "State 10000011000: 0 students\n",
      "State 10000100001: 0 students\n",
      "State 10000100100: 0 students\n",
      "State 10000101000: 0 students\n",
      "State 10000110000: 0 students\n",
      "State 10001000001: 0 students\n",
      "State 10001000010: 0 students\n",
      "State 10001000100: 0 students\n",
      "State 10001001000: 0 students\n",
      "State 10001010000: 0 students\n",
      "State 10001100000: 0 students\n",
      "State 10010000001: 0 students\n",
      "State 10010000100: 0 students\n",
      "State 10010001000: 0 students\n",
      "State 10010010000: 0 students\n",
      "State 10010100000: 0 students\n",
      "State 10011000000: 0 students\n",
      "State 10100000001: 0 students\n",
      "State 10100000010: 0 students\n",
      "State 10100000100: 0 students\n",
      "State 10100010000: 0 students\n",
      "State 10100100000: 0 students\n",
      "State 11000000001: 0 students\n",
      "State 11000000010: 0 students\n",
      "State 11000000100: 0 students\n",
      "State 11000010000: 0 students\n",
      "State 11000100000: 0 students\n",
      "State 11101000000: 4 students\n",
      "State 11010010000: 1 students\n",
      "State 11110000000: 7 students\n",
      "State 11010001000: 1 students\n",
      "State 11010000001: 1 students\n",
      "State 10110100000: 3 students\n",
      "State 10100010010: 1 students\n",
      "State 10100110000: 1 students\n",
      "State 11010100000: 1 students\n",
      "State 10000000111: 0 students\n",
      "State 10000001011: 0 students\n",
      "State 10000001101: 0 students\n",
      "State 10000001110: 0 students\n",
      "State 10000010011: 0 students\n",
      "State 10000010101: 0 students\n",
      "State 10000010110: 0 students\n",
      "State 10000011001: 0 students\n",
      "State 10000011010: 0 students\n",
      "State 10000011100: 0 students\n",
      "State 10000100011: 0 students\n",
      "State 10000100101: 0 students\n",
      "State 10000100110: 0 students\n",
      "State 10000101001: 0 students\n",
      "State 10000101010: 0 students\n",
      "State 10000101100: 0 students\n",
      "State 10000110001: 0 students\n",
      "State 10000110010: 0 students\n",
      "State 10000110100: 0 students\n",
      "State 10000111000: 0 students\n",
      "State 10001000011: 0 students\n",
      "State 10001000101: 0 students\n",
      "State 10001000110: 0 students\n",
      "State 10001001001: 0 students\n",
      "State 10001001010: 0 students\n",
      "State 10001001100: 0 students\n",
      "State 10001010001: 0 students\n",
      "State 10001010010: 0 students\n",
      "State 10001010100: 0 students\n",
      "State 10001011000: 0 students\n",
      "State 10001100001: 0 students\n",
      "State 10001100010: 0 students\n",
      "State 10001100100: 0 students\n",
      "State 10001101000: 0 students\n",
      "State 10001110000: 0 students\n",
      "State 10010000011: 0 students\n",
      "State 10010000101: 0 students\n",
      "State 10010000110: 0 students\n",
      "State 10010001001: 0 students\n",
      "State 10010001010: 0 students\n",
      "State 10010001100: 0 students\n",
      "State 10010010001: 0 students\n",
      "State 10010010010: 0 students\n",
      "State 10010010100: 0 students\n",
      "State 10010011000: 0 students\n",
      "State 10010100001: 0 students\n",
      "State 10010100010: 0 students\n",
      "State 10010100100: 0 students\n",
      "State 10010101000: 0 students\n",
      "State 10010110000: 0 students\n",
      "State 10011000001: 0 students\n",
      "State 10011000010: 0 students\n",
      "State 10011000100: 0 students\n",
      "State 10011001000: 0 students\n",
      "State 10011010000: 0 students\n",
      "State 10011100000: 0 students\n",
      "State 10100000011: 0 students\n",
      "State 10100000101: 0 students\n",
      "State 10100000110: 0 students\n",
      "State 10100001001: 0 students\n",
      "State 10100001010: 0 students\n",
      "State 10100001100: 0 students\n",
      "State 10100010001: 0 students\n",
      "State 10100010100: 0 students\n",
      "State 10100011000: 0 students\n",
      "State 10100100001: 0 students\n",
      "State 10100100010: 0 students\n",
      "State 10100100100: 0 students\n",
      "State 10100101000: 0 students\n",
      "State 10101000001: 0 students\n",
      "State 10101000010: 0 students\n",
      "State 10101000100: 0 students\n",
      "State 10101001000: 0 students\n",
      "State 10101010000: 0 students\n",
      "State 10101100000: 0 students\n",
      "State 10110000001: 0 students\n",
      "State 10110000010: 0 students\n",
      "State 10110000100: 0 students\n",
      "State 10110001000: 0 students\n",
      "State 10110010000: 0 students\n",
      "State 10111000000: 0 students\n",
      "State 11000000011: 0 students\n",
      "State 11000000101: 0 students\n",
      "State 11000000110: 0 students\n",
      "State 11000001001: 0 students\n",
      "State 11000001010: 0 students\n",
      "State 11000001100: 0 students\n",
      "State 11000010001: 0 students\n",
      "State 11000010010: 0 students\n",
      "State 11000010100: 0 students\n",
      "State 11000011000: 0 students\n",
      "State 11000100001: 0 students\n",
      "State 11000100010: 0 students\n",
      "State 11000100100: 0 students\n",
      "State 11000101000: 0 students\n",
      "State 11000110000: 0 students\n",
      "State 11001000001: 0 students\n",
      "State 11001000010: 0 students\n",
      "State 11001000100: 0 students\n",
      "State 11001001000: 0 students\n",
      "State 11001010000: 0 students\n",
      "State 11001100000: 0 students\n",
      "State 11010000010: 0 students\n",
      "State 11010000100: 0 students\n",
      "State 11011000000: 0 students\n",
      "State 11100000001: 0 students\n",
      "State 11100000010: 0 students\n",
      "State 11100000100: 0 students\n",
      "State 11100001000: 0 students\n",
      "State 11100010000: 0 students\n",
      "State 11100100000: 0 students\n",
      "State 11111000000: 5 students\n",
      "State 11100101000: 1 students\n",
      "State 10010101001: 1 students\n",
      "State 11110100000: 4 students\n",
      "State 11010101000: 1 students\n",
      "State 10100111000: 1 students\n",
      "State 10111100000: 1 students\n",
      "State 10010000111: 1 students\n",
      "State 11110000100: 1 students\n",
      "State 11011010000: 1 students\n",
      "State 11101010000: 1 students\n",
      "State 11110001000: 1 students\n",
      "State 11100000011: 1 students\n",
      "State 10000001111: 0 students\n",
      "State 10000010111: 0 students\n",
      "State 10000011011: 0 students\n",
      "State 10000011101: 0 students\n",
      "State 10000011110: 0 students\n",
      "State 10000100111: 0 students\n",
      "State 10000101011: 0 students\n",
      "State 10000101101: 0 students\n",
      "State 10000101110: 0 students\n",
      "State 10000110011: 0 students\n",
      "State 10000110101: 0 students\n",
      "State 10000110110: 0 students\n",
      "State 10000111001: 0 students\n",
      "State 10000111010: 0 students\n",
      "State 10000111100: 0 students\n",
      "State 10001000111: 0 students\n",
      "State 10001001011: 0 students\n",
      "State 10001001101: 0 students\n",
      "State 10001001110: 0 students\n",
      "State 10001010011: 0 students\n",
      "State 10001010101: 0 students\n",
      "State 10001010110: 0 students\n",
      "State 10001011001: 0 students\n",
      "State 10001011010: 0 students\n",
      "State 10001011100: 0 students\n",
      "State 10001100011: 0 students\n",
      "State 10001100101: 0 students\n",
      "State 10001100110: 0 students\n",
      "State 10001101001: 0 students\n",
      "State 10001101010: 0 students\n",
      "State 10001101100: 0 students\n",
      "State 10001110001: 0 students\n",
      "State 10001110010: 0 students\n",
      "State 10001110100: 0 students\n",
      "State 10001111000: 0 students\n",
      "State 10010001011: 0 students\n",
      "State 10010001101: 0 students\n",
      "State 10010001110: 0 students\n",
      "State 10010010011: 0 students\n",
      "State 10010010101: 0 students\n",
      "State 10010010110: 0 students\n",
      "State 10010011001: 0 students\n",
      "State 10010011010: 0 students\n",
      "State 10010011100: 0 students\n",
      "State 10010100011: 0 students\n",
      "State 10010100101: 0 students\n",
      "State 10010100110: 0 students\n",
      "State 10010101010: 0 students\n",
      "State 10010101100: 0 students\n",
      "State 10010110001: 0 students\n",
      "State 10010110010: 0 students\n",
      "State 10010110100: 0 students\n",
      "State 10010111000: 0 students\n",
      "State 10011000011: 0 students\n",
      "State 10011000101: 0 students\n",
      "State 10011000110: 0 students\n",
      "State 10011001001: 0 students\n",
      "State 10011001010: 0 students\n",
      "State 10011001100: 0 students\n",
      "State 10011010001: 0 students\n",
      "State 10011010010: 0 students\n",
      "State 10011010100: 0 students\n",
      "State 10011011000: 0 students\n",
      "State 10011100001: 0 students\n",
      "State 10011100010: 0 students\n",
      "State 10011100100: 0 students\n",
      "State 10011101000: 0 students\n",
      "State 10011110000: 0 students\n",
      "State 10100000111: 0 students\n",
      "State 10100001011: 0 students\n",
      "State 10100001101: 0 students\n",
      "State 10100001110: 0 students\n",
      "State 10100010011: 0 students\n",
      "State 10100010101: 0 students\n",
      "State 10100010110: 0 students\n",
      "State 10100011001: 0 students\n",
      "State 10100011010: 0 students\n",
      "State 10100011100: 0 students\n",
      "State 10100100011: 0 students\n",
      "State 10100100101: 0 students\n",
      "State 10100100110: 0 students\n",
      "State 10100101001: 0 students\n",
      "State 10100101010: 0 students\n",
      "State 10100101100: 0 students\n",
      "State 10100110001: 0 students\n",
      "State 10100110010: 0 students\n",
      "State 10100110100: 0 students\n",
      "State 10101000011: 0 students\n",
      "State 10101000101: 0 students\n",
      "State 10101000110: 0 students\n",
      "State 10101001001: 0 students\n",
      "State 10101001010: 0 students\n",
      "State 10101001100: 0 students\n",
      "State 10101010001: 0 students\n",
      "State 10101010010: 0 students\n",
      "State 10101010100: 0 students\n",
      "State 10101011000: 0 students\n",
      "State 10101100001: 0 students\n",
      "State 10101100010: 0 students\n",
      "State 10101100100: 0 students\n",
      "State 10101101000: 0 students\n",
      "State 10101110000: 0 students\n",
      "State 10110000011: 0 students\n",
      "State 10110000101: 0 students\n",
      "State 10110000110: 0 students\n",
      "State 10110001001: 0 students\n",
      "State 10110001010: 0 students\n",
      "State 10110001100: 0 students\n",
      "State 10110010001: 0 students\n",
      "State 10110010010: 0 students\n",
      "State 10110010100: 0 students\n",
      "State 10110011000: 0 students\n",
      "State 10110100001: 0 students\n",
      "State 10110100010: 0 students\n",
      "State 10110100100: 0 students\n",
      "State 10110101000: 0 students\n",
      "State 10110110000: 0 students\n",
      "State 10111000001: 0 students\n",
      "State 10111000010: 0 students\n",
      "State 10111000100: 0 students\n",
      "State 10111001000: 0 students\n",
      "State 10111010000: 0 students\n",
      "State 11000000111: 0 students\n",
      "State 11000001011: 0 students\n",
      "State 11000001101: 0 students\n",
      "State 11000001110: 0 students\n",
      "State 11000010011: 0 students\n",
      "State 11000010101: 0 students\n",
      "State 11000010110: 0 students\n",
      "State 11000011001: 0 students\n",
      "State 11000011010: 0 students\n",
      "State 11000011100: 0 students\n",
      "State 11000100011: 0 students\n",
      "State 11000100101: 0 students\n",
      "State 11000100110: 0 students\n",
      "State 11000101001: 0 students\n",
      "State 11000101010: 0 students\n",
      "State 11000101100: 0 students\n",
      "State 11000110001: 0 students\n",
      "State 11000110010: 0 students\n",
      "State 11000110100: 0 students\n",
      "State 11000111000: 0 students\n",
      "State 11001000011: 0 students\n",
      "State 11001000101: 0 students\n",
      "State 11001000110: 0 students\n",
      "State 11001001001: 0 students\n",
      "State 11001001010: 0 students\n",
      "State 11001001100: 0 students\n",
      "State 11001010001: 0 students\n",
      "State 11001010010: 0 students\n",
      "State 11001010100: 0 students\n",
      "State 11001011000: 0 students\n",
      "State 11001100001: 0 students\n",
      "State 11001100010: 0 students\n",
      "State 11001100100: 0 students\n",
      "State 11001101000: 0 students\n",
      "State 11001110000: 0 students\n",
      "State 11010000011: 0 students\n",
      "State 11010000101: 0 students\n",
      "State 11010000110: 0 students\n",
      "State 11010001001: 0 students\n",
      "State 11010001010: 0 students\n",
      "State 11010001100: 0 students\n",
      "State 11010010001: 0 students\n",
      "State 11010010010: 0 students\n",
      "State 11010010100: 0 students\n",
      "State 11010011000: 0 students\n",
      "State 11010100001: 0 students\n",
      "State 11010100010: 0 students\n",
      "State 11010100100: 0 students\n",
      "State 11010110000: 0 students\n",
      "State 11011000001: 0 students\n",
      "State 11011000010: 0 students\n",
      "State 11011000100: 0 students\n",
      "State 11011001000: 0 students\n",
      "State 11011100000: 0 students\n",
      "State 11100000101: 0 students\n",
      "State 11100000110: 0 students\n",
      "State 11100001001: 0 students\n",
      "State 11100001010: 0 students\n",
      "State 11100001100: 0 students\n",
      "State 11100010001: 0 students\n",
      "State 11100010010: 0 students\n",
      "State 11100010100: 0 students\n",
      "State 11100011000: 0 students\n",
      "State 11100100001: 0 students\n",
      "State 11100100010: 0 students\n",
      "State 11100100100: 0 students\n",
      "State 11100110000: 0 students\n",
      "State 11101000001: 0 students\n",
      "State 11101000010: 0 students\n",
      "State 11101000100: 0 students\n",
      "State 11101001000: 0 students\n",
      "State 11101100000: 0 students\n",
      "State 11110000001: 0 students\n",
      "State 11110000010: 0 students\n",
      "State 11110010000: 0 students\n",
      "State 11111100000: 5 students\n",
      "State 11011110000: 1 students\n",
      "State 10110101100: 1 students\n",
      "State 11111010000: 4 students\n",
      "State 10100101011: 1 students\n",
      "State 10110111000: 1 students\n",
      "State 11110110000: 1 students\n",
      "State 11110101000: 2 students\n",
      "State 11011011000: 1 students\n",
      "State 11110000110: 2 students\n",
      "State 11110000011: 1 students\n",
      "State 10000011111: 0 students\n",
      "State 10000101111: 0 students\n",
      "State 10000110111: 0 students\n",
      "State 10000111011: 0 students\n",
      "State 10000111101: 0 students\n",
      "State 10000111110: 0 students\n",
      "State 10001001111: 0 students\n",
      "State 10001010111: 0 students\n",
      "State 10001011011: 0 students\n",
      "State 10001011101: 0 students\n",
      "State 10001011110: 0 students\n",
      "State 10001100111: 0 students\n",
      "State 10001101011: 0 students\n",
      "State 10001101101: 0 students\n",
      "State 10001101110: 0 students\n",
      "State 10001110011: 0 students\n",
      "State 10001110101: 0 students\n",
      "State 10001110110: 0 students\n",
      "State 10001111001: 0 students\n",
      "State 10001111010: 0 students\n",
      "State 10001111100: 0 students\n",
      "State 10010001111: 0 students\n",
      "State 10010010111: 0 students\n",
      "State 10010011011: 0 students\n",
      "State 10010011101: 0 students\n",
      "State 10010011110: 0 students\n",
      "State 10010100111: 0 students\n",
      "State 10010101011: 0 students\n",
      "State 10010101101: 0 students\n",
      "State 10010101110: 0 students\n",
      "State 10010110011: 0 students\n",
      "State 10010110101: 0 students\n",
      "State 10010110110: 0 students\n",
      "State 10010111001: 0 students\n",
      "State 10010111010: 0 students\n",
      "State 10010111100: 0 students\n",
      "State 10011000111: 0 students\n",
      "State 10011001011: 0 students\n",
      "State 10011001101: 0 students\n",
      "State 10011001110: 0 students\n",
      "State 10011010011: 0 students\n",
      "State 10011010101: 0 students\n",
      "State 10011010110: 0 students\n",
      "State 10011011001: 0 students\n",
      "State 10011011010: 0 students\n",
      "State 10011011100: 0 students\n",
      "State 10011100011: 0 students\n",
      "State 10011100101: 0 students\n",
      "State 10011100110: 0 students\n",
      "State 10011101001: 0 students\n",
      "State 10011101010: 0 students\n",
      "State 10011101100: 0 students\n",
      "State 10011110001: 0 students\n",
      "State 10011110010: 0 students\n",
      "State 10011110100: 0 students\n",
      "State 10011111000: 0 students\n",
      "State 10100001111: 0 students\n",
      "State 10100010111: 0 students\n",
      "State 10100011011: 0 students\n",
      "State 10100011101: 0 students\n",
      "State 10100011110: 0 students\n",
      "State 10100100111: 0 students\n",
      "State 10100101101: 0 students\n",
      "State 10100101110: 0 students\n",
      "State 10100110011: 0 students\n",
      "State 10100110101: 0 students\n",
      "State 10100110110: 0 students\n",
      "State 10100111001: 0 students\n",
      "State 10100111010: 0 students\n",
      "State 10100111100: 0 students\n",
      "State 10101000111: 0 students\n",
      "State 10101001011: 0 students\n",
      "State 10101001101: 0 students\n",
      "State 10101001110: 0 students\n",
      "State 10101010011: 0 students\n",
      "State 10101010101: 0 students\n",
      "State 10101010110: 0 students\n",
      "State 10101011001: 0 students\n",
      "State 10101011010: 0 students\n",
      "State 10101011100: 0 students\n",
      "State 10101100011: 0 students\n",
      "State 10101100101: 0 students\n",
      "State 10101100110: 0 students\n",
      "State 10101101001: 0 students\n",
      "State 10101101010: 0 students\n",
      "State 10101101100: 0 students\n",
      "State 10101110001: 0 students\n",
      "State 10101110010: 0 students\n",
      "State 10101110100: 0 students\n",
      "State 10101111000: 0 students\n",
      "State 10110000111: 0 students\n",
      "State 10110001011: 0 students\n",
      "State 10110001101: 0 students\n",
      "State 10110001110: 0 students\n",
      "State 10110010011: 0 students\n",
      "State 10110010101: 0 students\n",
      "State 10110010110: 0 students\n",
      "State 10110011001: 0 students\n",
      "State 10110011010: 0 students\n",
      "State 10110011100: 0 students\n",
      "State 10110100011: 0 students\n",
      "State 10110100101: 0 students\n",
      "State 10110100110: 0 students\n",
      "State 10110101001: 0 students\n",
      "State 10110101010: 0 students\n",
      "State 10110110001: 0 students\n",
      "State 10110110010: 0 students\n",
      "State 10110110100: 0 students\n",
      "State 10111000011: 0 students\n",
      "State 10111000101: 0 students\n",
      "State 10111000110: 0 students\n",
      "State 10111001001: 0 students\n",
      "State 10111001010: 0 students\n",
      "State 10111001100: 0 students\n",
      "State 10111010001: 0 students\n",
      "State 10111010010: 0 students\n",
      "State 10111010100: 0 students\n",
      "State 10111011000: 0 students\n",
      "State 10111100001: 0 students\n",
      "State 10111100010: 0 students\n",
      "State 10111100100: 0 students\n",
      "State 10111101000: 0 students\n",
      "State 10111110000: 0 students\n",
      "State 11000001111: 0 students\n",
      "State 11000010111: 0 students\n",
      "State 11000011011: 0 students\n",
      "State 11000011101: 0 students\n",
      "State 11000011110: 0 students\n",
      "State 11000100111: 0 students\n",
      "State 11000101011: 0 students\n",
      "State 11000101101: 0 students\n",
      "State 11000101110: 0 students\n",
      "State 11000110011: 0 students\n",
      "State 11000110101: 0 students\n",
      "State 11000110110: 0 students\n",
      "State 11000111001: 0 students\n",
      "State 11000111010: 0 students\n",
      "State 11000111100: 0 students\n",
      "State 11001000111: 0 students\n",
      "State 11001001011: 0 students\n",
      "State 11001001101: 0 students\n",
      "State 11001001110: 0 students\n",
      "State 11001010011: 0 students\n",
      "State 11001010101: 0 students\n",
      "State 11001010110: 0 students\n",
      "State 11001011001: 0 students\n",
      "State 11001011010: 0 students\n",
      "State 11001011100: 0 students\n",
      "State 11001100011: 0 students\n",
      "State 11001100101: 0 students\n",
      "State 11001100110: 0 students\n",
      "State 11001101001: 0 students\n",
      "State 11001101010: 0 students\n",
      "State 11001101100: 0 students\n",
      "State 11001110001: 0 students\n",
      "State 11001110010: 0 students\n",
      "State 11001110100: 0 students\n",
      "State 11001111000: 0 students\n",
      "State 11010000111: 0 students\n",
      "State 11010001011: 0 students\n",
      "State 11010001101: 0 students\n",
      "State 11010001110: 0 students\n",
      "State 11010010011: 0 students\n",
      "State 11010010101: 0 students\n",
      "State 11010010110: 0 students\n",
      "State 11010011001: 0 students\n",
      "State 11010011010: 0 students\n",
      "State 11010011100: 0 students\n",
      "State 11010100011: 0 students\n",
      "State 11010100101: 0 students\n",
      "State 11010100110: 0 students\n",
      "State 11010101001: 0 students\n",
      "State 11010101010: 0 students\n",
      "State 11010101100: 0 students\n",
      "State 11010110001: 0 students\n",
      "State 11010110010: 0 students\n",
      "State 11010110100: 0 students\n",
      "State 11010111000: 0 students\n",
      "State 11011000011: 0 students\n",
      "State 11011000101: 0 students\n",
      "State 11011000110: 0 students\n",
      "State 11011001001: 0 students\n",
      "State 11011001010: 0 students\n",
      "State 11011001100: 0 students\n",
      "State 11011010001: 0 students\n",
      "State 11011010010: 0 students\n",
      "State 11011010100: 0 students\n",
      "State 11011100001: 0 students\n",
      "State 11011100010: 0 students\n",
      "State 11011100100: 0 students\n",
      "State 11011101000: 0 students\n",
      "State 11100000111: 0 students\n",
      "State 11100001011: 0 students\n",
      "State 11100001101: 0 students\n",
      "State 11100001110: 0 students\n",
      "State 11100010011: 0 students\n",
      "State 11100010101: 0 students\n",
      "State 11100010110: 0 students\n",
      "State 11100011001: 0 students\n",
      "State 11100011010: 0 students\n",
      "State 11100011100: 0 students\n",
      "State 11100100011: 0 students\n",
      "State 11100100101: 0 students\n",
      "State 11100100110: 0 students\n",
      "State 11100101001: 0 students\n",
      "State 11100101010: 0 students\n",
      "State 11100101100: 0 students\n",
      "State 11100110001: 0 students\n",
      "State 11100110010: 0 students\n",
      "State 11100110100: 0 students\n",
      "State 11100111000: 0 students\n",
      "State 11101000011: 0 students\n",
      "State 11101000101: 0 students\n",
      "State 11101000110: 0 students\n",
      "State 11101001001: 0 students\n",
      "State 11101001010: 0 students\n",
      "State 11101001100: 0 students\n",
      "State 11101010001: 0 students\n",
      "State 11101010010: 0 students\n",
      "State 11101010100: 0 students\n",
      "State 11101011000: 0 students\n",
      "State 11101100001: 0 students\n",
      "State 11101100010: 0 students\n",
      "State 11101100100: 0 students\n",
      "State 11101101000: 0 students\n",
      "State 11101110000: 0 students\n",
      "State 11110000101: 0 students\n",
      "State 11110001001: 0 students\n",
      "State 11110001010: 0 students\n",
      "State 11110001100: 0 students\n",
      "State 11110010001: 0 students\n",
      "State 11110010010: 0 students\n",
      "State 11110010100: 0 students\n",
      "State 11110011000: 0 students\n",
      "State 11110100001: 0 students\n",
      "State 11110100010: 0 students\n",
      "State 11110100100: 0 students\n",
      "State 11111000001: 0 students\n",
      "State 11111000010: 0 students\n",
      "State 11111000100: 0 students\n",
      "State 11111001000: 0 students\n",
      "State 11111101000: 5 students\n",
      "State 11110010011: 1 students\n",
      "State 11111110000: 4 students\n",
      "State 10010101111: 1 students\n",
      "State 11111010100: 2 students\n",
      "State 11110101100: 2 students\n",
      "State 10101010111: 1 students\n",
      "State 11011010110: 1 students\n",
      "State 11111000011: 1 students\n",
      "State 11111011000: 1 students\n",
      "State 11110001101: 1 students\n",
      "State 10000111111: 0 students\n",
      "State 10001011111: 0 students\n",
      "State 10001101111: 0 students\n",
      "State 10001110111: 0 students\n",
      "State 10001111011: 0 students\n",
      "State 10001111101: 0 students\n",
      "State 10001111110: 0 students\n",
      "State 10010011111: 0 students\n",
      "State 10010110111: 0 students\n",
      "State 10010111011: 0 students\n",
      "State 10010111101: 0 students\n",
      "State 10010111110: 0 students\n",
      "State 10011001111: 0 students\n",
      "State 10011010111: 0 students\n",
      "State 10011011011: 0 students\n",
      "State 10011011101: 0 students\n",
      "State 10011011110: 0 students\n",
      "State 10011100111: 0 students\n",
      "State 10011101011: 0 students\n",
      "State 10011101101: 0 students\n",
      "State 10011101110: 0 students\n",
      "State 10011110011: 0 students\n",
      "State 10011110101: 0 students\n",
      "State 10011110110: 0 students\n",
      "State 10011111001: 0 students\n",
      "State 10011111010: 0 students\n",
      "State 10011111100: 0 students\n",
      "State 10100011111: 0 students\n",
      "State 10100101111: 0 students\n",
      "State 10100110111: 0 students\n",
      "State 10100111011: 0 students\n",
      "State 10100111101: 0 students\n",
      "State 10100111110: 0 students\n",
      "State 10101001111: 0 students\n",
      "State 10101011011: 0 students\n",
      "State 10101011101: 0 students\n",
      "State 10101011110: 0 students\n",
      "State 10101100111: 0 students\n",
      "State 10101101011: 0 students\n",
      "State 10101101101: 0 students\n",
      "State 10101101110: 0 students\n",
      "State 10101110011: 0 students\n",
      "State 10101110101: 0 students\n",
      "State 10101110110: 0 students\n",
      "State 10101111001: 0 students\n",
      "State 10101111010: 0 students\n",
      "State 10101111100: 0 students\n",
      "State 10110001111: 0 students\n",
      "State 10110010111: 0 students\n",
      "State 10110011011: 0 students\n",
      "State 10110011101: 0 students\n",
      "State 10110011110: 0 students\n",
      "State 10110100111: 0 students\n",
      "State 10110101011: 0 students\n",
      "State 10110101101: 0 students\n",
      "State 10110101110: 0 students\n",
      "State 10110110011: 0 students\n",
      "State 10110110101: 0 students\n",
      "State 10110110110: 0 students\n",
      "State 10110111001: 0 students\n",
      "State 10110111010: 0 students\n",
      "State 10110111100: 0 students\n",
      "State 10111000111: 0 students\n",
      "State 10111001011: 0 students\n",
      "State 10111001101: 0 students\n",
      "State 10111001110: 0 students\n",
      "State 10111010011: 0 students\n",
      "State 10111010101: 0 students\n",
      "State 10111010110: 0 students\n",
      "State 10111011001: 0 students\n",
      "State 10111011010: 0 students\n",
      "State 10111011100: 0 students\n",
      "State 10111100011: 0 students\n",
      "State 10111100101: 0 students\n",
      "State 10111100110: 0 students\n",
      "State 10111101001: 0 students\n",
      "State 10111101010: 0 students\n",
      "State 10111101100: 0 students\n",
      "State 10111110001: 0 students\n",
      "State 10111110010: 0 students\n",
      "State 10111110100: 0 students\n",
      "State 10111111000: 0 students\n",
      "State 11000011111: 0 students\n",
      "State 11000101111: 0 students\n",
      "State 11000110111: 0 students\n",
      "State 11000111011: 0 students\n",
      "State 11000111101: 0 students\n",
      "State 11000111110: 0 students\n",
      "State 11001001111: 0 students\n",
      "State 11001010111: 0 students\n",
      "State 11001011011: 0 students\n",
      "State 11001011101: 0 students\n",
      "State 11001011110: 0 students\n",
      "State 11001100111: 0 students\n",
      "State 11001101011: 0 students\n",
      "State 11001101101: 0 students\n",
      "State 11001101110: 0 students\n",
      "State 11001110011: 0 students\n",
      "State 11001110101: 0 students\n",
      "State 11001110110: 0 students\n",
      "State 11001111001: 0 students\n",
      "State 11001111010: 0 students\n",
      "State 11001111100: 0 students\n",
      "State 11010001111: 0 students\n",
      "State 11010010111: 0 students\n",
      "State 11010011011: 0 students\n",
      "State 11010011101: 0 students\n",
      "State 11010011110: 0 students\n",
      "State 11010100111: 0 students\n",
      "State 11010101011: 0 students\n",
      "State 11010101101: 0 students\n",
      "State 11010101110: 0 students\n",
      "State 11010110011: 0 students\n",
      "State 11010110101: 0 students\n",
      "State 11010110110: 0 students\n",
      "State 11010111001: 0 students\n",
      "State 11010111010: 0 students\n",
      "State 11010111100: 0 students\n",
      "State 11011000111: 0 students\n",
      "State 11011001011: 0 students\n",
      "State 11011001101: 0 students\n",
      "State 11011001110: 0 students\n",
      "State 11011010011: 0 students\n",
      "State 11011010101: 0 students\n",
      "State 11011011001: 0 students\n",
      "State 11011011010: 0 students\n",
      "State 11011011100: 0 students\n",
      "State 11011100011: 0 students\n",
      "State 11011100101: 0 students\n",
      "State 11011100110: 0 students\n",
      "State 11011101001: 0 students\n",
      "State 11011101010: 0 students\n",
      "State 11011101100: 0 students\n",
      "State 11011110001: 0 students\n",
      "State 11011110010: 0 students\n",
      "State 11011110100: 0 students\n",
      "State 11011111000: 0 students\n",
      "State 11100001111: 0 students\n",
      "State 11100010111: 0 students\n",
      "State 11100011011: 0 students\n",
      "State 11100011101: 0 students\n",
      "State 11100011110: 0 students\n",
      "State 11100100111: 0 students\n",
      "State 11100101011: 0 students\n",
      "State 11100101101: 0 students\n",
      "State 11100101110: 0 students\n",
      "State 11100110011: 0 students\n",
      "State 11100110101: 0 students\n",
      "State 11100110110: 0 students\n",
      "State 11100111001: 0 students\n",
      "State 11100111010: 0 students\n",
      "State 11100111100: 0 students\n",
      "State 11101000111: 0 students\n",
      "State 11101001011: 0 students\n",
      "State 11101001101: 0 students\n",
      "State 11101001110: 0 students\n",
      "State 11101010011: 0 students\n",
      "State 11101010101: 0 students\n",
      "State 11101010110: 0 students\n",
      "State 11101011001: 0 students\n",
      "State 11101011010: 0 students\n",
      "State 11101011100: 0 students\n",
      "State 11101100011: 0 students\n",
      "State 11101100101: 0 students\n",
      "State 11101100110: 0 students\n",
      "State 11101101001: 0 students\n",
      "State 11101101010: 0 students\n",
      "State 11101101100: 0 students\n",
      "State 11101110001: 0 students\n",
      "State 11101110010: 0 students\n",
      "State 11101110100: 0 students\n",
      "State 11101111000: 0 students\n",
      "State 11110000111: 0 students\n",
      "State 11110001011: 0 students\n",
      "State 11110001110: 0 students\n",
      "State 11110010101: 0 students\n",
      "State 11110010110: 0 students\n",
      "State 11110011001: 0 students\n",
      "State 11110011010: 0 students\n",
      "State 11110011100: 0 students\n",
      "State 11110100011: 0 students\n",
      "State 11110100101: 0 students\n",
      "State 11110100110: 0 students\n",
      "State 11110101001: 0 students\n",
      "State 11110101010: 0 students\n",
      "State 11110110001: 0 students\n",
      "State 11110110010: 0 students\n",
      "State 11110110100: 0 students\n",
      "State 11110111000: 0 students\n",
      "State 11111000101: 0 students\n",
      "State 11111000110: 0 students\n",
      "State 11111001001: 0 students\n",
      "State 11111001010: 0 students\n",
      "State 11111001100: 0 students\n",
      "State 11111010001: 0 students\n",
      "State 11111010010: 0 students\n",
      "State 11111100001: 0 students\n",
      "State 11111100010: 0 students\n",
      "State 11111100100: 0 students\n",
      "State 11111011100: 1 students\n",
      "State 11111111000: 12 students\n",
      "State 11111110100: 1 students\n",
      "State 11110111100: 1 students\n",
      "State 10111101011: 1 students\n",
      "State 11111110010: 1 students\n",
      "State 11111101100: 1 students\n",
      "State 11111110001: 1 students\n",
      "State 10111101110: 1 students\n",
      "State 10001111111: 0 students\n",
      "State 10010111111: 0 students\n",
      "State 10011011111: 0 students\n",
      "State 10011101111: 0 students\n",
      "State 10011110111: 0 students\n",
      "State 10011111011: 0 students\n",
      "State 10011111101: 0 students\n",
      "State 10011111110: 0 students\n",
      "State 10100111111: 0 students\n",
      "State 10101011111: 0 students\n",
      "State 10101101111: 0 students\n",
      "State 10101110111: 0 students\n",
      "State 10101111011: 0 students\n",
      "State 10101111101: 0 students\n",
      "State 10101111110: 0 students\n",
      "State 10110011111: 0 students\n",
      "State 10110101111: 0 students\n",
      "State 10110110111: 0 students\n",
      "State 10110111011: 0 students\n",
      "State 10110111101: 0 students\n",
      "State 10110111110: 0 students\n",
      "State 10111001111: 0 students\n",
      "State 10111010111: 0 students\n",
      "State 10111011011: 0 students\n",
      "State 10111011101: 0 students\n",
      "State 10111011110: 0 students\n",
      "State 10111100111: 0 students\n",
      "State 10111101101: 0 students\n",
      "State 10111110011: 0 students\n",
      "State 10111110101: 0 students\n",
      "State 10111110110: 0 students\n",
      "State 10111111001: 0 students\n",
      "State 10111111010: 0 students\n",
      "State 10111111100: 0 students\n",
      "State 11000111111: 0 students\n",
      "State 11001011111: 0 students\n",
      "State 11001101111: 0 students\n",
      "State 11001110111: 0 students\n",
      "State 11001111011: 0 students\n",
      "State 11001111101: 0 students\n",
      "State 11001111110: 0 students\n",
      "State 11010011111: 0 students\n",
      "State 11010101111: 0 students\n",
      "State 11010110111: 0 students\n",
      "State 11010111011: 0 students\n",
      "State 11010111101: 0 students\n",
      "State 11010111110: 0 students\n",
      "State 11011001111: 0 students\n",
      "State 11011010111: 0 students\n",
      "State 11011011011: 0 students\n",
      "State 11011011101: 0 students\n",
      "State 11011011110: 0 students\n",
      "State 11011100111: 0 students\n",
      "State 11011101011: 0 students\n",
      "State 11011101101: 0 students\n",
      "State 11011101110: 0 students\n",
      "State 11011110011: 0 students\n",
      "State 11011110101: 0 students\n",
      "State 11011110110: 0 students\n",
      "State 11011111001: 0 students\n",
      "State 11011111010: 0 students\n",
      "State 11011111100: 0 students\n",
      "State 11100011111: 0 students\n",
      "State 11100101111: 0 students\n",
      "State 11100110111: 0 students\n",
      "State 11100111011: 0 students\n",
      "State 11100111101: 0 students\n",
      "State 11100111110: 0 students\n",
      "State 11101001111: 0 students\n",
      "State 11101010111: 0 students\n",
      "State 11101011011: 0 students\n",
      "State 11101011101: 0 students\n",
      "State 11101011110: 0 students\n",
      "State 11101100111: 0 students\n",
      "State 11101101011: 0 students\n",
      "State 11101101101: 0 students\n",
      "State 11101101110: 0 students\n",
      "State 11101110011: 0 students\n",
      "State 11101110101: 0 students\n",
      "State 11101110110: 0 students\n",
      "State 11101111001: 0 students\n",
      "State 11101111010: 0 students\n",
      "State 11101111100: 0 students\n",
      "State 11110001111: 0 students\n",
      "State 11110010111: 0 students\n",
      "State 11110011011: 0 students\n",
      "State 11110011101: 0 students\n",
      "State 11110011110: 0 students\n",
      "State 11110100111: 0 students\n",
      "State 11110101011: 0 students\n",
      "State 11110101101: 0 students\n",
      "State 11110101110: 0 students\n",
      "State 11110110011: 0 students\n",
      "State 11110110101: 0 students\n",
      "State 11110110110: 0 students\n",
      "State 11110111001: 0 students\n",
      "State 11110111010: 0 students\n",
      "State 11111000111: 0 students\n",
      "State 11111001011: 0 students\n",
      "State 11111001101: 0 students\n",
      "State 11111001110: 0 students\n",
      "State 11111010011: 0 students\n",
      "State 11111010101: 0 students\n",
      "State 11111010110: 0 students\n",
      "State 11111011001: 0 students\n",
      "State 11111011010: 0 students\n",
      "State 11111100011: 0 students\n",
      "State 11111100101: 0 students\n",
      "State 11111100110: 0 students\n",
      "State 11111101001: 0 students\n",
      "State 11111101010: 0 students\n",
      "State 11110111110: 2 students\n",
      "State 11111111001: 1 students\n",
      "State 11111110110: 1 students\n",
      "State 11111111100: 9 students\n",
      "State 11111101101: 2 students\n",
      "State 11101111110: 1 students\n",
      "State 11111110011: 1 students\n",
      "State 11111010111: 1 students\n",
      "State 11111111010: 2 students\n",
      "State 10011111111: 0 students\n",
      "State 10101111111: 0 students\n",
      "State 10110111111: 0 students\n",
      "State 10111011111: 0 students\n",
      "State 10111101111: 0 students\n",
      "State 10111110111: 0 students\n",
      "State 10111111011: 0 students\n",
      "State 10111111101: 0 students\n",
      "State 10111111110: 0 students\n",
      "State 11001111111: 0 students\n",
      "State 11010111111: 0 students\n",
      "State 11011011111: 0 students\n",
      "State 11011101111: 0 students\n",
      "State 11011110111: 0 students\n",
      "State 11011111011: 0 students\n",
      "State 11011111101: 0 students\n",
      "State 11011111110: 0 students\n",
      "State 11100111111: 0 students\n",
      "State 11101011111: 0 students\n",
      "State 11101101111: 0 students\n",
      "State 11101110111: 0 students\n",
      "State 11101111011: 0 students\n",
      "State 11101111101: 0 students\n",
      "State 11110011111: 0 students\n",
      "State 11110101111: 0 students\n",
      "State 11110110111: 0 students\n",
      "State 11110111011: 0 students\n",
      "State 11110111101: 0 students\n",
      "State 11111001111: 0 students\n",
      "State 11111011011: 0 students\n",
      "State 11111011101: 0 students\n",
      "State 11111011110: 0 students\n",
      "State 11111100111: 0 students\n",
      "State 11111101011: 0 students\n",
      "State 11111101110: 0 students\n",
      "State 11111110101: 0 students\n",
      "State 11111111110: 11 students\n",
      "State 11111111101: 4 students\n",
      "State 11111111011: 2 students\n",
      "State 11111110111: 2 students\n",
      "State 11011111111: 1 students\n",
      "State 10111111111: 0 students\n",
      "State 11101111111: 0 students\n",
      "State 11110111111: 0 students\n",
      "State 11111011111: 0 students\n",
      "State 11111101111: 0 students\n",
      "State 11111111111: 20 students\n"
     ]
    }
   ],
   "source": [
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Create the graph\n",
    "G = nx.Graph()\n",
    "\n",
    "# Add nodes with the 'count' attribute\n",
    "for state in states:\n",
    "    G.add_node(state, count=state_counts[state])\n",
    "\n",
    "# Add edges between states\n",
    "for state in states:\n",
    "    for i in range(num_questions+1):\n",
    "        next_state = list(state)\n",
    "        if next_state[i] == 0:\n",
    "            next_state[i] = 1\n",
    "            next_state = tuple(next_state)\n",
    "            if next_state in states:\n",
    "                G.add_edge(state, next_state)\n",
    "\n",
    "# Custom layout function with uniform horizontal placement and centered nodes\n",
    "def custom_layout(G, num_questions):\n",
    "    pos = {}\n",
    "    # Group nodes by their level (number of 1's in the state)\n",
    "    levels = {}\n",
    "    for state in G.nodes():\n",
    "        level = sum(state)  # Level is the number of 1's in the state\n",
    "        if level not in levels:\n",
    "            levels[level] = []\n",
    "        levels[level].append(state)\n",
    "    \n",
    "    # Determine the x and y positions for each node\n",
    "    for level, states_at_level in levels.items():\n",
    "        num_nodes_at_level = len(states_at_level)\n",
    "        for i, state in enumerate(sorted(states_at_level)):\n",
    "            # x position is evenly spaced horizontally for each level\n",
    "            x = i - (num_nodes_at_level - 1) / 2  # Center horizontally\n",
    "            y = level  # y position is the level itself (number of 1's)\n",
    "            pos[state] = (x, y)\n",
    "    \n",
    "    return pos\n",
    "\n",
    "\n",
    "# Apply the custom layout\n",
    "pos = custom_layout(G, num_questions)\n",
    "\n",
    "# Normalize x positions\n",
    "x_values = [pos[node][0] for node in pos]\n",
    "min_x, max_x = min(x_values), max(x_values)\n",
    "for node in pos:\n",
    "    x, y = pos[node]\n",
    "    x_norm = (x - min_x) / (max_x - min_x)\n",
    "    pos[node] = (x_norm, y)\n",
    "\n",
    "# Plot settings\n",
    "plt.figure(figsize=(18, 10))  # Adjust the figure size as needed\n",
    "\n",
    "# Draw edges\n",
    "nx.draw_networkx_edges(G, pos, alpha=0.2)\n",
    "\n",
    "# Adjust node sizes according to the number of students\n",
    "node_sizes = []\n",
    "for node in G.nodes():\n",
    "    count = G.nodes[node]['count']\n",
    "    size = max(300, min(6000, count/4))  # Increase the minimum size to 600\n",
    "    node_sizes.append(size)\n",
    "\n",
    "\n",
    "# Node colors based on the number of students\n",
    "node_colors = [G.nodes[node]['count'] for node in G.nodes()]\n",
    "nodes = nx.draw_networkx_nodes(\n",
    "    G, pos, node_size=node_sizes, node_color=node_colors, cmap=plt.cm.YlOrRd\n",
    ")\n",
    "\n",
    "# Create labels including the student counts\n",
    "labels = {\n",
    "    node: f\"{''.join(map(str, node))}\\n{G.nodes[node]['count']} students\"\n",
    "    for node in G.nodes()\n",
    "}\n",
    "\n",
    "# Transition probabilities: add labels to edges, including predicted values\n",
    "edge_labels = {}\n",
    "for state in states:\n",
    "    probabilities = calculate_transition_probabilities(A, np.array(state))\n",
    "    c_g = torch.ones(num_questions+1, dtype=torch.float32)\n",
    "    c_g = c_g - torch.tensor(state, dtype=torch.float32)  # 予算を更新\n",
    "    print(c_g)\n",
    "    print(torch.tensor([state], dtype=torch.float32))\n",
    "    state_tensor = torch.tensor(state, dtype=torch.float32)\n",
    "    print(state_tensor[1])\n",
    "    predicted_values = model(state_tensor, c_g)  # 予測値を計算\n",
    "    print(f\"State: {state}, Probabilities: {probabilities}, Predicted Values: {predicted_values}\")\n",
    "\n",
    "    for i in range(num_questions+1):\n",
    "        next_state = list(state)\n",
    "        if next_state[i] == 0:\n",
    "            next_state[i] = 1\n",
    "            next_state = tuple(next_state)\n",
    "            if next_state in states:\n",
    "                # 遷移確率と予測値をラベルに追加\n",
    "                transition_probability = f\"({probabilities[i]:.2f})\"\n",
    "                predicted_value = f\"{predicted_values[i]:.2f}\"  # 予測値を表示\n",
    "                edge_labels[(state, next_state)] = f\"{predicted_value}\\n{transition_probability}\"\n",
    "\n",
    "\n",
    "# Draw node labels\n",
    "nx.draw_networkx_labels(G, pos, labels, font_size=12)\n",
    "# Draw edge labels with transition probabilities\n",
    "nx.draw_networkx_edge_labels(G, pos, edge_labels=edge_labels, font_size=6, label_pos=0.6)\n",
    "\n",
    "# カラーバーの追加\n",
    "plt.colorbar(nodes, label='Number of Students')\n",
    "\n",
    "# グラフ描画の最後にコメントを追加\n",
    "plt.text(\n",
    "    0.5, -0.05,  # テキストの位置 (x, y)。x=0.5 は中央、y=1.05 はグラフの上\n",
    "    \"edges: predicted transition probability\\n (): transition probability\",  # 表示したいテキスト\n",
    "    horizontalalignment='center',  # テキストの水平方向の配置（中央揃え）\n",
    "    verticalalignment='center',    # テキストの垂直方向の配置（中央揃え）\n",
    "    transform=plt.gca().transAxes,  # Axes の座標系で位置を指定 (0-1の範囲)\n",
    "    fontsize=12,                    # フォントサイズ\n",
    "    color=\"black\"                   # テキストの色\n",
    ")\n",
    "\n",
    "plt.title('Vertical Network Graph of Test Results with Transition Probabilities')\n",
    "plt.axis('off')\n",
    "plt.tight_layout()\n",
    "\n",
    "# Display the graph\n",
    "plt.show()\n",
    "\n",
    "# Print the state counts\n",
    "print(\"State counts:\")\n",
    "for state, count in sorted(state_counts.items(), key=lambda x: sum(x[0])):\n",
    "    print(f\"State {''.join(map(str, state))}: {count} students\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1024\n"
     ]
    }
   ],
   "source": [
    "print(len(state_counts))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "KT",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
