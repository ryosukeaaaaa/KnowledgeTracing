{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 時間情報のない集団データ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 方針"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "・内部に問題ごとの依存関係を定義し、その関係をもとに遷移させる。\n",
    "\n",
    "・条件付き確率（遷移確率）と周辺分布の積の和から次の周辺分布を求める。\n",
    "\n",
    "・まずは遷移過程が部分的にしか分からない人工データを用意し、モデルを学習する。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 人工データ生成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.  0.  0.  0.  0.  0. ]\n",
      " [3.  0.  0.  0.  0.  0. ]\n",
      " [3.  0.  0.  0.  0.  0. ]\n",
      " [0.  1.5 1.5 0.  0.  0. ]\n",
      " [0.  0.  0.  3.  0.  0. ]\n",
      " [0.  0.  0.  0.  3.  0. ]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# 問題の依存関係の行列 A \n",
    "A = np.array([\n",
    "    [0, 0, 0, 0, 0, 0],  # 初期状態\n",
    "    [1, 0, 0, 0, 0, 0],  # 問題1は初期状態のみに依存\n",
    "    [1, 0, 0, 0, 0, 0],  # 問題2は問題1に依存\n",
    "    [0, 1, 1, 0, 0, 0],  # 問題3は問題2に依存\n",
    "    [0, 0, 0, 1, 0, 0],  # 問題4は問題2、問題3に依存\n",
    "    [0, 0, 0, 0, 1, 0]   # 問題4は問題2、問題3に依存\n",
    "], dtype = float)*3\n",
    "\n",
    "# 0でない要素の数で割る処理\n",
    "nonzero_counts = np.count_nonzero(A[1:], axis=1, keepdims=True)\n",
    "A[1:] = np.where(nonzero_counts != 0, A[1:] / nonzero_counts, 0)\n",
    "\n",
    "print(A)\n",
    "\n",
    "# 遷移確率を計算する関数\n",
    "def calculate_transition_probabilities(A, X):\n",
    "    n = len(X)\n",
    "    raw_probabilities = np.zeros(n)  # 遷移確率の元となる値\n",
    "    \n",
    "    # 不正解の問題に対して遷移確率を計算\n",
    "    for i in range(n):\n",
    "        if X[i] == 0:  # まだ正解していない問題のみ対象\n",
    "            required_problems = A[i, :]  # i番目の問題に必要な依存関係\n",
    "            \n",
    "            solved_problems = X * required_problems  # 現状解けている\n",
    "            \n",
    "            num_solved = np.sum(solved_problems)      # 実際に解けた問題の数\n",
    "            \n",
    "            raw_probabilities[i] = np.exp(num_solved)\n",
    "    \n",
    "    # 総和で割って正規化\n",
    "    total_sum = np.sum(raw_probabilities)  # expの総和\n",
    "    if total_sum > 0:  # 総和が0でなければ正規化\n",
    "        probabilities = raw_probabilities / total_sum\n",
    "    else:\n",
    "        probabilities = raw_probabilities  # 総和が0ならそのまま\n",
    "    \n",
    "    return probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 教師データセットを生成する関数\n",
    "def generate_training_data(A, initial_X, num_correct_problems, num_data_per_step):\n",
    "    n = len(initial_X)  # 問題数\n",
    "    dataset = []\n",
    "    \n",
    "    # 各ステップでデータを生成\n",
    "    for i in range(1, num_correct_problems + 1):  # 正解させる問題数。別にnum_correct_problems問目は生成する必要ない。\n",
    "        for j in range(num_data_per_step):  # 各ステップごとにデータ数\n",
    "            X = initial_X.copy()  # 初期状態からスタート\n",
    "            input_X = X.copy()\n",
    "            # i問正解させる\n",
    "            for k in range(i):\n",
    "\n",
    "                probabilities = calculate_transition_probabilities(A, X)\n",
    "                \n",
    "                if np.sum(probabilities) > 0:  # 正規化された確率がある場合\n",
    "                    # 確率に基づいて次に正解させる問題を選択\n",
    "                    next_correct_problem = np.random.choice(n, p=probabilities)\n",
    "                    X[next_correct_problem] = 1  # 選ばれた問題を正解に遷移させる\n",
    "                \n",
    "            # 初期状態と1ステップ後の状態の差分を教師データとして使用\n",
    "            target_Y = (X - input_X).clip(min=0)  # 0から1に変わった部分のみを1、他は0\n",
    "\n",
    "            # print(f\"input_X: {input_X}, target_Y: {target_Y}\")\n",
    "\n",
    "            # 初期状態（入力）と差分（教師データ）のペアを保存\n",
    "            dataset.append((input_X.copy(), target_Y.copy()))  # (入力データ, 教師データ)\n",
    "    return dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/zg/773ptkr55z99zw26dvy19_v00000gn/T/ipykernel_13586/3134062968.py:16: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/tensor_new.cpp:281.)\n",
      "  train_X = torch.tensor(train_X, dtype=torch.float32)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# データセットの生成\n",
    "num_questions = 5  # 問題数\n",
    "num_data_per_step = 60     # 各ステップごとに生成するデータ数\n",
    "\n",
    "# 生徒の回答状況 X (1が正解、0が不正解)\n",
    "# 初期状態は全て不正解\n",
    "X_init = np.array([1, 0, 0, 0, 0, 0])\n",
    "\n",
    "training_data = generate_training_data(A, X_init, num_questions, num_data_per_step)\n",
    "train_X = [input_data for input_data, _ in training_data]\n",
    "train_Y = [target_data for _, target_data in training_data]\n",
    "\n",
    "# PyTorch テンソルに変換\n",
    "train_X = torch.tensor(train_X, dtype=torch.float32)\n",
    "train_Y = torch.tensor(train_Y, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of States: 32\n",
      "\n",
      "defaultdict(<class 'int'>, {(1, 0, 1, 0, 0, 0): 28, (1, 0, 0, 1, 0, 0): 2, (1, 1, 0, 0, 0, 0): 25, (1, 0, 0, 0, 1, 0): 1, (1, 0, 0, 0, 0, 1): 4, (1, 1, 1, 0, 0, 0): 47, (1, 1, 0, 1, 0, 0): 5, (1, 0, 1, 0, 1, 0): 2, (1, 0, 1, 1, 0, 0): 2, (1, 0, 0, 0, 1, 1): 1, (1, 1, 0, 0, 0, 1): 3, (1, 1, 1, 1, 0, 0): 44, (1, 1, 1, 0, 1, 0): 4, (1, 0, 1, 1, 1, 0): 7, (1, 1, 0, 1, 1, 0): 3, (1, 0, 1, 0, 1, 1): 1, (1, 1, 1, 0, 0, 1): 1, (1, 1, 1, 1, 1, 0): 45, (1, 0, 1, 1, 1, 1): 3, (1, 1, 1, 1, 0, 1): 8, (1, 1, 0, 1, 1, 1): 1, (1, 1, 1, 0, 1, 1): 3, (1, 1, 1, 1, 1, 1): 60})\n",
      "State [1, 0, 0, 0, 0, 0]: 0 students\n",
      "State [1, 0, 0, 0, 0, 1]: 4 students\n",
      "State [1, 0, 0, 0, 1, 0]: 1 students\n",
      "State [1, 0, 0, 1, 0, 0]: 2 students\n",
      "State [1, 0, 1, 0, 0, 0]: 28 students\n",
      "State [1, 1, 0, 0, 0, 0]: 25 students\n",
      "State [1, 0, 0, 0, 1, 1]: 1 students\n",
      "State [1, 0, 0, 1, 0, 1]: 0 students\n",
      "State [1, 0, 0, 1, 1, 0]: 0 students\n",
      "State [1, 0, 1, 0, 0, 1]: 0 students\n",
      "State [1, 0, 1, 0, 1, 0]: 2 students\n",
      "State [1, 0, 1, 1, 0, 0]: 2 students\n",
      "State [1, 1, 0, 0, 0, 1]: 3 students\n",
      "State [1, 1, 0, 0, 1, 0]: 0 students\n",
      "State [1, 1, 0, 1, 0, 0]: 5 students\n",
      "State [1, 1, 1, 0, 0, 0]: 47 students\n",
      "State [1, 0, 0, 1, 1, 1]: 0 students\n",
      "State [1, 0, 1, 0, 1, 1]: 1 students\n",
      "State [1, 0, 1, 1, 0, 1]: 0 students\n",
      "State [1, 0, 1, 1, 1, 0]: 7 students\n",
      "State [1, 1, 0, 0, 1, 1]: 0 students\n",
      "State [1, 1, 0, 1, 0, 1]: 0 students\n",
      "State [1, 1, 0, 1, 1, 0]: 3 students\n",
      "State [1, 1, 1, 0, 0, 1]: 1 students\n",
      "State [1, 1, 1, 0, 1, 0]: 4 students\n",
      "State [1, 1, 1, 1, 0, 0]: 44 students\n",
      "State [1, 0, 1, 1, 1, 1]: 3 students\n",
      "State [1, 1, 0, 1, 1, 1]: 1 students\n",
      "State [1, 1, 1, 0, 1, 1]: 3 students\n",
      "State [1, 1, 1, 1, 0, 1]: 8 students\n",
      "State [1, 1, 1, 1, 1, 0]: 45 students\n",
      "State [1, 1, 1, 1, 1, 1]: 60 students\n",
      "defaultdict(<class 'int'>, {(1, 0, 1, 0, 0, 0): 28, (1, 0, 0, 1, 0, 0): 2, (1, 1, 0, 0, 0, 0): 25, (1, 0, 0, 0, 1, 0): 1, (1, 0, 0, 0, 0, 1): 4, (1, 1, 1, 0, 0, 0): 47, (1, 1, 0, 1, 0, 0): 5, (1, 0, 1, 0, 1, 0): 2, (1, 0, 1, 1, 0, 0): 2, (1, 0, 0, 0, 1, 1): 1, (1, 1, 0, 0, 0, 1): 3, (1, 1, 1, 1, 0, 0): 44, (1, 1, 1, 0, 1, 0): 4, (1, 0, 1, 1, 1, 0): 7, (1, 1, 0, 1, 1, 0): 3, (1, 0, 1, 0, 1, 1): 1, (1, 1, 1, 0, 0, 1): 1, (1, 1, 1, 1, 1, 0): 45, (1, 0, 1, 1, 1, 1): 3, (1, 1, 1, 1, 0, 1): 8, (1, 1, 0, 1, 1, 1): 1, (1, 1, 1, 0, 1, 1): 3, (1, 1, 1, 1, 1, 1): 60, (1, 0, 0, 0, 0, 0): 0, (1, 0, 0, 1, 0, 1): 0, (1, 0, 0, 1, 1, 0): 0, (1, 0, 1, 0, 0, 1): 0, (1, 1, 0, 0, 1, 0): 0, (1, 0, 0, 1, 1, 1): 0, (1, 0, 1, 1, 0, 1): 0, (1, 1, 0, 0, 1, 1): 0, (1, 1, 0, 1, 0, 1): 0})\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "from collections import defaultdict\n",
    "\n",
    "# Generate states where the first digit is always 1\n",
    "states = [(1,) + state for state in itertools.product([0, 1], repeat=num_questions)]\n",
    "print(f\"Number of States: {len(states)}\\n\")\n",
    "\n",
    "states = sorted(states, key=lambda state: sum(state))\n",
    "\n",
    "# Initialize the state counts\n",
    "state_counts = defaultdict(int)\n",
    "\n",
    "# Assuming 'dataset' is your list of student results\n",
    "for result, result2 in training_data:\n",
    "    # print(result2)\n",
    "    state_tuple = tuple(map(int, result + result2))  # Convert np.int64 to int\n",
    "    state_counts[state_tuple] += 1  # Count only if the first digit is 1\n",
    "\n",
    "print(state_counts)\n",
    "\n",
    "# Display the counts for each state\n",
    "for state in states:\n",
    "    count = state_counts[state]\n",
    "    formatted_state = list(state)  # Convert tuple to list for the desired format\n",
    "    print(f\"State {formatted_state}: {count} students\")\n",
    "\n",
    "print(state_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## モデル"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def _bcsoftmax1d(x, budget):\n",
    "    \"\"\"Budget Constrained Softmax function for vector.\n",
    "\n",
    "    Args:\n",
    "        x (Tensor): input vector. shape: (n_outputs, )\n",
    "        budget (Tensor): budget (constraint) vector. shape: (n_outputs, )\n",
    "\n",
    "    Returns:\n",
    "        y (Tensor): output probability vector. shape: (n_outputs, ). Satisfying the constraints y_i <= budget_i.\n",
    "    \n",
    "    \"\"\"\n",
    "    x = x - torch.max(x, dim=0)[0] # normalization to avoid numerical errors\n",
    "    exp_x = torch.exp(x)\n",
    "    # sorting\n",
    "    _, indices = torch.sort(budget / exp_x, descending=False)\n",
    "    exp_x = exp_x[indices]\n",
    "    budget = budget[indices]\n",
    "    # find K_B\n",
    "    r = torch.flip(torch.cumsum(torch.flip(exp_x, dims=(0, )), dim=0), dims=(0, ))\n",
    "    s = 1.0 - (torch.cumsum(budget, dim=0) - budget)\n",
    "    z = r / s\n",
    "    is_in_KB = torch.logical_and(\n",
    "        (s - budget) > 0, exp_x / z > budget\n",
    "    )\n",
    "    # compute outputs\n",
    "    s = 1 - torch.sum(budget * is_in_KB)\n",
    "    r = torch.sum(exp_x * (~is_in_KB))\n",
    "    y = torch.where(~is_in_KB, s * exp_x / r, budget)\n",
    "    # undo sorting\n",
    "    _, inv_indices = torch.sort(indices, descending=False)\n",
    "    return y[inv_indices]\n",
    "\n",
    "\n",
    "def _bcsoftmax1d_stable(x, budget):\n",
    "    \"\"\"Budget Constrained Softmax function for vector.\n",
    "    This function is more numerically stable than `_bcsoftmax1d` by computing some values in log-scale.\n",
    "    \n",
    "    Args:\n",
    "        x (Tensor): input vector. shape: (n_outputs, )\n",
    "        budget (Tensor): budget (constraint) vector. shape: (n_outputs, )\n",
    "\n",
    "    Returns:\n",
    "        y (Tensor): output probability vector. shape: (n_outputs, ). Satisfying the constraints y_i <= budget_i.\n",
    "    \n",
    "    \"\"\"\n",
    "    # sorting\n",
    "    _, indices = torch.sort(torch.log(budget) - x, descending=False)\n",
    "    x = x[indices]\n",
    "    budget = budget[indices]\n",
    "    # find K_B\n",
    "    log_r = torch.flip(torch.logcumsumexp(torch.flip(x, dims=(0, )), dim=0), dims=(0, ))\n",
    "    s = 1.0 - (torch.cumsum(budget, dim=0) - budget)\n",
    "    is_in_KB = torch.logical_or(\n",
    "        budget == 0,\n",
    "        torch.logical_and(\n",
    "            s - budget > 0,\n",
    "            x - log_r + torch.log(s) > torch.log(budget)\n",
    "        )\n",
    "    )\n",
    "    # compute outputs\n",
    "    exp_x = torch.exp(x - torch.max(torch.where(~is_in_KB, x, -torch.inf), dim=0)[0])\n",
    "    s = 1 - torch.sum(budget * is_in_KB)\n",
    "    r = torch.sum(exp_x * (~is_in_KB))\n",
    "    y = torch.where(~is_in_KB, s * exp_x / r, budget)\n",
    "    # undo sorting\n",
    "    _, inv_indices = torch.sort(indices, descending=False)\n",
    "    return y[inv_indices]\n",
    "\n",
    "\n",
    "class BCSoftmax1d(torch.autograd.Function):\n",
    "    \"\"\"Autograd implementation of Budget Constrained Softmax function for vector.\n",
    "    \"\"\"\n",
    "    generate_vmap_rule = True\n",
    "    \n",
    "    @staticmethod\n",
    "    def forward(x, c):\n",
    "        y = _bcsoftmax1d_stable(x, c)\n",
    "        return y\n",
    "\n",
    "    @staticmethod\n",
    "    def setup_context(ctx, inputs, output):\n",
    "        x, c = inputs\n",
    "        is_in_KB = c == output\n",
    "        ctx.save_for_backward(x, c, is_in_KB)\n",
    "    \n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_y):\n",
    "        x, c, is_in_KB = ctx.saved_tensors\n",
    "        exp_x = torch.exp(\n",
    "            x - torch.max(torch.where(~is_in_KB, x, -torch.inf), dim=0)[0]\n",
    "        )\n",
    "        s = 1 - torch.sum(c * is_in_KB)\n",
    "        r = torch.sum(exp_x * (~is_in_KB))\n",
    "        \n",
    "        # compute Jacobian\n",
    "        Jx = torch.where(\n",
    "            torch.outer(~is_in_KB, ~is_in_KB),\n",
    "            torch.diag(~is_in_KB * exp_x) * r - torch.outer(exp_x, exp_x),\n",
    "            0,\n",
    "        )\n",
    "        Jx *= torch.where(\n",
    "            s > 0,\n",
    "            s / (r * r),\n",
    "            0\n",
    "        )\n",
    "        Jc = torch.where(\n",
    "            torch.outer(~is_in_KB, is_in_KB),\n",
    "            - exp_x[:, None] / r,\n",
    "            1.0 * torch.diag(is_in_KB)\n",
    "        )\n",
    "\n",
    "        # print(\"s\", s, \"r\", r)\n",
    "        # print(\"勾配\", torch.matmul(grad_y, Jx), torch.matmul(grad_y, Jc))\n",
    "        assert not torch.isnan(torch.matmul(grad_y, Jx)).any(), \"Jx contains NaN\"\n",
    "        assert not torch.isinf(torch.matmul(grad_y, Jx)).any(), \"Jx contains Inf\"\n",
    "        assert not torch.isnan(torch.matmul(grad_y, Jc)).any(), \"Jc contains NaN\"\n",
    "        assert not torch.isinf(torch.matmul(grad_y, Jc)).any(), \"Jc contains Inf\"\n",
    "\n",
    "        # return vector-Jacobian product\n",
    "        return torch.matmul(grad_y, Jx), torch.matmul(grad_y, Jc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "######### Use these functions! #########\n",
    "bcsoftmax1d = BCSoftmax1d.apply\n",
    "\n",
    "# データによってmodelを通す回数が違\n",
    "# bcsoftmax2d = torch.vmap(BCSoftmax1d.apply) # input shape = (batch_size, n_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, num_questions):\n",
    "        super(Model, self).__init__()\n",
    "        self.fc = nn.Linear(num_questions, num_questions, bias=False)  # 全結合層\n",
    "\n",
    "    def forward(self, x, c):\n",
    "        x = self.fc(x)  # 全結合層の適用\n",
    "        x = bcsoftmax1d(x, c)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# モデル、損失関数、最適化関数の設定\n",
    "model = Model(num_questions+1)  # 5問+初期状態の問題を扱うモデル\n",
    "criterion = nn.CrossEntropyLoss()  # クロスエントロピー損失\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 学習"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [50/1000], Loss: 4.9274\n",
      "Epoch [100/1000], Loss: 4.8583\n",
      "Epoch [150/1000], Loss: 4.8140\n",
      "Epoch [200/1000], Loss: 4.7923\n",
      "Epoch [250/1000], Loss: 4.7814\n",
      "Epoch [300/1000], Loss: 4.7750\n",
      "Epoch [350/1000], Loss: 4.7710\n",
      "Epoch [400/1000], Loss: 4.7682\n",
      "Epoch [450/1000], Loss: 4.7661\n",
      "Epoch [500/1000], Loss: 4.7645\n",
      "Epoch [550/1000], Loss: 4.7632\n",
      "Epoch [600/1000], Loss: 4.7621\n",
      "Epoch [650/1000], Loss: 4.7611\n",
      "Epoch [700/1000], Loss: 4.7603\n",
      "Epoch [750/1000], Loss: 4.7597\n",
      "Epoch [800/1000], Loss: 4.7592\n",
      "Epoch [850/1000], Loss: 4.7588\n",
      "Epoch [900/1000], Loss: 4.7584\n",
      "Epoch [950/1000], Loss: 4.7581\n",
      "Epoch [1000/1000], Loss: 4.7578\n",
      "Training complete!\n"
     ]
    }
   ],
   "source": [
    "# 学習ループ\n",
    "num_epochs = 1000  # エポック数\n",
    "alpha = 0.001 # 正則化パラメータ\n",
    "\n",
    "# データの確認\n",
    "assert not torch.isnan(train_X).any(), \"train_X contains NaN\"\n",
    "assert not torch.isinf(train_X).any(), \"train_X contains Inf\"\n",
    "assert not torch.isnan(train_Y).any(), \"train_Y contains NaN\"\n",
    "assert not torch.isinf(train_Y).any(), \"train_Y contains Inf\"\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()  # モデルを訓練モードに\n",
    "    optimizer.zero_grad()  # 勾配の初期化\n",
    "    \n",
    "    outputs = []  # 出力を保持するリスト\n",
    "    \n",
    "    # 各データに対して train_Y の値に基づいてループを実行\n",
    "    for i, target in enumerate(train_Y):\n",
    "        c = torch.cat([torch.tensor([0.0]), torch.ones(num_questions, dtype=torch.float32)])\n",
    "        output = train_X[i]  # 各 i 番目の入力データを使用\n",
    "        output = output.view(-1)\n",
    "        # target (train_Y[i]) が int 型または float 型であると仮定\n",
    "        for _ in range(int(sum(target))):\n",
    "            # もしcの和が1なら、rが0となるので対応\n",
    "            if c.sum() <= 1:\n",
    "                # print(\"aaaaaaaa\")\n",
    "                output_0 = c\n",
    "            else:\n",
    "                output_0 = model(output, c)  # 前回の出力を次のステップの入力として使用\n",
    "            output = output_0 + output  # 出力を加算\n",
    "            c = c - output_0  # 予算を更新\n",
    "\n",
    "        outputs.append(output - train_X[i])  # 最終的な出力を保存\n",
    "\n",
    "    # outputs を適切な形に変換して損失計算（例えば torch.stack を使用）\n",
    "    outputs = torch.stack(outputs)\n",
    "    outputs = outputs.squeeze(1)\n",
    "\n",
    "    # モデルの出力の確認\n",
    "    assert not torch.isnan(outputs).any(), \"Model output contains NaN\"\n",
    "    assert not torch.isinf(outputs).any(), \"Model output contains Inf\"\n",
    "\n",
    "    # L1正則化項の計算\n",
    "    l1_reg = torch.tensor(0.0, requires_grad=True)\n",
    "    for param in model.parameters():\n",
    "        l1_reg = l1_reg + torch.sum(torch.abs(param))\n",
    "\n",
    "    # 損失の計算\n",
    "    loss0 = criterion(outputs, train_Y)\n",
    "\n",
    "    loss = loss0 + alpha * l1_reg  # L1正則化項を追加した損失\n",
    "    \n",
    "    # 損失の確認\n",
    "    assert not torch.isnan(loss).any(), \"Loss contains NaN\"\n",
    "    assert not torch.isinf(loss).any(), \"Loss contains Inf\"\n",
    "    \n",
    "    # バックプロパゲーションとパラメータの更新\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    # 100エポックごとに損失を表示\n",
    "    if (epoch+1) % 50 == 0:\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
    "\n",
    "# 学習結果の確認\n",
    "print(\"Training complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## テスト"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output: tensor([0.0000, 0.0000, 0.8703, 0.1217, 0.0064, 0.0017],\n",
      "       grad_fn=<BCSoftmax1dBackward>)\n"
     ]
    }
   ],
   "source": [
    "test = np.array([1, 1, 0, 0, 0, 0], dtype=np.float32)\n",
    "\n",
    "# numpy配列をtorch.Tensorに変換\n",
    "test_tensor = torch.tensor(test, dtype=torch.float32)\n",
    "\n",
    "model.eval()  # モデルを評価モードに\n",
    "\n",
    "c_test = torch.ones(num_questions+1, dtype=torch.float32)\n",
    "c_test = c_test - test_tensor  # 予算を更新\n",
    "\n",
    "# モデルに入力を渡して出力を得る\n",
    "output = model(test_tensor, c_test)\n",
    "print(\"Output:\", output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### パラメータ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a Parameter containing:\n",
      "tensor([[     0.0002,     -0.0008,     -0.0000,      0.0002,     -0.0015,\n",
      "              0.0011],\n",
      "        [     2.0828,      0.2276,      1.4830,     -0.0012,      0.0001,\n",
      "             -0.0003],\n",
      "        [     2.5312,     -0.0003,      0.0001,      0.0000,     -0.0003,\n",
      "              0.0007],\n",
      "        [    -1.8173,      2.3807,      0.4391,      0.0005,      0.0011,\n",
      "             -0.0005],\n",
      "        [    -2.3159,     -0.0698,     -0.0005,      0.0028,      0.0002,\n",
      "             -0.0002],\n",
      "        [    -2.1543,     -1.5462,     -1.7925,     -0.3469,     -0.0002,\n",
      "              0.0004]], requires_grad=True)\n",
      "本来の依存関係\n",
      " [[0.  0.  0.  0.  0.  0. ]\n",
      " [3.  0.  0.  0.  0.  0. ]\n",
      " [3.  0.  0.  0.  0.  0. ]\n",
      " [0.  1.5 1.5 0.  0.  0. ]\n",
      " [0.  0.  0.  3.  0.  0. ]\n",
      " [0.  0.  0.  0.  3.  0. ]]\n"
     ]
    }
   ],
   "source": [
    "torch.set_printoptions(precision=4, sci_mode=False)# モデルの各パラメータを表示\n",
    "for param in model.parameters():\n",
    "    print(\"a\", param)\n",
    "\n",
    "print(\"本来の依存関係\\n\", A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 評価指標"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KLダイバージェンスの計算式\n",
    "\n",
    "$$ D_{\\text{KL}}(p \\| q) = \\sum_{i} p(i) \\log \\frac{p(i)}{q(i)} $$\n",
    "\n",
    "---\n",
    "\n",
    "Hellinger距離の計算式\n",
    "\n",
    "$$ H(p, q) = \\frac{1}{\\sqrt{2}} \\left\\| \\sqrt{p} - \\sqrt{q} \\right\\|_2 $$\n",
    "\n",
    "ここで、ユークリッドノルム（L2ノルム）は以下のように定義されます：\n",
    "\n",
    "$$ \\left\\| \\sqrt{p} - \\sqrt{q} \\right\\|_2 = \\sqrt{\\sum_{i} \\left( \\sqrt{p(i)} - \\sqrt{q(i)} \\right)^2} $$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def kl_divergence(p, q, epsilon=1e-10):\n",
    "    \"\"\"\n",
    "    KLダイバージェンスを計算する関数（qが0の場合の無限大問題を回避）\n",
    "    \n",
    "    Parameters:\n",
    "        p (numpy.ndarray): 真の確率分布\n",
    "        q (numpy.ndarray): 予測確率分布\n",
    "        epsilon (float): スムージングパラメータ（非常に小さい値）\n",
    "    \n",
    "    Returns:\n",
    "        float: KLダイバージェンス\n",
    "    \"\"\"\n",
    "    p = np.array(p, dtype=np.float64)\n",
    "    q = np.array(q, dtype=np.float64)\n",
    "    \n",
    "    # pとqにスムージングを適用\n",
    "    p = np.where(p == 0, epsilon, p)\n",
    "    q = np.where(q == 0, epsilon, q)\n",
    "    \n",
    "    # KLダイバージェンスの計算\n",
    "    return np.sum(p * np.log(p / q))\n",
    "\n",
    "def hellinger_distance(p, q):\n",
    "    \"\"\"\n",
    "    Hellinger距離を計算する関数\n",
    "\n",
    "    Parameters:\n",
    "        p (numpy.ndarray): 真の分布 [batch_size, num_classes]\n",
    "        q (numpy.ndarray): 予測分布 [batch_size, num_classes]\n",
    "    \n",
    "    Returns:\n",
    "        float: Hellinger距離の平均値\n",
    "    \"\"\"\n",
    "    p = np.array(p, dtype=np.float64)\n",
    "    q = np.array(q, dtype=np.float64)\n",
    "    # Hellinger距離の計算式: H(p, q) = (1/√2) * ||√p - √q||_2\n",
    "    sqrt_p = np.sqrt(p)\n",
    "    sqrt_q = np.sqrt(q)\n",
    "    distance = np.sqrt(np.sum((sqrt_p - sqrt_q) ** 2)) / np.sqrt(2)\n",
    "    return np.mean(distance)\n",
    "\n",
    "def evaluate_model(r, p, q):\n",
    "    \"\"\"\n",
    "    遷移確率の真値と予測値の類似性を評価する関数\n",
    "    :param r: 各ノードの重み (np.array)\n",
    "    :param p: 各ノードの真の遷移確率 (2D np.array: ノード数 x 遷移確率)\n",
    "    :param q: 各ノードの予測遷移確率 (2D np.array: ノード数 x 遷移確率)\n",
    "    :return: 評価指標 L\n",
    "    \"\"\"\n",
    "    L = 0\n",
    "    for k in range(len(r)):\n",
    "        L += r[k] * kl_divergence(p[k], q[k])\n",
    "    return L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "状態: (1, 0, 0, 0, 0, 0), ノード分布: 1, KL: 0.0685, HD: 0.122\n",
      "状態: (1, 0, 0, 0, 0, 1), ノード分布: 0.0232, KL: 0.00126, HD: 0.00253\n",
      "状態: (1, 0, 0, 0, 1, 0), ノード分布: 0.0232, KL: 0.0254, HD: 0.00887\n",
      "状態: (1, 0, 0, 1, 0, 0), ノード分布: 0.0232, KL: 0.0268, HD: 0.00901\n",
      "状態: (1, 0, 1, 0, 0, 0), ノード分布: 0.465, KL: 0.275, HD: 0.136\n",
      "状態: (1, 1, 0, 0, 0, 0), ノード分布: 0.465, KL: 0.0614, HD: 0.0692\n",
      "状態: (1, 0, 0, 0, 1, 1), ノード分布: 0.00814, KL: 0.00029, HD: 0.000746\n",
      "状態: (1, 0, 0, 1, 0, 1), ノード分布: 0.000927, KL: 0.00108, HD: 0.00036\n",
      "状態: (1, 0, 0, 1, 1, 0), ノード分布: 0.00797, KL: 0.00978, HD: 0.00313\n",
      "状態: (1, 0, 1, 0, 0, 1), ノード分布: 0.0285, KL: 0.0138, HD: 0.00768\n",
      "状態: (1, 0, 1, 0, 1, 0), ノード分布: 0.0251, KL: 0.0737, HD: 0.0135\n",
      "状態: (1, 0, 1, 1, 0, 0), ノード分布: 0.0861, KL: 0.195, HD: 0.0441\n",
      "状態: (1, 1, 0, 0, 0, 1), ノード分布: 0.0285, KL: 0.00151, HD: 0.00293\n",
      "状態: (1, 1, 0, 0, 1, 0), ノード分布: 0.0251, KL: 0.0548, HD: 0.0121\n",
      "状態: (1, 1, 0, 1, 0, 0), ノード分布: 0.0861, KL: 0.153, HD: 0.0421\n",
      "状態: (1, 1, 1, 0, 0, 0), ノード分布: 0.703, KL: 0.0813, HD: 0.0895\n",
      "状態: (1, 0, 0, 1, 1, 1), ノード分布: 0.00316, KL: 7.95e-05, HD: 0.00025\n",
      "状態: (1, 0, 1, 0, 1, 1), ノード分布: 0.0164, KL: 0.00711, HD: 0.00411\n",
      "状態: (1, 0, 1, 1, 0, 1), ノード分布: 0.0074, KL: 0.0166, HD: 0.00375\n",
      "状態: (1, 0, 1, 1, 1, 0), ノード分布: 0.0472, KL: 0.153, HD: 0.0249\n",
      "状態: (1, 1, 0, 0, 1, 1), ノード分布: 0.0164, KL: 0.000241, HD: 0.000967\n",
      "状態: (1, 1, 0, 1, 0, 1), ノード分布: 0.0074, KL: 0.0131, HD: 0.00359\n",
      "状態: (1, 1, 0, 1, 1, 0), ノード分布: 0.0472, KL: 0.123, HD: 0.0244\n",
      "状態: (1, 1, 1, 0, 0, 1), ノード分布: 0.0767, KL: 0.000233, HD: 0.00205\n",
      "状態: (1, 1, 1, 0, 1, 0), ノード分布: 0.0544, KL: 0.139, HD: 0.0281\n",
      "状態: (1, 1, 1, 1, 0, 0), ノード分布: 0.724, KL: 0.00298, HD: 0.0224\n",
      "状態: (1, 0, 1, 1, 1, 1), ノード分布: 0.0319, KL: 0, HD: 0\n",
      "状態: (1, 1, 0, 1, 1, 1), ノード分布: 0.0319, KL: 0, HD: 0\n",
      "状態: (1, 1, 1, 0, 1, 1), ノード分布: 0.0576, KL: 0, HD: 0\n",
      "状態: (1, 1, 1, 1, 0, 1), ノード分布: 0.115, KL: 0, HD: 0\n",
      "状態: (1, 1, 1, 1, 1, 0), ノード分布: 0.764, KL: 0, HD: 0\n",
      "状態: (1, 1, 1, 1, 1, 1), ノード分布: 1, KL: 0, HD: 0\n",
      "評価指標 KL: 1.4973091466585093\n",
      "評価指標 HD: 0.6783519952354837\n"
     ]
    }
   ],
   "source": [
    "node_probabilities = defaultdict(float)\n",
    "KL = 0\n",
    "HD = 0\n",
    "start = (1,) + tuple(0 for _ in range(num_questions))\n",
    "node_probabilities[start] = 1\n",
    "\n",
    "for state in states:\n",
    "    probabilities = calculate_transition_probabilities(A, np.array(state))\n",
    "\n",
    "    # 最下層から頂点までのノードの分布を順に計算\n",
    "    for i in range(num_questions + 1):\n",
    "        if state[i] == 0:  # まだ解けていない問題\n",
    "            # 遷移後の状態\n",
    "            next_state = list(state)\n",
    "            next_state[i] = 1\n",
    "            next_state = tuple(next_state)\n",
    "            node_probabilities[next_state] += probabilities[i] * node_probabilities[state]\n",
    "    \n",
    "    # budgetの計算\n",
    "    c_g = torch.ones(num_questions+1, dtype=torch.float32)\n",
    "    c_g = c_g - torch.tensor(state, dtype=torch.float32)\n",
    "\n",
    "    # 状態とその予測分布\n",
    "    state_tensor = torch.tensor(state, dtype=torch.float32)\n",
    "    predicted_values = model(state_tensor, c_g)  # 予測値を計算\n",
    "\n",
    "    # 評価指標の計算\n",
    "    kl = node_probabilities[state] * kl_divergence(probabilities, predicted_values.detach())\n",
    "    hd = node_probabilities[state] * hellinger_distance(probabilities, predicted_values.detach())\n",
    "    print(f\"状態: {state}, ノード分布: {node_probabilities[state]:.3g}, KL: {kl:.3g}, HD: {hd:.3g}\")\n",
    "    KL += kl\n",
    "    HD += hd\n",
    "\n",
    "print(f\"評価指標 KL: {KL}\")\n",
    "print(f\"評価指標 HD: {HD}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 図示"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'states' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 9\u001b[0m\n\u001b[1;32m      6\u001b[0m G \u001b[38;5;241m=\u001b[39m nx\u001b[38;5;241m.\u001b[39mGraph()\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# Add nodes with the 'count' attribute\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m state \u001b[38;5;129;01min\u001b[39;00m \u001b[43mstates\u001b[49m:\n\u001b[1;32m     10\u001b[0m     G\u001b[38;5;241m.\u001b[39madd_node(state, count\u001b[38;5;241m=\u001b[39mstate_counts[state])\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# Add edges between states\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'states' is not defined"
     ]
    }
   ],
   "source": [
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Create the graph\n",
    "G = nx.Graph()\n",
    "\n",
    "# Add nodes with the 'count' attribute\n",
    "for state in states:\n",
    "    G.add_node(state, count=state_counts[state])\n",
    "\n",
    "# Add edges between states\n",
    "for state in states:\n",
    "    for i in range(num_questions+1):\n",
    "        next_state = list(state)\n",
    "        if next_state[i] == 0:\n",
    "            next_state[i] = 1\n",
    "            next_state = tuple(next_state)\n",
    "            if next_state in states:\n",
    "                G.add_edge(state, next_state)\n",
    "\n",
    "# Custom layout function with uniform horizontal placement and centered nodes\n",
    "def custom_layout(G, num_questions):\n",
    "    pos = {}\n",
    "    # Group nodes by their level (number of 1's in the state)\n",
    "    levels = {}\n",
    "    for state in G.nodes():\n",
    "        level = sum(state)  # Level is the number of 1's in the state\n",
    "        if level not in levels:\n",
    "            levels[level] = []\n",
    "        levels[level].append(state)\n",
    "    \n",
    "    # Determine the x and y positions for each node\n",
    "    for level, states_at_level in levels.items():\n",
    "        num_nodes_at_level = len(states_at_level)\n",
    "        for i, state in enumerate(sorted(states_at_level)):\n",
    "            # x position is evenly spaced horizontally for each level\n",
    "            x = i - (num_nodes_at_level - 1) / 2  # Center horizontally\n",
    "            y = level  # y position is the level itself (number of 1's)\n",
    "            pos[state] = (x, y)\n",
    "    \n",
    "    return pos\n",
    "\n",
    "\n",
    "# Apply the custom layout\n",
    "pos = custom_layout(G, num_questions)\n",
    "\n",
    "# Normalize x positions\n",
    "x_values = [pos[node][0] for node in pos]\n",
    "min_x, max_x = min(x_values), max(x_values)\n",
    "for node in pos:\n",
    "    x, y = pos[node]\n",
    "    x_norm = (x - min_x) / (max_x - min_x)\n",
    "    pos[node] = (x_norm, y)\n",
    "\n",
    "# Plot settings\n",
    "plt.figure(figsize=(18, 10))  # Adjust the figure size as needed\n",
    "\n",
    "# Draw edges\n",
    "nx.draw_networkx_edges(G, pos, alpha=0.2)\n",
    "\n",
    "# Adjust node sizes according to the number of students\n",
    "node_sizes = []\n",
    "for node in G.nodes():\n",
    "    count = G.nodes[node]['count']\n",
    "    size = max(300, min(6000, count/4))  # Increase the minimum size to 600\n",
    "    node_sizes.append(size)\n",
    "\n",
    "\n",
    "# Node colors based on the number of students\n",
    "node_colors = [G.nodes[node]['count'] for node in G.nodes()]\n",
    "nodes = nx.draw_networkx_nodes(\n",
    "    G, pos, node_size=node_sizes, node_color=node_colors, cmap=plt.cm.YlOrRd\n",
    ")\n",
    "\n",
    "# Create labels including the student counts\n",
    "labels = {\n",
    "    node: f\"{''.join(map(str, node))}\\n{G.nodes[node]['count']} students\"\n",
    "    for node in G.nodes()\n",
    "}\n",
    "\n",
    "# Transition probabilities: add labels to edges, including predicted values\n",
    "edge_labels = {}\n",
    "for state in states:\n",
    "    probabilities = calculate_transition_probabilities(A, np.array(state))\n",
    "    c_g = torch.ones(num_questions+1, dtype=torch.float32)\n",
    "    c_g = c_g - torch.tensor(state, dtype=torch.float32)  # 予算を更新\n",
    "    print(c_g)\n",
    "    print(torch.tensor([state], dtype=torch.float32))\n",
    "    state_tensor = torch.tensor(state, dtype=torch.float32)\n",
    "    print(state_tensor[1])\n",
    "    predicted_values = model(state_tensor, c_g)  # 予測値を計算\n",
    "    print(f\"State: {state}, Probabilities: {probabilities}, Predicted Values: {predicted_values}\")\n",
    "\n",
    "    for i in range(num_questions+1):\n",
    "        next_state = list(state)\n",
    "        if next_state[i] == 0:\n",
    "            next_state[i] = 1\n",
    "            next_state = tuple(next_state)\n",
    "            if next_state in states:\n",
    "                # 遷移確率と予測値をラベルに追加\n",
    "                transition_probability = f\"({probabilities[i]:.2f})\"\n",
    "                predicted_value = f\"{predicted_values[i]:.2f}\"  # 予測値を表示\n",
    "                edge_labels[(state, next_state)] = f\"{predicted_value}\\n{transition_probability}\"\n",
    "\n",
    "\n",
    "# Draw node labels\n",
    "nx.draw_networkx_labels(G, pos, labels, font_size=12)\n",
    "# Draw edge labels with transition probabilities\n",
    "nx.draw_networkx_edge_labels(G, pos, edge_labels=edge_labels, font_size=6, label_pos=0.6)\n",
    "\n",
    "# カラーバーの追加\n",
    "plt.colorbar(nodes, label='Number of Students')\n",
    "\n",
    "# グラフ描画の最後にコメントを追加\n",
    "plt.text(\n",
    "    0.5, -0.05,  # テキストの位置 (x, y)。x=0.5 は中央、y=1.05 はグラフの上\n",
    "    \"edges: predicted transition probability\\n (): transition probability\",  # 表示したいテキスト\n",
    "    horizontalalignment='center',  # テキストの水平方向の配置（中央揃え）\n",
    "    verticalalignment='center',    # テキストの垂直方向の配置（中央揃え）\n",
    "    transform=plt.gca().transAxes,  # Axes の座標系で位置を指定 (0-1の範囲)\n",
    "    fontsize=12,                    # フォントサイズ\n",
    "    color=\"black\"                   # テキストの色\n",
    ")\n",
    "\n",
    "plt.title('Vertical Network Graph of Test Results with Transition Probabilities')\n",
    "plt.axis('off')\n",
    "plt.tight_layout()\n",
    "\n",
    "# Display the graph\n",
    "plt.show()\n",
    "\n",
    "# Print the state counts\n",
    "print(\"State counts:\")\n",
    "for state, count in sorted(state_counts.items(), key=lambda x: sum(x[0])):\n",
    "    print(f\"State {''.join(map(str, state))}: {count} students\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "KT",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
